---
title: "Research"
format: html
toc: true
toc-title: On this page
number-sections: false
anchor-sections: false
page-layout: full
---

## ğŸš€ Research Vision {#research-vision}

I aim to advance the frontier of **safe, interpretable, and adaptive AI** for cyber-physical systems operating under uncertainty and dynamic constraints. My research sits at the intersection of **machine learning**, **optimization**, and **control theory**, with a particular focus on:

- **Physics-informed Deep Reinforcement Learning (DRL)**
- **Probabilistic & Bayesian Modeling**
- **Large Language Models (LLMs) for autonomous reasoning**
- **Vision-based simulation environments**

By tightly integrating domain knowledge into learning frameworks, I design agents capable of robust decision-making in real-world, high-stakes environments such as **smart grids**, **robotics**, and **intelligent infrastructure**.

---

## ğŸ§  Research Themes {#research-themes}

### Safe & Trustworthy Reinforcement Learning {#safe-rl}

<div style="display: flex; flex-wrap: wrap; align-items: center; gap: 1rem; padding: 1rem; border: 1.5px solid #ddd; border-radius: 12px; background-color: #f9fbfd; box-shadow: 1px 1px 6px rgba(0,0,0,0.05); margin-bottom: 1.5rem;">

<div style="flex: 1 1 300px; min-width: 250px;">
<p><strong>ğŸ¯ Objective</strong></p>
<p>Develop control agents that guarantee <strong>system safety</strong>, <strong>stability</strong>, and <strong>robust learning</strong> in dynamic, uncertain, and partially observable environments.</p>

<p><strong>ğŸ” Core Focus Areas</strong></p>
<ul>
<li>Constrained policy optimization and reward shaping</li>
<li>Physics-based priors in DRL</li>
<li>Adversarial resilience and anomaly detection</li>
<li>Epistemic and aleatoric uncertainty quantification</li>
</ul>
</div>

<div style="flex: 1 1 250px; text-align: center;">
<img src="/projects1/ehr/hex_ggehr.png" alt="Safe RL Diagram" style="max-width: 100%; border-radius: 8px;">
</div>

</div>


### Transfer Learning & Meta-Adaptation {#tl-rl}

<div style="display: flex; flex-wrap: wrap; align-items: center; gap: 1rem; padding: 1rem; border: 1.5px solid #ddd; border-radius: 12px; background-color: #f9fbfd; box-shadow: 1px 1px 6px rgba(0,0,0,0.05); margin-bottom: 1.5rem;">

<div style="flex: 1 1 300px; min-width: 250px;">
<p><strong>ğŸ¯ Objective</strong></p>
<p>Enabling rapid generalization across distribution shifts in topology, weather, or load profiles.</p>

<p><strong>ğŸ” Core Focus Areas</strong></p>
<ul>
<li>Transferable actor-critic architectures</li>
<li>Simulation-to-real (Sim2Real) adaptation</li>
<li>Meta-RL for sample efficiency</li>
</ul>
</div>

<div style="flex: 1 1 250px; text-align: center;">
<img src="/projects1/ehr/hex_ggehr.png" alt="Safe RL Diagram" style="max-width: 100%; border-radius: 8px;">
</div>

</div>

### Vision-Simulation Integration {#vision-sim}

<div style="display: flex; flex-wrap: wrap; align-items: center; gap: 1rem; padding: 1rem; border: 1.5px solid #ddd; border-radius: 12px; background-color: #f9fbfd; box-shadow: 1px 1px 6px rgba(0,0,0,0.05); margin-bottom: 1.5rem;">

<div style="flex: 1 1 300px; min-width: 250px;">
<p><strong>ğŸ¯ Objective</strong></p>
<p>Bridge the gap between perception and control by combining **synthetic sensors**, **simulated environments**, and **end-to-end learning** pipelines.</p>

<p><strong>ğŸ” Core Focus Areas</strong></p>
<ul>
<li>Perception-action loops with CARLA, AirSim  </li>
<li>Multi-modal representation fusion (image + state)  </li>
<li>Autonomous control with embedded perception modules</li>
<li>End-to-end autonomous control pipelines</li>
</ul>
</div>

<div style="flex: 1 1 250px; text-align: center;">
<img src="/projects1/ehr/hex_ggehr.png" alt="Safe RL Diagram" style="max-width: 100%; border-radius: 8px;">
</div>

</div>


### LLM-Augmented Decision Systems {#llm-control}

<div style="display: flex; flex-wrap: wrap; align-items: center; gap: 1rem; padding: 1rem; border: 1.5px solid #ddd; border-radius: 12px; background-color: #f9fbfd; box-shadow: 1px 1px 6px rgba(0,0,0,0.05); margin-bottom: 1.5rem;">

<div style="flex: 1 1 300px; min-width: 250px;">
<p><strong>ğŸ¯ Objective</strong></p>
<p>Develop control agents that guarantee <strong>system safety</strong>, <strong>stability</strong>, and <strong>robust learning</strong> in dynamic, uncertain, and partially observable environments.</p>

<p><strong>ğŸ” Core Focus Areas</strong></p>
<ul>
<li>LLMs for summarizing environment states and guiding agents </li>
<li>Translating textual inputs into actionable policies</li>
<li>Facilitating human-AI collaboration in dynamic tasks</li>
</ul>
</div>

<div style="flex: 1 1 250px; text-align: center;">
<img src="/projects1/ehr/hex_ggehr.png" alt="Safe RL Diagram" style="max-width: 100%; border-radius: 8px;">
</div>

</div>


## ğŸ”¬ Application Domains {#application-domains}

| Domain | Description |
|--------|-------------|
| âš¡ **Smart Energy Systems** | Volt-VAR control, DER coordination, and federated DRL for power grid stability |
| ğŸš˜ **Autonomous Systems** | Safe navigation, adaptive planning, and control in simulation and real-world driving environments |
| ğŸ›¡ **Secure AI for Infrastructure** | Resilience against cyber-attacks and adversarial scenarios in safety-critical systems |

---

## ğŸ“š Selected Publications {#publications}

::: {.panel-tabset}

### ğŸ“ Journal Papers

1. **Kundan Kumar**, Gelli Ravikumar  
**Physics-based Deep Reinforcement Learning for Grid-Resilient Volt-VAR Control** *(Under Review)*  
*IEEE Transactions on Smart Grid, 2025*  
<span style="display:inline-flex; gap:4px;">
<a class="btn btn-primary btn-sm" href="https://arxiv.org/abs/2202.13541">Paper</a>
<a class="btn btn-success btn-sm" href="#">Code</a>
<a class="btn btn-info btn-sm" href="#">Poster</a>
</span>

---

### ğŸ¤ Conference Papers

1. **Kundan Kumar**, Gelli Ravikumar  
**Transfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids**  
*IEEE PES Grid Edge Technologies Conference & Exposition, 2025*  
<span style="display:inline-flex; gap:4px;">
<a class="btn btn-primary btn-sm" href="https://arxiv.org/abs/2202.13541">Paper</a>
<a class="btn btn-success btn-sm" href="#">Code</a>
<a class="btn btn-info btn-sm" href="#">Poster</a>
</span>

2. **Kundan Kumar**, Aditya Akilesh Mantha, Gelli Ravikumar  
**Bayesian Optimization for Deep Reinforcement Learning in Robust Volt-Var Control**  
*IEEE PES General Meeting, 2024*  
<span style="display:inline-flex; gap:4px;">
<a class="btn btn-primary btn-sm" href="https://arxiv.org/abs/2202.13541">Paper</a>
<a class="btn btn-success btn-sm" href="#">Code</a>
<a class="btn btn-info btn-sm" href="#">Poster</a>
</span>

3. **Kundan Kumar**, Gelli Ravikumar  
**Deep RL-based Volt-VAR Control and Attack Resiliency for DER-integrated Distribution Grids**  
*IEEE ISGT, 2024*  
<span style="display:inline-flex; gap:4px;">
<a class="btn btn-primary btn-sm" href="https://ieeexplore.ieee.org/document/10454163">Paper</a>
<a class="btn btn-success btn-sm" href="#">Code</a>
<a class="btn btn-info btn-sm" href="#">Poster</a>
</span>

4. JK Francis, C Kumar, J Herrera-Gerena, **Kundan Kumar**, MJ Darr  
**Deep Learning and Pattern-based Methodology for Multivariable Sensor Data Regression**  
*IEEE ICMLA, 2022*  
<span style="display:inline-flex; gap:4px;">
<a class="btn btn-primary btn-sm" href="https://ieeexplore.ieee.org/document/10069730">Paper</a>
<a class="btn btn-success btn-sm" href="#">Code</a>
<a class="btn btn-info btn-sm" href="#">Poster</a>
</span>

5. Kin Gwn Lore, Nicholas Sweet, **Kundan Kumar**, N Ahmed, S Sarkar  
**Deep Value of Information Estimators for Collaborative Human-Machine Information Gathering**  
*ACM/IEEE ICCPS, 2016*  
<span style="display:inline-flex; gap:4px;">
<a class="btn btn-primary btn-sm" href="https://arxiv.org/abs/1512.07592">Paper</a>
<a class="btn btn-success btn-sm" href="#">Code</a>
<a class="btn btn-info btn-sm" href="#">Poster</a>
</span>

:::

---

## ğŸ§ª Ongoing Projects {#ongoing-projects}

- **Federated DRL for Cyber-Resilient Volt-VAR Optimization**  
  Exploring decentralized, communication-efficient coordination among DERs using LSTM-enhanced PPO agents.

- **One-Shot Policy Transfer with Physics Priors**  
  Training grid agents in simpler environments and adapting to complex grids (IEEE 123-bus, 8500-node) in few iterations.

- **LLM-Guided Autonomous Planning for Smart Buildings**  
  Integrating OpenAI and Claude with CityLearn to convert user prompts into interpretable policy instructions.

