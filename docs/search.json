[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kundan Kumar",
    "section": "",
    "text": "Email\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     GitHub\n  \n  \n    \n     YouTube\n  \n  \n    \n     Substack\n  \n  \n    \n     Scholar\n  \n\n  \n  \nHi! I‚Äôm Kundan Kumar, a Ph.D.¬†candidate in Computer Science at Iowa State University. My research focuses on creating intelligent and adaptable AI systems for next-generation cyber-physical infrastructure, integrating deep reinforcement learning (DRL), multi-agent systems, large language models (LLMs), and computer vision.\nI develop safety-critical DRL frameworks that incorporate domain knowledge and uncertainty, enabling reliable decision-making in complex environments. Recent projects include exploring transfer learning and enhancing adversarial resilience across systems. I also create LLM-integrated simulation frameworks for autonomous systems, combining perception, trajectory planning, and natural language reasoning.\nOutside of research, I share insights on Substack and YouTube. I enjoy cooking and ice skating üõº in my free time.\n\n\n\n\n\n\nOther Research Interests\n\n\n\n\n  \n    \n      LLM Reasoning & Agents\n      Agentic workflows (LangChain/LangGraph), tool-use, memory, retrieval, planning & reflection loops for robust multi-step reasoning.\n    \n  \n\n\n  \n    \n      Statistical ML\n      Uncertainty quantification, probabilistic modeling, and data-driven inference in dynamic environments.\n    \n  \n\n\n  \n    Autonomous Perception & Control\n    Vision-based perception (detection, segmentation, sensor fusion) integrated with learning-based control and trajectory planning for autonomous systems.\n  \n\n\n\n\n\n\nExplore My Work\n\n\n\n\n  \n    Blogs\n    \n      \n\n\n\n\n\n\n\nSelf-Attention Mechanism\n\n\n\nOct 21, 2025\n\n\n\n\n\n\nNo matching items\n\n    \n    See all ‚Üí\n  \n\n  \n    Talks\n    \n      \n\n\n\n\n\n\n\n\n\nScaling Smart Grids with Transfer Learning and DRL\n\n\n\nJul 16, 2025\n\n\n\n\n\n\nNo matching items\n\n    \n    See all ‚Üí\n  \n\n  \n    Publications\n    \n      \n\n\n\n\n\n\n\nBayesian-Optimized Bidirectional Long-Short-Term Memory network for Wind Power Forecasting with Uncertainty Quantification\n\n\n\n\n\nyear\n\n\n2025\n\n\n\n\n\n\n\n\nNo matching items\n\n    \n    See all ‚Üí\n  \n\n  \n    Projects\n    \n      \n\n\n\n\n\n\n\n\n\nAI-Powered Patient Education System\n\n\n\n\n\nNo matching items\n\n    \n    See all ‚Üí\n  \n\n\n\n\n\nNews Highlights\n\n  \n    [Sep 2025]\n    \n      Our paper on Bayesian-Optimized Bidirectional Long-Short-Term Memory network for Wind Power Forecasting with Uncertainty Quantification has been accepted to Journal on Electric Power Systems Research 2026.\n    \n  \n  \n  \n    [Jul 2025]\n    \n      Selected for the Cohere Machine Learning Summer School, hosted by Cohere Labs.\n    \n  \n\n  \n    [Mar 2025]\n    \n      Our paper on Advanced Semi-Supervised Learning with Uncertainty Estimation for Phase Identification in Distribution Systems has been accepted to Conference on IEEE PES General Meeting 2025."
  },
  {
    "objectID": "llm_grid_planner.html",
    "href": "llm_grid_planner.html",
    "title": "LLM-Driven Grid Planner",
    "section": "",
    "text": "Code \nThe LLM-Driven Grid Planner demonstrates how Large Language Models (LLMs) can serve as adaptive reasoning agents in smart grid management.\nIt integrates natural-language-guided reinforcement learning (RL) for real-time grid optimization, enabling interpretable and human-aligned decision support for operators.\n\n\nFramework\nTraditional grid control systems rely on predefined rule-based logic or black-box deep RL agents.\nIn contrast, this framework introduces a language-driven layer, allowing system operators to provide high-level natural-language goals, which the LLM translates into structured RL objectives or safety constraints.\nThis synergy creates an interpretable control loop, where human intentions, grid dynamics, and agent behavior are aligned through continuous dialogue and reasoning.\n\n\n\nCore Components\n\nLLM Planner: Parses operator input and converts it into structured optimization or control policies.\n\nRL Agent: Learns to execute the translated goals using algorithms like PPO, DDPG, or SAC.\n\nSmart Grid Environment: Simulates volt-VAR, power flow, and frequency management scenarios.\n\nExplainability Layer: Generates step-by-step rationales behind control decisions for improved trust and transparency.\n\n\n\n\nObjectives\n\nEnable human-in-the-loop grid management using natural language.\n\nImprove safety and interpretability in reinforcement learning decisions.\n\nSupport scalable grid optimization through AI-assisted planning and control.\n\n\n\n\nBroader Impact\nThe LLM-Driven Grid Planner exemplifies a step toward explainable, trustworthy, and interactive AI for smart infrastructure.\nBy merging language reasoning with reinforcement learning, it establishes a foundation for next-generation AI-assisted energy systems that are safer, transparent, and easier to govern."
  },
  {
    "objectID": "robo/robo_2/index.html",
    "href": "robo/robo_2/index.html",
    "title": "AI-Powered Patient Education System",
    "section": "",
    "text": "ggehr (read: gg E-H-R) stands for ggplot2 extension for EHR data, which provides a set of tools to facilitate EHR (Electronic Health Records) visualization.\nggehr package helps you make visualize EHR data, so that you can\n\nhave an overview of the mixed type information related to a patient;\nvisually identify the errors in data recording.\n\nLearn more about ggehr"
  },
  {
    "objectID": "robo/robo10.html",
    "href": "robo/robo10.html",
    "title": "Motion Prediction and Detection for Autonomous Vehicles",
    "section": "",
    "text": "Google Colab  YOLOv5 Code  PyTorch Hub \nInspired by other open-source deep learning projects such as YOLO, ResNet, and Code, this project demonstrates object detection and motion prediction for autonomous vehicles using the Kaggle Lyft motion prediction dataset. We use YOLOv5 for real-time object detection and ResNet-50 for motion trajectory prediction."
  },
  {
    "objectID": "robo/robo_3/index.html",
    "href": "robo/robo_3/index.html",
    "title": "Multi-Agent Travel Assistant System",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "robo/robo_3/index.html#norwegian-surveillance-system-for-excess-mortality",
    "href": "robo/robo_3/index.html#norwegian-surveillance-system-for-excess-mortality",
    "title": "Multi-Agent Travel Assistant System",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "robo/robo_3/index.html#r-packages-for-mortality-surveillance",
    "href": "robo/robo_3/index.html#r-packages-for-mortality-surveillance",
    "title": "Multi-Agent Travel Assistant System",
    "section": "R packages for mortality surveillance",
    "text": "R packages for mortality surveillance\n(continue‚Ä¶)\n\nnowcast\nsplalert\nmortanor"
  },
  {
    "objectID": "robo/robo_3/index.html#collaboration-with-cause-of-death-registry",
    "href": "robo/robo_3/index.html#collaboration-with-cause-of-death-registry",
    "title": "Multi-Agent Travel Assistant System",
    "section": "Collaboration with Cause of Death Registry",
    "text": "Collaboration with Cause of Death Registry"
  },
  {
    "objectID": "robo/robo9.html",
    "href": "robo/robo9.html",
    "title": "P2P File Sharing Protocol",
    "section": "",
    "text": "App  Code \nThe Washington State Department of Agriculture developed WaCSE for the Washington State Conservation Commission to use in the Sustainable Farms and Fields (SFF) program. Intended users are the Conservation Commission, conservation districts, growers, and anyone interested in reducing agricultural greenhouse gas (GHG) emissions. This interactive tool estimates the reduction of GHG emissions from different conservation practices across Washington‚Äôs diverse counties."
  },
  {
    "objectID": "llms/llms9.html",
    "href": "llms/llms9.html",
    "title": "Motion Prediction and Detection for Autonomous Vehicles",
    "section": "",
    "text": "Google Colab  YOLOv5 Code  PyTorch Hub \nInspired by other open-source deep learning projects such as YOLO, ResNet, and Code, this project demonstrates object detection and motion prediction for autonomous vehicles using the Kaggle Lyft motion prediction dataset. We use YOLOv5 for real-time object detection and ResNet-50 for motion trajectory prediction."
  },
  {
    "objectID": "llms/llms6/index.html",
    "href": "llms/llms6/index.html",
    "title": "Survival Of Ventilated and Control Flies",
    "section": "",
    "text": "{pkgdown} site  Code  CRAN \nInspired by other branding R packages such as Code, Code, and Code, washi provides color palettes and themes consistent with Washington Soil Health Initiative (WaSHI) branding. This package is to be used only by direct collaborators within WaSHI, though you are welcome to adapt the package to suit your own organization‚Äôs branding."
  },
  {
    "objectID": "llms/llms4/index.html",
    "href": "llms/llms4/index.html",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "llms/llms4/index.html#norwegian-surveillance-system-for-excess-mortality",
    "href": "llms/llms4/index.html#norwegian-surveillance-system-for-excess-mortality",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "llms/llms4/index.html#r-packages-for-mortality-surveillance",
    "href": "llms/llms4/index.html#r-packages-for-mortality-surveillance",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "R packages for mortality surveillance",
    "text": "R packages for mortality surveillance\n(continue‚Ä¶)\n\nnowcast\nsplalert\nmortanor"
  },
  {
    "objectID": "llms/llms4/index.html#collaboration-with-cause-of-death-registry",
    "href": "llms/llms4/index.html#collaboration-with-cause-of-death-registry",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "Collaboration with Cause of Death Registry",
    "text": "Collaboration with Cause of Death Registry"
  },
  {
    "objectID": "llms/llms2/index.html",
    "href": "llms/llms2/index.html",
    "title": "Multi-Agent Travel Assistant System",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "llms/llms2/index.html#norwegian-surveillance-system-for-excess-mortality",
    "href": "llms/llms2/index.html#norwegian-surveillance-system-for-excess-mortality",
    "title": "Multi-Agent Travel Assistant System",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "llms/llms2/index.html#r-packages-for-mortality-surveillance",
    "href": "llms/llms2/index.html#r-packages-for-mortality-surveillance",
    "title": "Multi-Agent Travel Assistant System",
    "section": "R packages for mortality surveillance",
    "text": "R packages for mortality surveillance\n(continue‚Ä¶)\n\nnowcast\nsplalert\nmortanor"
  },
  {
    "objectID": "llms/llms2/index.html#collaboration-with-cause-of-death-registry",
    "href": "llms/llms2/index.html#collaboration-with-cause-of-death-registry",
    "title": "Multi-Agent Travel Assistant System",
    "section": "Collaboration with Cause of Death Registry",
    "text": "Collaboration with Cause of Death Registry"
  },
  {
    "objectID": "llms/llms7.html",
    "href": "llms/llms7.html",
    "title": "Prompt Injection Attacks on LLM Medical Diagnosis by Symptom Elaboration",
    "section": "",
    "text": "Code \nThe goal of orcas is to scrape orca sighting data from the web and visualize it in maps and tables.\nI‚Äôve always had an affinity for the Southern Resident Killer Whales in the Salish Sea. The Center for Whale Research does a lot of really fascinating and important work monitoring their population. They post their survey data on their website; each encounter with the orcas is a separate webpage. I was both curious and intimidated by web scraping so I decided this would make a great case study and personal project. I also learned how to use custom icons in leaflet maps! üêã"
  },
  {
    "objectID": "dev/short_bio.html",
    "href": "dev/short_bio.html",
    "title": "Kundan Kumar",
    "section": "",
    "text": "i! I‚Äôm Kundan Kumar, a Ph.D.¬†candidate and researcher focused on building intelligent, secure, and adaptable AI systems for next-generation cyber-physical infrastructure. My work bridges deep reinforcement learning (DRL), multi-agent systems, large language models (LLMs), safe and explainable AI, and computer vision, with real-world applications in smart grids, autonomous vehicles, and critical infrastructure.\nMy Ph.D.¬†research centers on physics-informed and safety-critical DRL frameworks that embed domain knowledge, safety constraints, and uncertainty into the learning process‚Äîenabling agents to make robust and interpretable decisions in dynamic, complex environments. My research within DRL focuses on techniques such as transfer learning, uncertainty quantification, and adversarial resilience to improve generalization, safety, and reliability across diverse tasks and environments.\nI also develop LLM-integrated simulation frameworks for robotics and autonomous systems, combining vision-based perception, trajectory planning, and natural language reasoning to support high-level control and human-AI collaboration.\nBeyond research, I enjoy sharing my insights through educational content on Substack and YouTube. Outside of work, I love cooking and Ice skating üõº."
  },
  {
    "objectID": "teaching/coms4170/index.html",
    "href": "teaching/coms4170/index.html",
    "title": "COMS 4170: Software Testing",
    "section": "",
    "text": "COMS 4170 is a rigorous course that delves into advanced methods of testing and quality assurance for software at both the undergraduate and graduate levels the Iowa State University. It is taught by Professor Myra Cohen."
  },
  {
    "objectID": "teaching/coms4170/index.html#software-testing",
    "href": "teaching/coms4170/index.html#software-testing",
    "title": "COMS 4170: Software Testing",
    "section": "",
    "text": "COMS 4170 is a rigorous course that delves into advanced methods of testing and quality assurance for software at both the undergraduate and graduate levels the Iowa State University. It is taught by Professor Myra Cohen."
  },
  {
    "objectID": "teaching/coms1130/index.html",
    "href": "teaching/coms1130/index.html",
    "title": "COMS 1130: Introduction to Spreadsheets and Databases",
    "section": "",
    "text": "Credits: 3\nInstitution: Iowa State University\nFormat: In-Person Course (Offered Fall & Spring)\nCOMS 1130 is a 3-credit undergraduate course that teaches essential skills in Microsoft Excel and Microsoft Access, emphasizing hands-on, real-world applications of data management and analysis.\n\n\n\nThis course introduces students to data organization, analysis, and decision-making using Microsoft Excel and Access. Through a project-based approach, students learn to create, analyze, and manage data models for business, engineering, and academic applications."
  },
  {
    "objectID": "teaching/coms1130/index.html#coms-1130-introduction-to-spreadsheets-and-databases",
    "href": "teaching/coms1130/index.html#coms-1130-introduction-to-spreadsheets-and-databases",
    "title": "COMS 1130: Introduction to Spreadsheets and Databases",
    "section": "",
    "text": "Credits: 3\nInstitution: Iowa State University\nFormat: In-Person Course (Offered Fall & Spring)\nCOMS 1130 is a 3-credit undergraduate course that teaches essential skills in Microsoft Excel and Microsoft Access, emphasizing hands-on, real-world applications of data management and analysis.\n\n\n\nThis course introduces students to data organization, analysis, and decision-making using Microsoft Excel and Access. Through a project-based approach, students learn to create, analyze, and manage data models for business, engineering, and academic applications."
  },
  {
    "objectID": "teaching/coms3190/index.html",
    "href": "teaching/coms3190/index.html",
    "title": "COMS 3190: User Interface Design",
    "section": "",
    "text": "COMS 3190 introduces students to the principles and practices of user interface (UI) and user experience (UX) design through a balance of theory and extensive hands-on development.\nThe course covers human-computer interaction (HCI) concepts, front-end and back-end technologies, and the use of modern frameworks and APIs for developing web and Windows-based user interfaces.\nStudents gain experience with:\n- UI design principles\n- HTML, CSS, and JavaScript\n- React, Node.js, and Express\n- Databases (MongoDB and MySQL)\n- UML modeling and event-driven architecture\n- Web and desktop-based client/server applications\n\n\n\nFigure: Design-to-development process for building interactive and user-centered applications.\n\n\n\n\n\n\nComputer Science Graduate Teaching Assistant (Fall 2024)\n\nAs a Teaching Assistant for COMS 3190, I supported over 100 students in learning full-stack web development principles within the context of UI/UX design. My responsibilities included:\n\nTechnical Instruction: Led lab sessions and live demos on HTML, CSS, JavaScript, React, and Node.js, focusing on responsive, accessible design.\n\nProject Mentorship: Guided teams through semester-long UI/UX projects, helping with front-end development, API design, and database integration.\n\nDesign & Modeling Support: Assisted students in using UML for system modeling and behavioral analysis, including use case and interaction diagrams.\n\nTesting Assistance: Supported unit testing and UI testing in JavaScript and assisted with debugging web applications.\n\nCode Review & Feedback: Evaluated submissions and provided feedback on usability, design consistency, and code efficiency.\n\nOffice Hours: Offered individualized technical support and design mentoring to strengthen students‚Äô understanding of UI/UX best practices."
  },
  {
    "objectID": "teaching/coms3190/index.html#coms-3190-user-interface-design",
    "href": "teaching/coms3190/index.html#coms-3190-user-interface-design",
    "title": "COMS 3190: User Interface Design",
    "section": "",
    "text": "COMS 3190 introduces students to the principles and practices of user interface (UI) and user experience (UX) design through a balance of theory and extensive hands-on development.\nThe course covers human-computer interaction (HCI) concepts, front-end and back-end technologies, and the use of modern frameworks and APIs for developing web and Windows-based user interfaces.\nStudents gain experience with:\n- UI design principles\n- HTML, CSS, and JavaScript\n- React, Node.js, and Express\n- Databases (MongoDB and MySQL)\n- UML modeling and event-driven architecture\n- Web and desktop-based client/server applications\n\n\n\nFigure: Design-to-development process for building interactive and user-centered applications.\n\n\n\n\n\n\nComputer Science Graduate Teaching Assistant (Fall 2024)\n\nAs a Teaching Assistant for COMS 3190, I supported over 100 students in learning full-stack web development principles within the context of UI/UX design. My responsibilities included:\n\nTechnical Instruction: Led lab sessions and live demos on HTML, CSS, JavaScript, React, and Node.js, focusing on responsive, accessible design.\n\nProject Mentorship: Guided teams through semester-long UI/UX projects, helping with front-end development, API design, and database integration.\n\nDesign & Modeling Support: Assisted students in using UML for system modeling and behavioral analysis, including use case and interaction diagrams.\n\nTesting Assistance: Supported unit testing and UI testing in JavaScript and assisted with debugging web applications.\n\nCode Review & Feedback: Evaluated submissions and provided feedback on usability, design consistency, and code efficiency.\n\nOffice Hours: Offered individualized technical support and design mentoring to strengthen students‚Äô understanding of UI/UX best practices."
  },
  {
    "objectID": "teaching/teaching.html",
    "href": "teaching/teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "As a Computer Science Graduate Teaching Assistant at Iowa State University with over five years of teaching experience, I focus on creating an comprehensive, engaging, and challenging learning environment that meets the different needs of students. My teaching approach emphasizes connecting theory with real-world practice, helping students turn basic computer science ideas into practical skills. I encourage hands-on learning through software development, user interface design, and database projects that build both technical skills and problem-solving abilities. By combining project-based tasks with personalized guidance, I aim to prepare students to face current challenges in the tech field with confidence and creativity. My goal is to help students be ready for jobs in technology and able to think of new ideas."
  },
  {
    "objectID": "teaching/teaching.html#coms1130",
    "href": "teaching/teaching.html#coms1130",
    "title": "Teaching",
    "section": "Spreadsheets and Databases",
    "text": "Spreadsheets and Databases"
  },
  {
    "objectID": "teaching/teaching.html#coms-1130-spreadsheets-and-databases",
    "href": "teaching/teaching.html#coms-1130-spreadsheets-and-databases",
    "title": "Teaching",
    "section": "COMS 1130 ‚Äì Spreadsheets and Databases",
    "text": "COMS 1130 ‚Äì Spreadsheets and Databases\n\n\n\n\n\nFall 2016\nThis course is a foundational course focused on using tools such as Microsoft Excel and Microsoft Access for effective data organization, analysis, and reporting. Students develop proficiency in applying formulas, creating pivot tables, designing queries, and building forms and visual analyses to support practical business and data-driven decision-making."
  },
  {
    "objectID": "teaching/teaching.html#coms3090",
    "href": "teaching/teaching.html#coms3090",
    "title": "Teaching",
    "section": "Software Development Practices",
    "text": "Software Development Practices"
  },
  {
    "objectID": "teaching/teaching.html#coms-3090-software-development-practices",
    "href": "teaching/teaching.html#coms-3090-software-development-practices",
    "title": "Teaching",
    "section": "COMS 3090 ‚Äì Software Development Practices",
    "text": "COMS 3090 ‚Äì Software Development Practices\n\n\n\n\n\nFall 2022, ¬† Spring 2023, ¬† Spring 2024, ¬† Fall 2025\nThis course is a practical, hands-on program that primarily deals with modern software development standards. It mainly focuses on Git, Agile methodologies, code reviews, unit-testing, and continuous integration and deployment (CI/CD). Students collaborate in team-based projects that replicate development workflows of the real world. These projects put a particular emphasis on collaboration, documentation, and iterative improvement. Finally, the course is about comprehensive Android application and game development, which includes design, implementation, testing, and deployment."
  },
  {
    "objectID": "teaching/teaching.html#coms3190",
    "href": "teaching/teaching.html#coms3190",
    "title": "Teaching",
    "section": "User Interface Design",
    "text": "User Interface Design"
  },
  {
    "objectID": "teaching/teaching.html#coms-3190-user-interface-design",
    "href": "teaching/teaching.html#coms-3190-user-interface-design",
    "title": "Teaching",
    "section": "COMS 3190 ‚Äì User Interface Design",
    "text": "COMS 3190 ‚Äì User Interface Design\n\n\n\n\n\nFall 2023\nThis course explores the principles of designing user-friendly and efficient interfaces. It integrates hardware and data-driven UI practices, incorporating Raspberry Pi for Internet of Things (IoT) applications and Node.js for front-end visualization and interactive design."
  },
  {
    "objectID": "teaching/teaching.html#coms3620",
    "href": "teaching/teaching.html#coms3620",
    "title": "Teaching",
    "section": "Object-Oriented Analysis and Design",
    "text": "Object-Oriented Analysis and Design"
  },
  {
    "objectID": "teaching/teaching.html#coms-3620-object-oriented-analysis-and-design",
    "href": "teaching/teaching.html#coms-3620-object-oriented-analysis-and-design",
    "title": "Teaching",
    "section": "COMS 3620 ‚Äì Object-Oriented Analysis and Design",
    "text": "COMS 3620 ‚Äì Object-Oriented Analysis and Design\n\n\n\n\n\nFall 2020, ¬† Spring 2021, ¬† Fall 2021, ¬† Fall 2024\nThis course teaches the modeling and design of software systems using object-oriented principles. It emphasizes the use of UML diagrams, design patterns, and Java implementation to develop modular, maintainable, and scalable software solutions."
  },
  {
    "objectID": "teaching/teaching.html#coms3630",
    "href": "teaching/teaching.html#coms3630",
    "title": "Teaching",
    "section": "Database Management Systems",
    "text": "Database Management Systems"
  },
  {
    "objectID": "teaching/teaching.html#coms-3630-database-management-systems",
    "href": "teaching/teaching.html#coms-3630-database-management-systems",
    "title": "Teaching",
    "section": "COMS 3630 ‚Äì Database Management Systems",
    "text": "COMS 3630 ‚Äì Database Management Systems\n\n\n\n\n\nSpring 2022\nThis course covers the fundamentals of database architecture, data modeling, and Structured Query Language (SQL). Students gain hands-on experience with relational database systems while exploring key concepts such as indexing, transactions, normalization, and comprehensive database design."
  },
  {
    "objectID": "teaching/teaching.html#coms4170",
    "href": "teaching/teaching.html#coms4170",
    "title": "Teaching",
    "section": "Software Testing",
    "text": "Software Testing"
  },
  {
    "objectID": "teaching/teaching.html#coms-4170-software-testing",
    "href": "teaching/teaching.html#coms-4170-software-testing",
    "title": "Teaching",
    "section": "COMS 4170 ‚Äì Software Testing",
    "text": "COMS 4170 ‚Äì Software Testing\n\n\n\n\n\nSpring 2025\nThis course focuses on the principles and practices of software verification and validation. Students learn to design and execute effective test cases, utilize debugging tools, and implement automation frameworks to ensure software quality, reliability, and maintainability."
  },
  {
    "objectID": "teaching/teaching.html#future-goals",
    "href": "teaching/teaching.html#future-goals",
    "title": "Teaching",
    "section": "Future Goals",
    "text": "Future Goals\nI am dedicated to the continuous development of my teaching methods and curriculum design. My objectives consist of:\n\nIncorporating new AI and software development tools as tools for student learning.\nCreating interactive, experiential, and project-based learning environments that encourage students to be actively involved.\nBecoming a resource to the community of computer science education through the innovation of curricula, research, and guidance of other educators.\nBroadening the students‚Äô access to the computing field where they can tackle the challenges of the real world by using their theoretical knowledge.\n\nEmail me if you want to collaborate or learn more about my teaching and research initiatives."
  },
  {
    "objectID": "rpkg/carla/index.html",
    "href": "rpkg/carla/index.html",
    "title": "Carla",
    "section": "",
    "text": "This package provides discovery."
  },
  {
    "objectID": "rpkg/publications.html",
    "href": "rpkg/publications.html",
    "title": "Kundan Kumar",
    "section": "",
    "text": "üìù Journal Papersüé§ Conference Papersüé§ Conference Papers\n\n\n\nKundan Kumar, Gelli Ravikumar\nPhysics-based Deep Reinforcement Learning for Grid-Resilient Volt-VAR Control (Under Review)\nIEEE Transactions on Smart Grid, 2025\n Paper Code Poster \n\n\n\n\n\nPage 1Page 2\n\n\n\nKundan Kumar, Kumar Utkarsh, Wang Jiyu and Padullaparti Harsha Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems\n\nIEEE PES General Meeting, 2025\n Paper Code Poster \n\nKundan Kumar, Gelli Ravikumar\nTransfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids\nIEEE PES Grid Edge Technologies Conference & Exposition, 2025\n Paper Code Poster \nKundan Kumar, Aditya Akilesh Mantha, Gelli Ravikumar\nBayesian Optimization for Deep Reinforcement Learning in Robust Volt-Var Control\nIEEE PES General Meeting, 2024\n Paper Code Poster \nKundan Kumar, Gelli Ravikumar\nDeep RL-based Volt-VAR Control and Attack Resiliency for DER-integrated Distribution Grids\nIEEE ISGT, 2024\n Paper Code Poster \n\n\n\n\nJK Francis, C Kumar, J Herrera-Gerena, Kundan Kumar, MJ Darr\nDeep Learning and Pattern-based Methodology for Multivariable Sensor Data Regression\nIEEE ICMLA, 2022\n Paper Code Poster \nKin Gwn Lore, Nicholas Sweet, Kundan Kumar, N Ahmed, S Sarkar\nDeep Value of Information Estimators for Collaborative Human-Machine Information Gathering\nACM/IEEE ICCPS, 2016\n Paper Code Poster \n\n\n\n\n\n\n\n\n\nKundan Kumar, Gelli Ravikumar\nTransfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids\nIEEE PES Grid Edge Technologies Conference & Exposition, 2025\n Paper Code Poster \nKundan Kumar, Aditya Akilesh Mantha, Gelli Ravikumar\nBayesian Optimization for Deep Reinforcement Learning in Robust Volt-Var Control\nIEEE PES General Meeting, 2024\n Paper Code Poster \nKundan Kumar, Gelli Ravikumar\nDeep RL-based Volt-VAR Control and Attack Resiliency for DER-integrated Distribution Grids\nIEEE ISGT, 2024\n Paper Code Poster \n\n\n1 2\n\n\n\n\n\n\nJK Francis, C Kumar, J Herrera-Gerena, Kundan Kumar, MJ Darr\nDeep Learning and Pattern-based Methodology for Multivariable Sensor Data Regression\nIEEE ICMLA, 2022\n Paper Code Poster \nKin Gwn Lore, Nicholas Sweet, Kundan Kumar, N Ahmed, S Sarkar\nDeep Value of Information Estimators for Collaborative Human-Machine Information Gathering\nACM/IEEE ICCPS, 2016\n Paper Code Poster \n\n\n1 2"
  },
  {
    "objectID": "rpkg/publications.html#selected-publications",
    "href": "rpkg/publications.html#selected-publications",
    "title": "Kundan Kumar",
    "section": "",
    "text": "üìù Journal Papersüé§ Conference Papersüé§ Conference Papers\n\n\n\nKundan Kumar, Gelli Ravikumar\nPhysics-based Deep Reinforcement Learning for Grid-Resilient Volt-VAR Control (Under Review)\nIEEE Transactions on Smart Grid, 2025\n Paper Code Poster \n\n\n\n\n\nPage 1Page 2\n\n\n\nKundan Kumar, Kumar Utkarsh, Wang Jiyu and Padullaparti Harsha Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems\n\nIEEE PES General Meeting, 2025\n Paper Code Poster \n\nKundan Kumar, Gelli Ravikumar\nTransfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids\nIEEE PES Grid Edge Technologies Conference & Exposition, 2025\n Paper Code Poster \nKundan Kumar, Aditya Akilesh Mantha, Gelli Ravikumar\nBayesian Optimization for Deep Reinforcement Learning in Robust Volt-Var Control\nIEEE PES General Meeting, 2024\n Paper Code Poster \nKundan Kumar, Gelli Ravikumar\nDeep RL-based Volt-VAR Control and Attack Resiliency for DER-integrated Distribution Grids\nIEEE ISGT, 2024\n Paper Code Poster \n\n\n\n\nJK Francis, C Kumar, J Herrera-Gerena, Kundan Kumar, MJ Darr\nDeep Learning and Pattern-based Methodology for Multivariable Sensor Data Regression\nIEEE ICMLA, 2022\n Paper Code Poster \nKin Gwn Lore, Nicholas Sweet, Kundan Kumar, N Ahmed, S Sarkar\nDeep Value of Information Estimators for Collaborative Human-Machine Information Gathering\nACM/IEEE ICCPS, 2016\n Paper Code Poster \n\n\n\n\n\n\n\n\n\nKundan Kumar, Gelli Ravikumar\nTransfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids\nIEEE PES Grid Edge Technologies Conference & Exposition, 2025\n Paper Code Poster \nKundan Kumar, Aditya Akilesh Mantha, Gelli Ravikumar\nBayesian Optimization for Deep Reinforcement Learning in Robust Volt-Var Control\nIEEE PES General Meeting, 2024\n Paper Code Poster \nKundan Kumar, Gelli Ravikumar\nDeep RL-based Volt-VAR Control and Attack Resiliency for DER-integrated Distribution Grids\nIEEE ISGT, 2024\n Paper Code Poster \n\n\n1 2\n\n\n\n\n\n\nJK Francis, C Kumar, J Herrera-Gerena, Kundan Kumar, MJ Darr\nDeep Learning and Pattern-based Methodology for Multivariable Sensor Data Regression\nIEEE ICMLA, 2022\n Paper Code Poster \nKin Gwn Lore, Nicholas Sweet, Kundan Kumar, N Ahmed, S Sarkar\nDeep Value of Information Estimators for Collaborative Human-Machine Information Gathering\nACM/IEEE ICCPS, 2016\n Paper Code Poster \n\n\n1 2"
  },
  {
    "objectID": "rpkg/physics-informed-actor-critic/index.html",
    "href": "rpkg/physics-informed-actor-critic/index.html",
    "title": "Physics Informed Actor Critic",
    "section": "",
    "text": "https://github.com/"
  },
  {
    "objectID": "rpkg/research.html",
    "href": "rpkg/research.html",
    "title": "Research",
    "section": "",
    "text": "I seek to create safe, interpretable, and adaptive AI systems for real-world cyber-physical environments that operate with uncertainty, constraints, and adversarial settings. My research merges machine learning, optimization, and control theory, focusing on safety, robustness, and generalization.\nMy research revolves around the following pillars:\n\nSafe & Trustworthy Reinforcement Learning: Designing agents robust to adversarial attacks, resilient to distributional shifts, and allowing for safe exploration.\nPhysics-informed Deep Reinforcement Learning (DRL): Embedding physical laws and constraints in the learning frameworks for stability, interpretability, and faster convergence.\nProbabilistic & Bayesian Modeling: Probabilistic & Bayesian Modeling: Capturing both epistemic and aleatoric uncertainty for trustable control under high stakes, partially observable systems.\nLarge Language Models (LLMs) for autonomous reasoning: Using LLMs for better planning, explainability, and human-AI collaboration in control systems.\nVision-based simulation environments: Using platforms such as CARLA and CityLearn to train agents in multimodal, visually rich, and interactive environments.\n\nThrough the tight coupling of domain knowledge into learning frameworks, I hope to enable resilient, generalizable, and safe AI for critical applications in areas such as smart grids, autonomous systems, and intelligent infrastructure."
  },
  {
    "objectID": "rpkg/research.html#research-vision",
    "href": "rpkg/research.html#research-vision",
    "title": "Research",
    "section": "",
    "text": "I seek to create safe, interpretable, and adaptive AI systems for real-world cyber-physical environments that operate with uncertainty, constraints, and adversarial settings. My research merges machine learning, optimization, and control theory, focusing on safety, robustness, and generalization.\nMy research revolves around the following pillars:\n\nSafe & Trustworthy Reinforcement Learning: Designing agents robust to adversarial attacks, resilient to distributional shifts, and allowing for safe exploration.\nPhysics-informed Deep Reinforcement Learning (DRL): Embedding physical laws and constraints in the learning frameworks for stability, interpretability, and faster convergence.\nProbabilistic & Bayesian Modeling: Probabilistic & Bayesian Modeling: Capturing both epistemic and aleatoric uncertainty for trustable control under high stakes, partially observable systems.\nLarge Language Models (LLMs) for autonomous reasoning: Using LLMs for better planning, explainability, and human-AI collaboration in control systems.\nVision-based simulation environments: Using platforms such as CARLA and CityLearn to train agents in multimodal, visually rich, and interactive environments.\n\nThrough the tight coupling of domain knowledge into learning frameworks, I hope to enable resilient, generalizable, and safe AI for critical applications in areas such as smart grids, autonomous systems, and intelligent infrastructure."
  },
  {
    "objectID": "rpkg/research.html#research-focus",
    "href": "rpkg/research.html#research-focus",
    "title": "Research",
    "section": "My Research Focus Areas",
    "text": "My Research Focus Areas\n\n\n\n\n\nDRL-based Control\n\n\n   DRL for Volt-VAR Design control agents for voltage regulation and reactive power optimization in smart distribution grids.  \n   Physics-Informed Actor-Critic Embed grid physics and control limits directly into the DRL learning loop for stable and efficient decisions.  \n   Sim-to-Real Transfer Train agents in simulated OpenDSS environments and deploy them on real-time OPAL-RT setups.  \n\n\n\n\nSafe & Trustworthy RL\n\n\n   Robust & Stable Learning Develop agents that ensure system safety, robustness, and interpretability under uncertainty.  \n   Uncertainty-Aware Policies Quantify epistemic and aleatoric uncertainty in high-stakes, partially observable settings.  \n\n\n\n\nTransfer & Meta-Adaptation\n\n\n   Domain Adaptation Enable agents to generalize across grids with different topologies, dynamics, and loads.  \n   Meta-RL for Efficiency Leverage meta-reasoning to accelerate learning in low-data, high-variance scenarios.  \n\n\n\nVision-Simulation Integration\n\n\n   Perception-Control Fusion Use CARLA and AirSim to train end-to-end systems in visual RL tasks with sensors.  \n   Multi-modal Representations Combine visual, state, and contextual features for better decision-making.  \n\n\n\nLLM-Augmented Decision Systems\n\n\n\n\n   LLM-Guided Control Translate natural language into actionable policies for real-world environments."
  },
  {
    "objectID": "rpkg/research.html#application-domains",
    "href": "rpkg/research.html#application-domains",
    "title": "Research",
    "section": "Application Domains",
    "text": "Application Domains\n\n\n\nDomain\nDescription\n\n\n\n\nSmart Energy Systems\nVolt-VAR control, DER coordination, and federated DRL for power grid stability\n\n\nAutonomous Systems\nSafe navigation, adaptive planning, and control in simulation and real-world environments\n\n\nSecure AI for Infrastructure\nResilience against cyber-attacks and adversarial scenarios in safety-critical systems"
  },
  {
    "objectID": "rpkg/research.html#publications",
    "href": "rpkg/research.html#publications",
    "title": "Research",
    "section": "Publications",
    "text": "Publications\n\nJournal PapersConference Papers\n\n\n\nArif Hussian, Kundan Kumar, Gelli Ravikumar\nBayesian-optimized bidirectional long-short-term memory network for wind power forecasting with uncertainty quantification , Electric Power Systems Research, 2026\n Paper Code Poster \nKundan Kumar, Gelli Ravikumar\nPhysics-based Deep Reinforcement Learning for Grid-Resilient Volt-VAR Control (Under Review), IEEE Transactions on Smart Grid, 2025\n Paper Code Poster \n\n\n\n\n\nConference Papers\n\n\n\n\n\nKundan Kumar, Gelli Ravikumar A Multi-Objective Optimization Framework for Carbon-Aware Smart Energy Management, IEEE North American Power Symposium (NAPS), 2025  Paper Code Poster \n\n\nKundan Kumar, Kumar Utkarsh, Wang Jiyu, Padullaparti Harsha Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems, IEEE PES General Meeting, 2025  Paper Code Poster \n\n\nKundan Kumar, Gelli Ravikumar Transfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids, IEEE PES Grid Edge Technologies Conference & Exposition, 2025  Paper Code Poster \n\n\n\n\nKundan Kumar, Aditya Akilesh Mantha, Gelli Ravikumar Bayesian Optimization for Deep Reinforcement Learning in Robust Volt-Var Control, IEEE PES General Meeting, 2024  Paper Code Poster \n\n\nKundan Kumar, Gelli Ravikumar Deep RL-based Volt-VAR Control and Attack Resiliency for DER-Integrated Distribution Grids, IEEE Innovative Smart Grid Technologies (ISGT), 2024  Paper Code Poster \n\n\nJK Francis, C Kumar, J Herrera-Gerena, Kundan Kumar, MJ Darr Deep Learning and Pattern-based Methodology for Multivariable Sensor Data Regression, IEEE ICMLA, 2022  Paper Code Poster \n\n\nKin Gwn Lore, Nicholas Sweet, Kundan Kumar, N Ahmed, S Sarkar Deep Value of Information Estimators for Collaborative Human-Machine Information Gathering, ACM/IEEE ICCPS, 2016  Paper Code Poster \n\n\n\n\n\n Show More"
  },
  {
    "objectID": "rpkg/research.html#ongoing-projects",
    "href": "rpkg/research.html#ongoing-projects",
    "title": "Research",
    "section": "Ongoing Projects",
    "text": "Ongoing Projects\n\nFederated DRL for Cyber-Resilient Volt-VAR Optimization\nDecentralized, communication-efficient control using LSTM-enhanced PPO agents across distributed DERs.\nOne-Shot Policy Transfer with Physics Priors\nTrain agents on small topologies and adapt to IEEE 123-bus, 8500-node networks in a few iterations.\nLLM-Guided Autonomous Planning for Smart Buildings\nConvert user prompts to interpretable control policies using LLMs (OpenAI, Claude) in CityLearn environments."
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Journal Articles\n\n\n\nKumar, Kundan, Ravikumar Gelli, and Christopher Quinn. 2025.\n‚ÄúPhysics-Informed DRL for Smart Grids.‚Äù  IEEE Transactions on Smart Grid.  Paper Code Poster\n\n\n\n\n\n\nConference Papers\n\n\n\nKumar, Kundan, and Christopher Quinn. 2024.\n‚ÄúFederated DRL for Resilient Energy Systems.‚Äù  In Proceedings of ACM BuildSys.  Paper Code\n\n\n\n\n\n\nWorkshop Papers\n\n\n\nKumar, Kundan, and Nabila Masud. 2024.\n‚ÄúOne-Shot DRL for Low-Data Grid Settings.‚Äù  In NeurIPS Workshop on Energy Systems.  Paper Poster"
  },
  {
    "objectID": "blog/blog_20251020_self_attention_mechanism/index.html",
    "href": "blog/blog_20251020_self_attention_mechanism/index.html",
    "title": "Self-Attention Mechanism",
    "section": "",
    "text": "Two days ago (Jan 11 2023) I watched a presentation by data scientists at Roche about why they are making their clinical trials in 2023 open source with R. As someone who uses R for most of the time and has done similar works (not in pharma, but in public health surveillance and reporting: watch my talk, Code to find out what we do), I watched the presentation with great interest. Here are my notes, combined with some thoughts on open-source in the industry, public sector and academia."
  },
  {
    "objectID": "blog/blog_20251020_self_attention_mechanism/index.html#step-1-compute-attention-scores",
    "href": "blog/blog_20251020_self_attention_mechanism/index.html#step-1-compute-attention-scores",
    "title": "Self-Attention Mechanism",
    "section": "Step 1 ‚Äî Compute Attention Scores",
    "text": "Step 1 ‚Äî Compute Attention Scores\nThe similarity between a query and all keys is computed via the dot product:\n[ = Q K^ ]\nEach element ( s_{ij} ) represents how much token ( i ) attends to token ( j ).\nTo stabilize gradients, the scores are scaled by ( ):\n[ = ]"
  },
  {
    "objectID": "blog/blog_20251020_self_attention_mechanism/index.html#step-2-apply-softmax",
    "href": "blog/blog_20251020_self_attention_mechanism/index.html#step-2-apply-softmax",
    "title": "Self-Attention Mechanism",
    "section": "Step 2 ‚Äî Apply Softmax",
    "text": "Step 2 ‚Äî Apply Softmax\nWe convert scores into probabilities:\n[ A = ( ) ]\nHere, each row of ( A ) sums to 1 ‚Äî it represents the attention distribution for one token."
  },
  {
    "objectID": "blog/blog_20251020_self_attention_mechanism/index.html#step-3-weighted-sum-of-values",
    "href": "blog/blog_20251020_self_attention_mechanism/index.html#step-3-weighted-sum-of-values",
    "title": "Self-Attention Mechanism",
    "section": "Step 3 ‚Äî Weighted Sum of Values",
    "text": "Step 3 ‚Äî Weighted Sum of Values\nFinally, we multiply the attention weights ( A ) by the value matrix ( V ):\n[ = A V ]\nThis produces the contextualized representation for each token ‚Äî a weighted combination of all token values."
  },
  {
    "objectID": "blog/technotes_ml_series_20251105_class_unbalanced/index.html",
    "href": "blog/technotes_ml_series_20251105_class_unbalanced/index.html",
    "title": "How to handle class-unbalanced data?",
    "section": "",
    "text": "Class imbalance is a technique to handle the unbalanced data in the data-sets to build a reliable ML model and avoid the model for poor generalization."
  },
  {
    "objectID": "blog/technotes_ml_series_20251105_class_unbalanced/index.html#data-level-approaches-resampling-techniques",
    "href": "blog/technotes_ml_series_20251105_class_unbalanced/index.html#data-level-approaches-resampling-techniques",
    "title": "How to handle class-unbalanced data?",
    "section": "Data-Level Approaches (Resampling Techniques)",
    "text": "Data-Level Approaches (Resampling Techniques)\n\nOversampling the minority class\n\nRandom Oversampling: duplicate minority class examples until balance is reached.\nSMOTE (Synthetic Minority Over-sampling Technique): generates synthetic data points for the minority class by interpolating between nearest neighbors.\nADASYN: similar to SMOTE but focuses on generating harder-to-learn examples.\n\n\n\nUndersampling the majority class\n\nRandom Undersampling: randomly remove majority class examples.\nCluster Centroids / Tomek Links / NearMiss: more informed undersampling to preserve useful structure.\n\n\n\nHybrid methods\n\nCombine oversampling and undersampling to avoid overfitting or losing too much information.\n\nAlgorithm-Level Approaches\nClass Weights / Cost-Sensitive Learning\nAssign higher misclassification cost to minority class (many libraries like scikit-learn allow class_weight=‚Äòbalanced‚Äô).\nAnomaly Detection / One-Class Models\nTreat minority class as ‚Äúrare events‚Äù and use anomaly detection approaches.\nEnsemble Techniques\nUse Bagging/Boosting with imbalance-aware modifications (e.g., Balanced Random Forest, EasyEnsemble, RUSBoost).\nEvaluation-Level Approaches Confusion Matrix: A breakdown of predictions into a table showing correct predictions (the diagonal) and the types of incorrect predictions made (what classes incorrect predictions were assigned). Precision: A measure of a classifiers exactness. Recall: A measure of a classifiers completeness F1 Score (or F-score): A weighted average of precision and recall. Avoid accuracy as the metric (it will be misleading).\nPrefer metrics that account for imbalance:\nPrecision, Recall, F1-score\nROC-AUC, PR-AUC (especially useful with rare positives)\nMatthews Correlation Coefficient (MCC)\nBalanced Accuracy\n. Data Collection & Domain Knowledge\nGather more examples of the minority class if possible (often the best long-term solution).\nUse domain knowledge to engineer features that help separate classes better.\nActive learning: selectively label more examples from uncertain regions.\n\nAdvanced / Modern Techniques\n\nGenerative Models (GANs, VAEs): to synthesize minority samples.\nSemi-supervised or Self-supervised Learning: leverage unlabeled data to improve representation of minority class.\nFocal Loss (in deep learning): gives higher weight to hard-to-classify (often minority) samples.\nCourse link"
  },
  {
    "objectID": "blog/technotes_ml_series_20251105_class_unbalanced/index.html#principles-and-tools",
    "href": "blog/technotes_ml_series_20251105_class_unbalanced/index.html#principles-and-tools",
    "title": "How to handle class-unbalanced data?",
    "section": "Principles and tools",
    "text": "Principles and tools\nReproducibility: Git (code versioning), dependencies (renv for r package dependencies, Docker for system dependencies)\n\nClean code\nCode comments: not recommended! Better to write code in a way that does not need additional comments.\nDRY: don‚Äôt repeat yourself (principle of software development), avoid copy and paste everywhere.\nSRP: single-responsibility prinicple, a function should do one thing: either plot a chart, saves a file, changes variables etc, but not all.\nNaming conventions\n\nReserve dots (.) for S3 methods (print.patient)\nReserve CamelCase for R6 classes or package names (OurPatients)\nUse snake cases (all_patients) for function names and arguments, use verb noun pattern (plot_this())\n\n\n\nCode smells\nA function might be too large: break into smaller ones (e.g.¬†could fit in one screen)\nA function violates SRP: break into smaller ones, and be explicit in what result it is expected to return\nA function with multiple arguments: the scenarios to be tested increase rapidly. Recommended to minimize number of critical function arguments, and break the function into smaller ones.\nBad comments in the code: drop the unnecessary, unclear, outdated comments, write code that are self-explanatory.\n\n\nDevelopment workflow\nCode refactoring: change existing code without its functionality\nTDD: Test-Driven Development\n\nstart with writing a new (failing) test\nwrite code thtat passes the nenw tetst\nrefactor the code\nand repeat\n\nBenefits: your code is covered by tests; you think of testing scenarios first; ‚Äúfail fast‚Äù - can immediately repair the code; more freedom to refactor (improve) the code.\nHow to test\n\nautomatically: CI/CD, after pushing Git commits\nmanually:\n\nrun all unit tests in the package (Build / Test package)\nrun tests in a selected test file (Run Tests)\nrun a single test in Rstudio console\n\n\nHow to check\n\nR CMD CHECK"
  },
  {
    "objectID": "blog/technotes_ml_series_20251105_class_unbalanced/index.html#writing-robust-statistical-software",
    "href": "blog/technotes_ml_series_20251105_class_unbalanced/index.html#writing-robust-statistical-software",
    "title": "How to handle class-unbalanced data?",
    "section": "Writing robust statistical software",
    "text": "Writing robust statistical software\nImplement complext statistical methods such that the software is reliable, and includes appropriate testing to ensure high quality and validity and ultimately credibility of statistical analysis results.\n\nchoose the right method and understand them\nsolve the core implementation problem with prototype code\n\nNeed to try a few different solutions, compare and select the best one. Might also need to involve domain experts.\n\nspend enough time on planning the design of the R package\n\nDon‚Äôt write the package right away; instead define the scope, discuss with users, and design the package.\nStart to draw a flow diagram, align names, arguments and classes; write prototype code.\n\nassume the package will evolve over time\n\nPackages you depend on will change; users will require new features\nWrite tests\n\nunit tests\nintegration tests\n\nMake the package extensible\n\nconsider object oriented package designs\ncombine functions in pipelines\n\nKeep it manageable\n\navoid too many arguments\navoid too large functions"
  },
  {
    "objectID": "blog/technotes_ml_series_20251105_class_unbalanced/index.html#key-components",
    "href": "blog/technotes_ml_series_20251105_class_unbalanced/index.html#key-components",
    "title": "How to handle class-unbalanced data?",
    "section": "Key components",
    "text": "Key components\n\nDependency management\nInstall dependencies (system/OS level; R packages)\n\nSet repos (can be specified in options()) to e.g.¬†CRAN, BioConductor\nrenv\ncontainer with dependencies pre-installed\n\n\n\nStatic code analysis\n\nLinting (for programmatic and syntax errors) via lintr package\nCode style enforcement via styler package\nSpell checks identifies misspelled words in vignettes, docs and R code via spelling package\n\n\n\nTesting\n\nR CMD build builds R packages as a installable artifact\nR CMD check runs 20+ checks including unit tests, reports errors, warnigns and notes\nTest coverage reports with covr, checks how many lines of code are covered with tests\nR CMD INSTALL tests R package installation\n\n\n\nDocumentation\nAuto-generated docs via Roxygen and pkgdown\n\n\nRelease and deployments\nRelease artifacts and deployments to target systems\n\nChangelog (features, bug fixes) in the NEWS.md\nRelease: create the package with R CMD build. Validation report with thevalidatoR\nPublishing: CRAN, BioConductor"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Doing real-world projects is, I think, the best way to learn and also to engage the world\nand find out what the world is all about.\n\n‚Äì Ray Kurzweil\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoreden\n\n\nR tools to faciliate sustainable nutrition research\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent Travel Assistant System\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatbot Design using Retrieval‚ÄëAugmented Generation (RAG)\n\n\nBuilt a domain‚Äëspecific chatbot integrating vector‚Äëbased retrieval with GPT models to provide accurate, context‚Äëaware responses\n\n\n\n\n\n\n\n\n\n\n\n\nCongressional Policy Analysis using ML and HPCA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Powered Patient Education System\n\n\nDevelop an AI agent to enhance patient education by delivering personalized, on-demand health information through summaries, comprehension checks, and quizzes about relevant‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\n\nCollaboration and Competition\n\n\nTrain a pair of agents to play tennis.\n\n\n\nNovember 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Injection Attacks on LLM Medical Diagnosis by Symptom Elaboration\n\n\n\nR package\n\n\n\nAttacker is to trick the LLM to generate inappropriate possible medical diagnosis which could mislead the end use\n\n\n\nJanuary 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurvival Of Ventilated and Control Flies\n\n\n\nR package\n\n\n\nHypothesis Analysis of Life Expectancy of Flies in Normal vs ill Ventilated Bottles\n\n\n\nSeptember 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification of Foods Based on their Quality\n\n\n\nArcGIS\n\nPython\n\n\n\nML model to assess the quality of fruit from an data set, which could be integrated into a product for use in home kitchens\n\n\n\nMay 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nP2P File Sharing Protocol\n\n\n\nShiny app\n\n\n\nBuild a peer-to-peer file sharing protocol that keeps track of which peers are sharing and what files are being shared in the network\n\n\n\nJanuary 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nMotion Prediction and Detection for Autonomous Vehicles\n\n\n\nAutonomous Systems\n\nDeep Learning\n\nComputer Vision\n\n\n\nDevelop a framework for vehicle detection and motion planning of vehicles in complex driving scenarios\n\n\n\nDecember 7, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/rstats_20230721_teaching/index.html",
    "href": "talks/rstats_20230721_teaching/index.html",
    "title": "Transforming medical statistics classroom with R and Quarto",
    "section": "",
    "text": "Time and place: July 21, 2023 10AM. Roche office, Basel, Switzerland\nSlides for this talk can be accessed Code."
  },
  {
    "objectID": "talks/rstats_20230721_teaching/index.html#about-the-topic",
    "href": "talks/rstats_20230721_teaching/index.html#about-the-topic",
    "title": "Transforming medical statistics classroom with R and Quarto",
    "section": "About the topic",
    "text": "About the topic\nThe 8 day introductory statistics course (MF9130) at the Faculty of Medicine, University of Oslo is designed for PhD students in medicine, biology, psychology and other health related fields. Similar to other conventional teaching methods, the course has been focusing largely on theory and hand calculation. The software has been Stata and SPSS, and data analysis was mostly left for the students to figure out on their own.\nThis year, we made an attempt to transform the course with R, and aimed to teach more practical data analysis skills. We added one session per day where the instructor guide students on R and project management, importing data , basic manipulation and statistical methods. The IT skills of the students vary greatly, and therefore we used the ‚Äòsticky notes‚Äô help system borrowed from the Carpentries to make sure everyone could get help in the first days. We have created a course website using Quarto, where all the material and R exercises (with rendered solution) are available for self-study. We have witnessed amazing progress - by the end of the first week, students with the least computer / data skills were able to work on dataframes, make basic plots and do a chi-squared test. This helps build students confidence in data and statistics, and as a result, they can start to work on their own datasets using the skills immediately."
  },
  {
    "objectID": "talks/rstats_20190402_blogdown/index.html",
    "href": "talks/rstats_20190402_blogdown/index.html",
    "title": "Building Website in R: Step by Step Introduction to blogdown",
    "section": "",
    "text": "Since this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "talks/community_20240921_quartofriends/index.html",
    "href": "talks/community_20240921_quartofriends/index.html",
    "title": "Use Quarto, Make Friends",
    "section": "",
    "text": "It has been two years since Quarto became the most popular reproducible publication tool in data science and R community. However Quarto is so much more than just a publication tool! I started using it since late 2022, and it has helped me become more organized, productive and connected with people in the data science community.\nIn this talk I will not focus on the technical aspects on ‚Äòhow‚Äô to use this tool. In the first part of the talk, I would like to report the latest news and trends seen in the useR conference and Posit conf, the two biggest global R events. In the second part, I will share my own experience in using Quarto for my career: from learning new skills, collaborating with co-workers, teaching university courses to networking and building a community (CAMIS collaboration). It is a powerful tool to share your work, and make new connections - both for work and for fun! I hope this talk will provide you with some new ideas on how to use this fantastic technology to fulfill your goals."
  },
  {
    "objectID": "talks/ehr_20210218_biday/index.html",
    "href": "talks/ehr_20210218_biday/index.html",
    "title": "Network Analysis of Hospital EHR data",
    "section": "",
    "text": "Since this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "talks/index.html",
    "href": "talks/index.html",
    "title": "Talks",
    "section": "",
    "text": "Talks on A Multi-Objective Optimization Framework for Carbon-Aware Smart Energy Management in NAPS"
  },
  {
    "objectID": "talks/index.html#upcoming",
    "href": "talks/index.html#upcoming",
    "title": "Talks",
    "section": "",
    "text": "Talks on A Multi-Objective Optimization Framework for Carbon-Aware Smart Energy Management in NAPS"
  },
  {
    "objectID": "talks/index.html#selected-previous-talks",
    "href": "talks/index.html#selected-previous-talks",
    "title": "Talks",
    "section": "Selected previous talks",
    "text": "Selected previous talks\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\n\nDescription\n\n\n\nDate\n\n\n\n\n\n\n\n\nScaling Smart Grids with Transfer Learning and DRL\n\n\n\n\n\n2025-07-16\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talks/rstats_20240613_teaching/index.html",
    "href": "talks/rstats_20240613_teaching/index.html",
    "title": "A one year recap on teaching statistcis to medical students: how can R and Quarto help?",
    "section": "",
    "text": "Time and place: June 13 2024. Online\nSlides for this talk can be accessed Code."
  },
  {
    "objectID": "talks/rstats_20240613_teaching/index.html#about-the-topic",
    "href": "talks/rstats_20240613_teaching/index.html#about-the-topic",
    "title": "A one year recap on teaching statistcis to medical students: how can R and Quarto help?",
    "section": "About the topic",
    "text": "About the topic\nThe Department of Biostatistics at University of Oslo offer statistics courses at different levels for medical students and PhD candidates with clinical backgrounds. The courses were traditionally taught with a focus on theory instead of data analysis, where SPSS and STATA were the tools of choice.\nSince 2023 spring semester, we have been gradually transforming some of our statistics courses into R, using Quarto course websites and Carpentries style live-coding instruction. With new Quarto tools (such as WebR) we also added interactivity in the code blocks. So far we have transformed two courses with over 100 students who have almost no programming experience. We have observed impressive progress in the skill development, and received significantly more positive feedback when it comes to statistics education.\nIn this talk, I would like to share our experience on the successes and challenges throughout the process. Looking back, is it cost-effective? Definitely. Can we do better in the future? Almost surely. If you are also planning to adopt new technology in your teaching activities, join us to learn more about what you can do to make the transition happen!\nCourse website can be accessed here"
  },
  {
    "objectID": "projects/project2/index.html",
    "href": "projects/project2/index.html",
    "title": "AI-Powered Patient Education System",
    "section": "",
    "text": "ggehr (read: gg E-H-R) stands for ggplot2 extension for EHR data, which provides a set of tools to facilitate EHR (Electronic Health Records) visualization.\nggehr package helps you make visualize EHR data, so that you can\n\nhave an overview of the mixed type information related to a patient;\nvisually identify the errors in data recording.\n\nLearn more about ggehr"
  },
  {
    "objectID": "projects/project10.html",
    "href": "projects/project10.html",
    "title": "P2P File Sharing Protocol",
    "section": "",
    "text": "App  Code \nThe Washington State Department of Agriculture developed WaCSE for the Washington State Conservation Commission to use in the Sustainable Farms and Fields (SFF) program. Intended users are the Conservation Commission, conservation districts, growers, and anyone interested in reducing agricultural greenhouse gas (GHG) emissions. This interactive tool estimates the reduction of GHG emissions from different conservation practices across Washington‚Äôs diverse counties."
  },
  {
    "objectID": "projects/project3/index.html",
    "href": "projects/project3/index.html",
    "title": "Multi-Agent Travel Assistant System",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "projects/project3/index.html#norwegian-surveillance-system-for-excess-mortality",
    "href": "projects/project3/index.html#norwegian-surveillance-system-for-excess-mortality",
    "title": "Multi-Agent Travel Assistant System",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "projects/project3/index.html#r-packages-for-mortality-surveillance",
    "href": "projects/project3/index.html#r-packages-for-mortality-surveillance",
    "title": "Multi-Agent Travel Assistant System",
    "section": "R packages for mortality surveillance",
    "text": "R packages for mortality surveillance\n(continue‚Ä¶)\n\nnowcast\nsplalert\nmortanor"
  },
  {
    "objectID": "projects/project3/index.html#collaboration-with-cause-of-death-registry",
    "href": "projects/project3/index.html#collaboration-with-cause-of-death-registry",
    "title": "Multi-Agent Travel Assistant System",
    "section": "Collaboration with Cause of Death Registry",
    "text": "Collaboration with Cause of Death Registry"
  },
  {
    "objectID": "projects/project9.html",
    "href": "projects/project9.html",
    "title": "Classification of Foods Based on their Quality",
    "section": "",
    "text": "App  Code \nThe Soil Health Roadmap is a science-based guide to maintaining and improving soil health in eight focus areas across Washington state.\nFor each focus area, I created crop and soil maps using the arcpy Python package. I then summarized the crop acreage and soil properties in interactive ArcGIS dashboards to complement the Paper."
  },
  {
    "objectID": "projects/project6/index.html",
    "href": "projects/project6/index.html",
    "title": "Noreden",
    "section": "",
    "text": "Noreden"
  },
  {
    "objectID": "projects/project7/index.html",
    "href": "projects/project7/index.html",
    "title": "Survival Of Ventilated and Control Flies",
    "section": "",
    "text": "{pkgdown} site  Code  CRAN \nInspired by other branding R packages such as Code, Code, and Code, washi provides color palettes and themes consistent with Washington Soil Health Initiative (WaSHI) branding. This package is to be used only by direct collaborators within WaSHI, though you are welcome to adapt the package to suit your own organization‚Äôs branding."
  },
  {
    "objectID": "publications/articles/pesgm2025.html",
    "href": "publications/articles/pesgm2025.html",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "",
    "text": "Open Poster (PDF)"
  },
  {
    "objectID": "publications/articles/pesgm2025.html#abstract",
    "href": "publications/articles/pesgm2025.html#abstract",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "Abstract",
    "text": "Abstract\nThe integration of advanced metering infrastructure (AMI) into power distribution networks generates valuable data for tasks such as phase identification; however, the limited and unreliable availability of labeled data in the form of customer phase connectivity presents challenges. To address this issue, we propose a semi-supervised learning (SSL) bayesian framework that effectively leverages both limited labeled and unlimited unlabeled data.\n\nWhy Phase Identification Needs a New Approach ?\n\nProblem: Utilities don‚Äôt know which phase customers are connected to this affects voltage regulation, DER integration, and fault localization.\n\n\n\n\n\nFig. 1: Illustration of Semi-Supervised Learning Techniques\n\n\n\n\nChallenges & Motivation\n\n\n\nChallenge: Ground truth phase data is scarce, unreliable, and costly to collect.\n\n\nProblem: Supervised ML methods require large amounts of labeled data and often unavailable or unreliable.\n\n\nMotivation: How do we scale phase identification without needing tons of labeled data?"
  },
  {
    "objectID": "publications/articles/pesgm2025.html#contribution",
    "href": "publications/articles/pesgm2025.html#contribution",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "Contribution",
    "text": "Contribution\nOur approach incorporates:\n\nSelf-training with an ensemble of multilayer perceptron classifiers.\nLabel spreading to propagate labels based on data similarity.\nBayesian Neural Networks (BNNs) for uncertainty estimation, improving confidence and reducing phase identification errors.\n\nKey Highlights:*\n\nAchieved ~98% ¬± 0.08 accuracy on real utility data (Duquesne Light Company) using minimal and unreliable labeled data.\nUncertainty-aware predictions reduce misclassification risk and improve smart grid reliability.\nCombines pseudo-labeling, graph-based SSL, and probabilistic modeling to handle data scarcity in real-world distribution networks.\n\nOur ‚ÄúSSL + Uncertainty Estimation‚Äù approach provides an efficient and scalable solution for phase identification in AMI data, enabling utilities to improve modeling, simulation, and operational decision-making."
  },
  {
    "objectID": "publications/articles/pesgm2025.html#semi-supervised-learning-framework-for-ami",
    "href": "publications/articles/pesgm2025.html#semi-supervised-learning-framework-for-ami",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "Semi-Supervised Learning Framework for AMI",
    "text": "Semi-Supervised Learning Framework for AMI\nWe formulate SSL as a regularized optimization problem: Equation¬†1\n\\[\n\\min_{f \\in \\mathcal{F}} \\left[ \\frac{1}{n_L} \\sum_{i=1}^{n_L} \\ell(f(x_i), y_i) + \\lambda R_u(f, \\mathcal{D}_U) \\right]\n\\tag{1}\\]\nWhere:\n\n( (, ) ): Supervised loss (cross-entropy)\n\n( R_u(f, _U) ): Unsupervised regularization term\n\n( ): Trade-off parameter\n\nThe challenge is designing ( R_u(f, _U) ) to effectively leverage unlabeled data.\n\\[\\begin{equation}\n  f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k}\n  (\\#eq:binom)\n\\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation @ref(eq:binom)."
  },
  {
    "objectID": "publications/articles/Journal1.html#abstract",
    "href": "publications/articles/Journal1.html#abstract",
    "title": "Bayesian-Optimized Bidirectional Long-Short-Term Memory network for Wind Power Forecasting with Uncertainty Quantification",
    "section": "Abstract",
    "text": "Abstract\n\nObjective\nWind energy technologies, including advanced management and scheduling, rely on accurate wind power forecasting (WPF) for optimal operation. Enhancing forecast precision is crucial for reducing volatility in wind power and improving forecasting reliability. While forecasting methods estimate future values from historical data, traditional approaches often struggle with computational efficiency and model complexity. To address these challenges, we propose a hybrid forecasting model that integrates multi- variate estimation (MVE) and pure prediction (TSP) using a bidirectional long-short-term memory network (Bi- LSTM) optimized with Tree-structured Parzen Estimator (TPE)- based Bayesian optimization. The model incorporates numerical weather prediction (NWP) data for real-time forecasting, a key limitation in existing methods. MVE utilizes features such as wind speed, direction, temperature, and pressure, while TSP captures historical power generation patterns. The TPE-optimized Bi-LSTM architecture effectively captures bidirectional temporal dependencies, improving in both short-term and long-term forecasting. The model is evaluated using a six-year historical wind energy dataset from NREL, with performance assessed through RMSE, MAE, and R2 score. It outperforms traditional LSTM variants (Vanilla LSTM, Stacked LSTM, Bi-LSTM) and state-of-the-art models such as Transformers and GRUs, achieving R¬≤ scores of 0.976 for MVE and 0.932, 0.928, and 0.864 for TSP across short-term, day- ahead, and long-term forecasting, respectively. Additionally, TPE based Bayesian optimization reduces computational time around 8-10%, enhancing hyperparameter tuning efficiency. The study further analyzes the model‚Äôs computational burden, scalability, and practical implementation, offering a robust and efficient approach for improving wind power forecasting accuracy. \n\n\nMethod\n(\\(N_{ASD}=23\\), \\(N_{NT}=52\\))\n\n\nResults\n\n\nConclusions"
  },
  {
    "objectID": "publications/articles/iccpsS2016.html",
    "href": "publications/articles/iccpsS2016.html",
    "title": "Deep value of information estimators for collaborative human-machine information gathering",
    "section": "",
    "text": "K. G. Lore, N. Sweet, K. Kumar, N. Ahmed and S. Sarkar, ‚ÄúDeep Value of Information Estimators for Collaborative Human-Machine Information Gathering,‚Äù 2016 ACM/IEEE 7th International Conference on Cyber-Physical Systems (ICCPS), Vienna, Austria, 2016, pp.¬†1-10, doi: 10.1109/ICCPS.2016.7479095. IEEE."
  },
  {
    "objectID": "publications/articles/iccpsS2016.html#citation",
    "href": "publications/articles/iccpsS2016.html#citation",
    "title": "Deep value of information estimators for collaborative human-machine information gathering",
    "section": "",
    "text": "K. G. Lore, N. Sweet, K. Kumar, N. Ahmed and S. Sarkar, ‚ÄúDeep Value of Information Estimators for Collaborative Human-Machine Information Gathering,‚Äù 2016 ACM/IEEE 7th International Conference on Cyber-Physical Systems (ICCPS), Vienna, Austria, 2016, pp.¬†1-10, doi: 10.1109/ICCPS.2016.7479095. IEEE."
  },
  {
    "objectID": "publications/articles/iccpsS2016.html#abstract",
    "href": "publications/articles/iccpsS2016.html#abstract",
    "title": "Deep value of information estimators for collaborative human-machine information gathering",
    "section": "Abstract",
    "text": "Abstract\nEffective human-machine collaboration can significantly improve many learning and planning strategies for information gathering via fusion of ‚Äòhard‚Äô and ‚Äòsoft‚Äô data originating from machine and human sensors, respectively. However, gathering the most informative data from human sensors without task overloading remains a critical technical challenge. In this context, Value of Information (VOI) is a crucial decision- theoretic metric for scheduling interaction with human sensors. We present a new Deep Learning based VOI estimation framework that can be used to schedule collaborative human-machine sensing with efficient online inference and minimal policy hand-tuning. Supervised learning is used to train deep convolutional neural networks (CNNs) to extract hierarchical features from ‚Äòimages‚Äô of belief spaces obtained via data fusion. These features can be associated with soft data query choices to reliably compute VOI for human interaction. The CNN framework is described in detail, and a performance comparison to a feature- based POMDP scheduling policy is provided. The practical feasibility of our method is also demonstrated on a mobile robotic search problem with language-based semantic human sensor inputs."
  },
  {
    "objectID": "publications/articles/gridedge2025.html",
    "href": "publications/articles/gridedge2025.html",
    "title": "Transfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids",
    "section": "",
    "text": "K. Kumar and G. Ravikumar, ‚ÄúTransfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids,‚Äù 2025 IEEE PES Grid Edge Technologies Conference & Exposition (Grid Edge), San Diego, CA, USA, 2025, pp.¬†1-5, doi: 10.1109/GridEdge61154.2025.10887439. IEEE"
  },
  {
    "objectID": "publications/articles/gridedge2025.html#citation",
    "href": "publications/articles/gridedge2025.html#citation",
    "title": "Transfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids",
    "section": "",
    "text": "K. Kumar and G. Ravikumar, ‚ÄúTransfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids,‚Äù 2025 IEEE PES Grid Edge Technologies Conference & Exposition (Grid Edge), San Diego, CA, USA, 2025, pp.¬†1-5, doi: 10.1109/GridEdge61154.2025.10887439. IEEE"
  },
  {
    "objectID": "publications/articles/gridedge2025.html#abstract",
    "href": "publications/articles/gridedge2025.html#abstract",
    "title": "Transfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids",
    "section": "Abstract",
    "text": "Abstract\nThe integration of renewable energy resources has made power system management increasingly complex. DRL is a potential solution to optimize power system operations, but it requires significant time and resources during training. The control policies developed using DRL are specific to a single grid and require retraining from scratch for other grids. Training the DRL model from scratch is computationally expensive. This paper proposes a novel TL with a DRL framework to optimize VV C across different grids. This framework significantly reduces training time and improves VVC control performance by fine-tuning pre-trained DRL models for various grids. We developed a policy reuse classifier that transfers the knowledge from the IEEE-123 Bus system to the IEEE-13 Bus system. We performed an impact analysis to determine the effectiveness of TL. Our results show that TL improves the VVC control policy by 69.51 %, achieves faster convergence, and reduces the training time by 98.14%."
  },
  {
    "objectID": "robo.html",
    "href": "robo.html",
    "title": "Robotics",
    "section": "",
    "text": "Doing real-world projects is, I think, the best way to learn and also to engage the world and find out what the world is all about.\n\n-Ray Kurzweil\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCollaboration and Competition\n\n\nTrain a pair of agents to play tennis.\n\n\n\n\n\n\n\n\n\n\n\n\nNoreden\n\n\nR tools to faciliate sustainable nutrition research\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent Travel Assistant System\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatbot Design using Retrieval‚ÄëAugmented Generation (RAG)\n\n\nBuilt a domain‚Äëspecific chatbot integrating vector‚Äëbased retrieval with GPT models to provide accurate, context‚Äëaware responses\n\n\n\n\n\n\n\n\n\n\n\n\nCongressional Policy Analysis using ML and HPCA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Powered Patient Education System\n\n\nDevelop an AI agent to enhance patient education by delivering personalized, on-demand health information through summaries, comprehension checks, and quizzes about relevant‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Injection Attacks on LLM Medical Diagnosis by Symptom Elaboration\n\n\n\nR package\n\n\n\nAttacker is to trick the LLM to generate inappropriate possible medical diagnosis which could mislead the end use\n\n\n\nJan 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification of Foods Based on their Quality\n\n\n\nArcGIS\n\nPython\n\n\n\nML model to assess the quality of fruit from an data set, which could be integrated into a product for use in home kitchens\n\n\n\nMay 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nP2P File Sharing Protocol\n\n\n\nShiny app\n\n\n\nBuild a peer-to-peer file sharing protocol that keeps track of which peers are sharing and what files are being shared in the network\n\n\n\nJan 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nMotion Prediction and Detection for Autonomous Vehicles\n\n\n\nAutonomous Systems\n\nDeep Learning\n\nComputer Vision\n\n\n\nDevelop a framework for vehicle detection and motion planning of vehicles in complex driving scenarios\n\n\n\nDec 7, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "rag_energy_advisor.html",
    "href": "rag_energy_advisor.html",
    "title": "RAG-Enhanced Energy Advisor",
    "section": "",
    "text": "Code \nThe RAG-Enhanced Energy Advisor explores how retrieval-augmented generation (RAG) frameworks can improve decision-making and control strategies in energy management systems ‚Äî while also examining their potential security vulnerabilities.\nThis project simulates a scenario where an attacker attempts to trick an LLM into generating inappropriate or unsafe outputs, such as fabricated or misleading control actions, or even false medical diagnostics within smart building health-energy systems.\nThe system aims to demonstrate defensive prompting, retrieval filtering, and trust calibration mechanisms to ensure that LLM-based advisory systems remain robust, interpretable, and safe.\n\n\nResearch Context\n\nIntegrates RAG pipelines for real-time adaptive learning in multi-building environments.\n\nExamines prompt-injection attacks that can mislead models into unsafe or irrelevant outputs.\n\nIntroduces trust-aware retrieval weighting to dynamically filter retrieved documents based on domain relevance and safety metrics.\n\n\n\n\nCore Technologies\n\nLangChain for retrieval orchestration\n\nFAISS / ChromaDB for vector-based semantic search\n\nOpenAI GPT / Llama 3 as the base reasoning model\n\nCityLearn environment for multi-building simulation and energy optimization\n\n\n\n\nKey Insights\nThe project highlights the dual nature of RAG systems ‚Äî powerful for enhancing reasoning and grounding, yet susceptible to data poisoning and adversarial instructions.\nBy incorporating safety filters and reinforcement-based trust weighting, this framework helps move toward secure, reliable LLM-driven control in energy and cyber-physical systems."
  },
  {
    "objectID": "drl/drl8.html",
    "href": "drl/drl8.html",
    "title": "Classification of Foods Based on their Quality",
    "section": "",
    "text": "App  Code \nThe Soil Health Roadmap is a science-based guide to maintaining and improving soil health in eight focus areas across Washington state.\nFor each focus area, I created crop and soil maps using the arcpy Python package. I then summarized the crop acreage and soil properties in interactive ArcGIS dashboards to complement the Paper."
  },
  {
    "objectID": "drl/drl3/index.html",
    "href": "drl/drl3/index.html",
    "title": "Chatbot Design using Retrieval‚ÄëAugmented Generation (RAG)",
    "section": "",
    "text": "Noreden"
  },
  {
    "objectID": "drl/drl5/index.html",
    "href": "drl/drl5/index.html",
    "title": "Noreden",
    "section": "",
    "text": "Noreden"
  },
  {
    "objectID": "drl/drl10.html",
    "href": "drl/drl10.html",
    "title": "Motion Prediction and Detection for Autonomous Vehicles",
    "section": "",
    "text": "Google Colab  YOLOv5 Code  PyTorch Hub \nInspired by other open-source deep learning projects such as YOLO, ResNet, and Code, this project demonstrates object detection and motion prediction for autonomous vehicles using the Kaggle Lyft motion prediction dataset. We use YOLOv5 for real-time object detection and ResNet-50 for motion trajectory prediction."
  },
  {
    "objectID": "drl/drl6/index.html",
    "href": "drl/drl6/index.html",
    "title": "Survival Of Ventilated and Control Flies",
    "section": "",
    "text": "{pkgdown} site  Code  CRAN \nInspired by other branding R packages such as Code, Code, and Code, washi provides color palettes and themes consistent with Washington Soil Health Initiative (WaSHI) branding. This package is to be used only by direct collaborators within WaSHI, though you are welcome to adapt the package to suit your own organization‚Äôs branding."
  },
  {
    "objectID": "about_me.html",
    "href": "about_me.html",
    "title": "Kundan Kumar",
    "section": "",
    "text": "Email\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     GitHub\n  \n  \n    \n     YouTube\n  \n  \n    \n     Substack\n  \n  \n    \n     Scholar\n  \n\n  \n  \nHi! I‚Äôm Kundan Kumar, a Ph.D.¬†candidate in Computer Science at Iowa State University. My research focuses on creating intelligent and adaptable AI systems for next-generation cyber-physical infrastructure, integrating deep reinforcement learning (DRL), multi-agent systems, large language models (LLMs), and computer vision.\nI develop safety-critical DRL frameworks that incorporate domain knowledge and uncertainty, enabling reliable decision-making in complex environments. Recent projects include exploring transfer learning and enhancing adversarial resilience across systems. I also create LLM-integrated simulation frameworks for autonomous systems, combining perception, trajectory planning, and natural language reasoning.\nOutside of research, I share insights on Substack and YouTube. I enjoy cooking and ice skating üõº in my free time.\n\n\n\n\n\n\nOther Research Interests\n\n\n\n\n  \n    \n      LLM Reasoning & Agents\n      Agentic workflows (LangChain/LangGraph), tool-use, memory, retrieval, planning & reflection loops for robust multi-step reasoning.\n    \n  \n\n\n  \n    \n      Statistical ML\n      Uncertainty quantification, probabilistic modeling, and data-driven inference in dynamic environments.\n    \n  \n\n\n  \n    Autonomous Perception & Control\n    Vision-based perception (detection, segmentation, sensor fusion) integrated with learning-based control and trajectory planning for autonomous systems.\n  \n\n\n\n\n\n\nExplore My Work\n\n\n\n\n  \n    Blogs\n    \n      \n\n\n\n\n\n\n\nSelf-Attention Mechanism\n\n\n\nOct 21, 2025\n\n\n\n\n\n\nNo matching items\n\n    \n    See all ‚Üí\n  \n\n  \n    Talks\n    \n      \n\n\n\n\n\n\n\n\n\nScaling Smart Grids with Transfer Learning and DRL\n\n\n\nJul 16, 2025\n\n\n\n\n\n\nNo matching items\n\n    \n    See all ‚Üí\n  \n\n  \n    Publications\n    \n      \n\n\n\n\n\n\n\nBayesian-Optimized Bidirectional Long-Short-Term Memory network for Wind Power Forecasting with Uncertainty Quantification\n\n\n\n\n\nyear\n\n\n2025\n\n\n\n\n\n\n\n\nNo matching items\n\n    \n    See all ‚Üí\n  \n\n  \n    Projects\n    \n      \n\n\n\n\n\n\n\n\n\nAI-Powered Patient Education System\n\n\n\n\n\nNo matching items\n\n    \n    See all ‚Üí\n  \n\n\n\n\n\nNews Highlights\n\n  \n    [Sep 2025]\n    \n      Our paper on Bayesian-Optimized Bidirectional Long-Short-Term Memory network for Wind Power Forecasting with Uncertainty Quantification has been accepted to Journal on Electric Power Systems Research 2026.\n    \n  \n  \n  \n    [Jul 2025]\n    \n      Selected for the Cohere Machine Learning Summer School, hosted by Cohere Labs.\n    \n  \n\n  \n    [Mar 2025]\n    \n      Our paper on Advanced Semi-Supervised Learning with Uncertainty Estimation for Phase Identification in Distribution Systems has been accepted to Conference on IEEE PES General Meeting 2025."
  },
  {
    "objectID": "citylearn.html",
    "href": "citylearn.html",
    "title": "LLM-Powered Energy Optimizer",
    "section": "",
    "text": "Code \nThe LLM-Powered Energy Optimizer integrates Large Language Models (LLMs) with the CityLearn multi-building energy environment to achieve adaptive energy coordination and optimization.\nBy combining the reasoning ability of LLMs with reinforcement-based control agents, this framework demonstrates how language-driven guidance can enhance decision-making and interpretability in smart energy systems.\n\n\nSystem Overview\nThe project leverages CityLearn, an open-source urban energy simulator, where multiple buildings interact with shared energy resources such as batteries, HVAC systems, and renewable units.\nThe LLM acts as a high-level advisor, generating structured reasoning steps, policy explanations, and optimization prompts to assist the RL controller in selecting efficient energy actions.\n\n\n\nCore Components\n\nCityLearn Environment: Multi-building coordination for energy storage and HVAC scheduling\n\nLLM Agent Layer: Generates task explanations, reasoning chains, and adaptive control advice\n\nReinforcement Learning Backbone: PPO and SAC algorithms for optimizing power and comfort metrics\n\nPhysics-Informed Feedback: Embeds voltage, power, and thermal constraints into decision flow\n\n\n\n\nObjectives\n\nReduce total energy consumption and carbon footprint\n\nImprove system interpretability through LLM reasoning chains\n\nEnable human-in-the-loop adjustments using natural-language instructions\n\n\n\n\nResearch Impact\nThis work bridges the gap between natural-language intelligence and energy optimization, enabling explainable, sustainable, and LLM-guided adaptive control in modern smart cities."
  },
  {
    "objectID": "drl.html",
    "href": "drl.html",
    "title": "DRL",
    "section": "",
    "text": "Doing real-world projects is, I think, the best way to learn and also to engage the world and find out what the world is all about.\n\n-Ray Kurzweil\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Powered Patient Education System\n\n\nDevelop an AI agent to enhance patient education by delivering personalized, on-demand health information through summaries, comprehension checks, and quizzes about relevant‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\n\nCollaboration and Competition\n\n\nTrain a pair of agents to play tennis.\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent Travel Assistant System\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoreden\n\n\nR tools to faciliate sustainable nutrition research\n\n\n\n\n\n\n\n\n\n\n\n\nCongressional Policy Analysis using ML and HPCA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatbot Design using Retrieval‚ÄëAugmented Generation (RAG)\n\n\nBuilt a domain‚Äëspecific chatbot integrating vector‚Äëbased retrieval with GPT models to provide accurate, context‚Äëaware responses\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Injection Attacks on LLM Medical Diagnosis by Symptom Elaboration\n\n\n\nR package\n\n\n\nAttacker is to trick the LLM to generate inappropriate possible medical diagnosis which could mislead the end use\n\n\n\nJan 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurvival Of Ventilated and Control Flies\n\n\n\nR package\n\n\n\nHypothesis Analysis of Life Expectancy of Flies in Normal vs ill Ventilated Bottles\n\n\n\nSep 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification of Foods Based on their Quality\n\n\n\nArcGIS\n\nPython\n\n\n\nML model to assess the quality of fruit from an data set, which could be integrated into a product for use in home kitchens\n\n\n\nMay 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nP2P File Sharing Protocol\n\n\n\nShiny app\n\n\n\nBuild a peer-to-peer file sharing protocol that keeps track of which peers are sharing and what files are being shared in the network\n\n\n\nJan 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nMotion Prediction and Detection for Autonomous Vehicles\n\n\n\nAutonomous Systems\n\nDeep Learning\n\nComputer Vision\n\n\n\nDevelop a framework for vehicle detection and motion planning of vehicles in complex driving scenarios\n\n\n\nDec 7, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "llms.html",
    "href": "llms.html",
    "title": "LLMs",
    "section": "",
    "text": "Doing real-world projects is, I think, the best way to learn and also to engage the world and find out what the world is all about.\n\n-Ray Kurzweil\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoreden\n\n\nR tools to faciliate sustainable nutrition research\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent Travel Assistant System\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatbot Design using Retrieval‚ÄëAugmented Generation (RAG)\n\n\nBuilt a domain‚Äëspecific chatbot integrating vector‚Äëbased retrieval with GPT models to provide accurate, context‚Äëaware responses\n\n\n\n\n\n\n\n\n\n\n\n\nCongressional Policy Analysis using ML and HPCA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Powered Patient Education System\n\n\nDevelop an AI agent to enhance patient education by delivering personalized, on-demand health information through summaries, comprehension checks, and quizzes about relevant‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\n\nCollaboration and Competition\n\n\nTrain a pair of agents to play tennis.\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Injection Attacks on LLM Medical Diagnosis by Symptom Elaboration\n\n\n\nR package\n\n\n\nAttacker is to trick the LLM to generate inappropriate possible medical diagnosis which could mislead the end use\n\n\n\nJan 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurvival Of Ventilated and Control Flies\n\n\n\nR package\n\n\n\nHypothesis Analysis of Life Expectancy of Flies in Normal vs ill Ventilated Bottles\n\n\n\nSep 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification of Foods Based on their Quality\n\n\n\nArcGIS\n\nPython\n\n\n\nML model to assess the quality of fruit from an data set, which could be integrated into a product for use in home kitchens\n\n\n\nMay 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nP2P File Sharing Protocol\n\n\n\nShiny app\n\n\n\nBuild a peer-to-peer file sharing protocol that keeps track of which peers are sharing and what files are being shared in the network\n\n\n\nJan 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nMotion Prediction and Detection for Autonomous Vehicles\n\n\n\nAutonomous Systems\n\nDeep Learning\n\nComputer Vision\n\n\n\nDevelop a framework for vehicle detection and motion planning of vehicles in complex driving scenarios\n\n\n\nDec 7, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "drl/drl1/index.html",
    "href": "drl/drl1/index.html",
    "title": "AI-Powered Patient Education System",
    "section": "",
    "text": "ggehr (read: gg E-H-R) stands for ggplot2 extension for EHR data, which provides a set of tools to facilitate EHR (Electronic Health Records) visualization.\nggehr package helps you make visualize EHR data, so that you can\n\nhave an overview of the mixed type information related to a patient;\nvisually identify the errors in data recording.\n\nLearn more about ggehr"
  },
  {
    "objectID": "drl/drl7.html",
    "href": "drl/drl7.html",
    "title": "Prompt Injection Attacks on LLM Medical Diagnosis by Symptom Elaboration",
    "section": "",
    "text": "Code \nThe goal of orcas is to scrape orca sighting data from the web and visualize it in maps and tables.\nI‚Äôve always had an affinity for the Southern Resident Killer Whales in the Salish Sea. The Center for Whale Research does a lot of really fascinating and important work monitoring their population. They post their survey data on their website; each encounter with the orcas is a separate webpage. I was both curious and intimidated by web scraping so I decided this would make a great case study and personal project. I also learned how to use custom icons in leaflet maps! üêã"
  },
  {
    "objectID": "drl/drl2/index.html",
    "href": "drl/drl2/index.html",
    "title": "Multi-Agent Travel Assistant System",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "drl/drl2/index.html#norwegian-surveillance-system-for-excess-mortality",
    "href": "drl/drl2/index.html#norwegian-surveillance-system-for-excess-mortality",
    "title": "Multi-Agent Travel Assistant System",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "drl/drl2/index.html#r-packages-for-mortality-surveillance",
    "href": "drl/drl2/index.html#r-packages-for-mortality-surveillance",
    "title": "Multi-Agent Travel Assistant System",
    "section": "R packages for mortality surveillance",
    "text": "R packages for mortality surveillance\n(continue‚Ä¶)\n\nnowcast\nsplalert\nmortanor"
  },
  {
    "objectID": "drl/drl2/index.html#collaboration-with-cause-of-death-registry",
    "href": "drl/drl2/index.html#collaboration-with-cause-of-death-registry",
    "title": "Multi-Agent Travel Assistant System",
    "section": "Collaboration with Cause of Death Registry",
    "text": "Collaboration with Cause of Death Registry"
  },
  {
    "objectID": "drl/drl4/index.html",
    "href": "drl/drl4/index.html",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "drl/drl4/index.html#norwegian-surveillance-system-for-excess-mortality",
    "href": "drl/drl4/index.html#norwegian-surveillance-system-for-excess-mortality",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "drl/drl4/index.html#r-packages-for-mortality-surveillance",
    "href": "drl/drl4/index.html#r-packages-for-mortality-surveillance",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "R packages for mortality surveillance",
    "text": "R packages for mortality surveillance\n(continue‚Ä¶)\n\nnowcast\nsplalert\nmortanor"
  },
  {
    "objectID": "drl/drl4/index.html#collaboration-with-cause-of-death-registry",
    "href": "drl/drl4/index.html#collaboration-with-cause-of-death-registry",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "Collaboration with Cause of Death Registry",
    "text": "Collaboration with Cause of Death Registry"
  },
  {
    "objectID": "drl/drl9.html",
    "href": "drl/drl9.html",
    "title": "P2P File Sharing Protocol",
    "section": "",
    "text": "App  Code \nThe Washington State Department of Agriculture developed WaCSE for the Washington State Conservation Commission to use in the Sustainable Farms and Fields (SFF) program. Intended users are the Conservation Commission, conservation districts, growers, and anyone interested in reducing agricultural greenhouse gas (GHG) emissions. This interactive tool estimates the reduction of GHG emissions from different conservation practices across Washington‚Äôs diverse counties."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Kundan Kumar",
    "section": "",
    "text": "Home\n    Contact"
  },
  {
    "objectID": "contact.html#visit-us",
    "href": "contact.html#visit-us",
    "title": "Kundan Kumar",
    "section": "Visit Us",
    "text": "Visit Us\nThe Lab is located in Atanasoff Hall at the Iowa State University.\n\nStreet Address: 2434 Osborn Dr , Ames, IA 50011"
  },
  {
    "objectID": "contact.html#email-us",
    "href": "contact.html#email-us",
    "title": "Kundan Kumar",
    "section": "Email Us",
    "text": "Email Us\n\n\n\n\n\n  \nName¬†*  \nEmail¬†*  \nSubject  ‚Äî¬†Select a topic¬†‚Äî Research Resources Opportunities  \nMessage\n\n\n\nSubmit"
  },
  {
    "objectID": "dl.html",
    "href": "dl.html",
    "title": "DRL",
    "section": "",
    "text": "Doing real-world projects is, I think, the best way to learn and also to engage the world and find out what the world is all about.\n\n-Ray Kurzweil\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI-Powered Patient Education System\n\n\nDevelop an AI agent to enhance patient education by delivering personalized, on-demand health information through summaries, comprehension checks, and quizzes about relevant‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\n\nCollaboration and Competition\n\n\nTrain a pair of agents to play tennis.\n\n\n\n\n\n\n\n\n\n\n\n\nMulti-Agent Travel Assistant System\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNoreden\n\n\nR tools to faciliate sustainable nutrition research\n\n\n\n\n\n\n\n\n\n\n\n\nCongressional Policy Analysis using ML and HPCA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChatbot Design using Retrieval‚ÄëAugmented Generation (RAG)\n\n\nBuilt a domain‚Äëspecific chatbot integrating vector‚Äëbased retrieval with GPT models to provide accurate, context‚Äëaware responses\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt Injection Attacks on LLM Medical Diagnosis by Symptom Elaboration\n\n\n\nR package\n\n\n\nAttacker is to trick the LLM to generate inappropriate possible medical diagnosis which could mislead the end use\n\n\n\nJan 20, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nSurvival Of Ventilated and Control Flies\n\n\n\nR package\n\n\n\nHypothesis Analysis of Life Expectancy of Flies in Normal vs ill Ventilated Bottles\n\n\n\nSep 7, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassification of Foods Based on their Quality\n\n\n\nArcGIS\n\nPython\n\n\n\nML model to assess the quality of fruit from an data set, which could be integrated into a product for use in home kitchens\n\n\n\nMay 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nP2P File Sharing Protocol\n\n\n\nShiny app\n\n\n\nBuild a peer-to-peer file sharing protocol that keeps track of which peers are sharing and what files are being shared in the network\n\n\n\nJan 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\nMotion Prediction and Detection for Autonomous Vehicles\n\n\n\nAutonomous Systems\n\nDeep Learning\n\nComputer Vision\n\n\n\nDevelop a framework for vehicle detection and motion planning of vehicles in complex driving scenarios\n\n\n\nDec 7, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/articles/isgt2024.html",
    "href": "publications/articles/isgt2024.html",
    "title": "Deep Rl-based volt-var control and attack resiliency for der-integrated distribution grids",
    "section": "",
    "text": "K. Kumar and G. Ravikumar, ‚ÄúDeep RL-based Volt-VAR Control and Attack Resiliency for DER-integrated Distribution Grids,‚Äù 2024 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT), Washington, DC, USA, 2024, pp.¬†1-5, doi: 10.1109/ISGT59692.2024.10454163. IEEE"
  },
  {
    "objectID": "publications/articles/isgt2024.html#citation",
    "href": "publications/articles/isgt2024.html#citation",
    "title": "Deep Rl-based volt-var control and attack resiliency for der-integrated distribution grids",
    "section": "",
    "text": "K. Kumar and G. Ravikumar, ‚ÄúDeep RL-based Volt-VAR Control and Attack Resiliency for DER-integrated Distribution Grids,‚Äù 2024 IEEE Power & Energy Society Innovative Smart Grid Technologies Conference (ISGT), Washington, DC, USA, 2024, pp.¬†1-5, doi: 10.1109/ISGT59692.2024.10454163. IEEE"
  },
  {
    "objectID": "publications/articles/isgt2024.html#abstract",
    "href": "publications/articles/isgt2024.html#abstract",
    "title": "Deep Rl-based volt-var control and attack resiliency for der-integrated distribution grids",
    "section": "Abstract",
    "text": "Abstract\nIntegrating distributed energy resources (DERs) into a power system requires more advanced control mechanisms. One of the control strategies used for Volt-VAR control (VVC) is to manage voltage and reactive power. With the increase in the complexity of the power system, there is a need to develop an autonomous and robust control mechanism using deep reinforcement learning (DRL) to enhance grid performance and adjust voltage and reactive power settings. These adjustments minimize losses and enhance voltage stability in the grid. In this paper, we proposed a novel approach to develop a DRL-based VVC framework and mitigation techniques to protect against stealthy white-box attacks targeting the trained control policies of the DRL model. The mitigation technique on the trained DRL is proposed to control the voltage violations on the smart grid to enhance the stability of the grid and minimize voltage irregularities. Our proposed mitigation technique provided better control policies for DRL-based VVC, successfully mitigating 100 percent of voltage violations in the smart grid environment. The results show that the mitigation technique enhances the security and robustness of trained DRL VVC agents."
  },
  {
    "objectID": "publications/articles/naps2025.html#abstract",
    "href": "publications/articles/naps2025.html#abstract",
    "title": "A Multi-Objective Optimization Framework for Carbon-Aware Smart Energy Management",
    "section": "Abstract",
    "text": "Abstract\nAs renewable energy sources become more integrated into the power grid, efficient scheduling of household energy consumption is essential to reduce costs and carbon footprint. In this paper, we introduce an energy optimization framework that optimizes the timing of appliance use based on dynamic carbon intensity and electricity prices. We determine optimal operation schedules using a multi-objective optimization model with a Gurobi solver and machine learning. We combine Random Forest and XGBoost for demand prediction, incorporating their uncertainty estimates into the optimization constraints. The model optimizes ON/OFF appliance schedules while considering constraints like minimum operating times and power balance. It shifts usage to lower-cost and carbon-intensity periods, which helps to reduce energy consumption.\nKey contributions include ML-based demand predictions and mixed-integer programming (MIP) optimization that improves robustness to prediction errors while adjusting schedules based on time-of-use pricing and carbon intensity. Our smart scheduling and load shifting achieve a 35.8% reduction in costs, a 38.6% decrease in carbon emissions, and a 25.8% reduction in peak demand using a carbon-aware scheduling algorithm. This framework effectively shifts loads to low-cost, low-carbon times, offering significant economic and environmental benefits for residential energy management without compromising user comfort."
  },
  {
    "objectID": "publications/articles/naps2025.html#impact-statement",
    "href": "publications/articles/naps2025.html#impact-statement",
    "title": "A Multi-Objective Optimization Framework for Carbon-Aware Smart Energy Management",
    "section": "Impact Statement",
    "text": "Impact Statement"
  },
  {
    "objectID": "publications/articles/icmla2022.html",
    "href": "publications/articles/icmla2022.html",
    "title": "Deep learning and pattern-based methodology for multivariable sensor data regression",
    "section": "",
    "text": "J. K. Francis, C. Kumar, J. Herrera-Gerena, K. Kumar and M. J. Darr, ‚ÄúDeep Learning and Pattern-based Methodology for Multivariable Sensor Data Regression,‚Äù 2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA), Nassau, Bahamas, 2022, pp.¬†748-753, doi: 10.1109/ICMLA55696.2022.00125. IEEE."
  },
  {
    "objectID": "publications/articles/icmla2022.html#citation",
    "href": "publications/articles/icmla2022.html#citation",
    "title": "Deep learning and pattern-based methodology for multivariable sensor data regression",
    "section": "",
    "text": "J. K. Francis, C. Kumar, J. Herrera-Gerena, K. Kumar and M. J. Darr, ‚ÄúDeep Learning and Pattern-based Methodology for Multivariable Sensor Data Regression,‚Äù 2022 21st IEEE International Conference on Machine Learning and Applications (ICMLA), Nassau, Bahamas, 2022, pp.¬†748-753, doi: 10.1109/ICMLA55696.2022.00125. IEEE."
  },
  {
    "objectID": "publications/articles/icmla2022.html#abstract",
    "href": "publications/articles/icmla2022.html#abstract",
    "title": "Deep learning and pattern-based methodology for multivariable sensor data regression",
    "section": "Abstract",
    "text": "Abstract\nWe propose a deep learning methodology for multivariable regression based on pattern recognition that triggers fast learning over sensor data. We used a conversion of sensors-to-image, which enables us to take advantage of Computer Vision architectures and training processes. In addition to this data preparation methodology, we explore using state-of-the-art architectures to generate regression outputs to predict agricultural crop continuous yield information. Finally, we compare with some top models reported in MLCAS2021. We found that using a straightforward training process, we were able to accomplish an MAE of 4.394, RMSE of 5.945, and R2 of 0.861."
  },
  {
    "objectID": "publications/articles/pesgm2024.html",
    "href": "publications/articles/pesgm2024.html",
    "title": "Bayesian Optimization for Deep Reinforcement Learning for Robust Volt-Var Control",
    "section": "",
    "text": "K. Kumar, A. A. Mantha and G. Ravikumar, ‚ÄúBayesian Optimization for Deep Reinforcement Learning for Robust Volt-Var Control,‚Äù 2024 IEEE Power & Energy Society General Meeting (PESGM), Seattle, WA, USA, 2024, pp.¬†1-5, doi: 10.1109/PESGM51994.2024.10688889. IEEE"
  },
  {
    "objectID": "publications/articles/pesgm2024.html#citation",
    "href": "publications/articles/pesgm2024.html#citation",
    "title": "Bayesian Optimization for Deep Reinforcement Learning for Robust Volt-Var Control",
    "section": "",
    "text": "K. Kumar, A. A. Mantha and G. Ravikumar, ‚ÄúBayesian Optimization for Deep Reinforcement Learning for Robust Volt-Var Control,‚Äù 2024 IEEE Power & Energy Society General Meeting (PESGM), Seattle, WA, USA, 2024, pp.¬†1-5, doi: 10.1109/PESGM51994.2024.10688889. IEEE"
  },
  {
    "objectID": "publications/articles/pesgm2024.html#abstract",
    "href": "publications/articles/pesgm2024.html#abstract",
    "title": "Bayesian Optimization for Deep Reinforcement Learning for Robust Volt-Var Control",
    "section": "Abstract",
    "text": "Abstract\nThe high penetration of Renewable Energy Sources (RES) into the grid introduces complexity to the operation and optimization of energy. One potential solution to the challenge is to use deep reinforcement learning (DRL) based techniques to regulate voltage and reactive power under dynamic conditions. However, there is a need to optimize the DRL for better performance and robustness. This paper proposes a Bayesian optimization (BO) technique within the DRL framework to improve the performance and robustness of volt-var control (VVC) in power distribution systems. We combine the actor-critic DRL algorithm with the BO framework to yield fast optimal volt-var control policies. We use BO techniques to estimate DRL-based VVC decisions and accelerate model-training convergence. In the case study, we demonstrated that the BO in DRL on IEEE-13 has improved decision-making by 21.11% and 81.81% for 123 bus test systems. Our research shows that Bayesian-enabled DRL adapts to different grid configurations and maintains voltage profiles within desired limits, thereby improving DRL control policies."
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Kundan Kumar",
    "section": "",
    "text": "Home\n    Publications\n  \n\n\nPublications\nThe following is a list of my research publications, including journal articles, conference papers, Workshops papers and preprints.\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Title\n      \n      \n        Author\n      \n      \n        Publication\n      \n      \n        Year\n      \n    \n  \n    \n      \n      \n    \n\n\n\n  \n    A Multi-Objective Optimization Framework for Carbon-Aware Smart Energy Management\n    Kundan Kumar\n    57th North American Power Symposium\n    (2025)\n    \n\n    Details\n\n    \n\n    \n\n    \n\n    \n\n  \n\n  \n    Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems\n    Kundan Kumar\n    IEEE Power & Energy Society General Meeting\n    (2025)\n    \n\n    Details\n\n    \n\n    \n\n    \n\n    \n\n  \n\n  \n    Bayesian-Optimized Bidirectional Long-Short-Term Memory network for Wind Power Forecasting with Uncertainty Quantification\n    Kundan Kumar\n    Electric Power Systems Research (under Review)\n    (2025)\n    \n\n    Details\n\n    \n\n    \n\n    \n\n    \n\n  \n\n  \n    Transfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids\n    Kundan Kumar.\n    IEEE\n    (2025)\n    \n\n    Details\n\n    \n      \n        DOI\n      \n    \n\n    \n\n    \n\n    \n\n  \n\n  \n    Bayesian Optimization for Deep Reinforcement Learning for Robust Volt-Var Control\n    Kundan Kumar\n    IEEE\n    (2024)\n    \n\n    Details\n\n    \n      \n        DOI\n      \n    \n\n    \n\n    \n\n    \n\n  \n\n  \n    Deep Rl-based volt-var control and attack resiliency for der-integrated distribution grids\n    Kundan Kumar\n    IEEE\n    (2024)\n    \n\n    Details\n\n    \n      \n        DOI\n      \n    \n\n    \n\n    \n\n    \n\n  \n\n  \n    Deep learning and pattern-based methodology for multivariable sensor data regression\n    Kundan Kumar\n    IEEE International Conference on Machine Learning and Applications (ICMLA)\n    (2024)\n    \n\n    Details\n\n    \n      \n        DOI\n      \n    \n\n    \n\n    \n\n    \n\n  \n\n  \n    Deep value of information estimators for collaborative human-machine information gathering\n     Kundan Kumar\n    ACM/IEEE 7th International Conference on Cyber-Physical Systems (ICCPS\n    (2016)\n    \n\n    Details\n\n    \n      \n        DOI\n      \n    \n\n    \n\n    \n\n    \n\n  \n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project8.html",
    "href": "projects/project8.html",
    "title": "Prompt Injection Attacks on LLM Medical Diagnosis by Symptom Elaboration",
    "section": "",
    "text": "Code \nThe goal of orcas is to scrape orca sighting data from the web and visualize it in maps and tables.\nI‚Äôve always had an affinity for the Southern Resident Killer Whales in the Salish Sea. The Center for Whale Research does a lot of really fascinating and important work monitoring their population. They post their survey data on their website; each encounter with the orcas is a separate webpage. I was both curious and intimidated by web scraping so I decided this would make a great case study and personal project. I also learned how to use custom icons in leaflet maps! üêã"
  },
  {
    "objectID": "projects/project11.html",
    "href": "projects/project11.html",
    "title": "Motion Prediction and Detection for Autonomous Vehicles",
    "section": "",
    "text": "Google Colab  YOLOv5 Code  PyTorch Hub \nInspired by other open-source deep learning projects such as YOLO, ResNet, and Code, this project demonstrates object detection and motion prediction for autonomous vehicles using the Kaggle Lyft motion prediction dataset. We use YOLOv5 for real-time object detection and ResNet-50 for motion trajectory prediction."
  },
  {
    "objectID": "projects/project4/index.html",
    "href": "projects/project4/index.html",
    "title": "Chatbot Design using Retrieval‚ÄëAugmented Generation (RAG)",
    "section": "",
    "text": "Noreden"
  },
  {
    "objectID": "projects/project5/index.html",
    "href": "projects/project5/index.html",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "projects/project5/index.html#norwegian-surveillance-system-for-excess-mortality",
    "href": "projects/project5/index.html#norwegian-surveillance-system-for-excess-mortality",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "projects/project5/index.html#r-packages-for-mortality-surveillance",
    "href": "projects/project5/index.html#r-packages-for-mortality-surveillance",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "R packages for mortality surveillance",
    "text": "R packages for mortality surveillance\n(continue‚Ä¶)\n\nnowcast\nsplalert\nmortanor"
  },
  {
    "objectID": "projects/project5/index.html#collaboration-with-cause-of-death-registry",
    "href": "projects/project5/index.html#collaboration-with-cause-of-death-registry",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "Collaboration with Cause of Death Registry",
    "text": "Collaboration with Cause of Death Registry"
  },
  {
    "objectID": "talks/ehr_20221013_ml_icu/index.html",
    "href": "talks/ehr_20221013_ml_icu/index.html",
    "title": "Machine Learning in Intensive Care Units",
    "section": "",
    "text": "A 45 minutes trial lecture to fulfill the requirement of my PhD degree."
  },
  {
    "objectID": "talks/dummy_talk/index.html",
    "href": "talks/dummy_talk/index.html",
    "title": "My Dummy Talk",
    "section": "",
    "text": "This is a simple demo of a Quarto talk listing with an image, title, and subtitle."
  },
  {
    "objectID": "talks/community_20240710_camis/index.html",
    "href": "talks/community_20240710_camis/index.html",
    "title": "CAMIS: An Open-Source, Community endeavour for Comparing Analysis Method Implementations",
    "section": "",
    "text": "2024.7.8-11, Salzburg, Austria. Conference link: UseR!\nStatisticians using multiple softwares (SAS, R, Python) will have found differences in analysis results that warrant further justification. Whilst some industries may accept results not being the same as long as they are ‚Äúclose‚Äù, the highly regulated pharmaceutical industry would require an identical match in results. Yet, discrepancies might still occur, and knowing the reasons (different methods, options, algorithms etc) is critical to the modern statistician and subsequent regulatory submissions.\nIn this talk I will introduce CAMIS: Comparing Analysis Method Implementations in Software. https://psiaims.github.io/CAMIS/ It is a joint-project between PHUSE, the R Validation Hub, PSI AIMS, R consortium and openstatsware. The aim of CAMIS is to investigate and document differences and similarities between different statistical softwares such as SAS and R. We use Quarto and Github to document methods, algorithms and comparisons between softwares through small case studies, and all articles are contributed by the community. In the transition from proprietary to open source technology in the industry, CAMIS can serve as a guidebook to navigate this process.\n\nkeywords: cross industry collaboration, multi-lingua, open-source, quarto"
  },
  {
    "objectID": "talks/ehr_20240918_betterehr/index.html",
    "href": "talks/ehr_20240918_betterehr/index.html",
    "title": "One step closer to better Electronic Health Records data",
    "section": "",
    "text": "Real-World Data (RWD) like Electronic Health Records (EHR) is crucial for understanding drug usage and various treatments and generating Real-World Evidence (RWE). Risk prediction has been a major application where EHR is used, and there is now a shift towards causal inference, which requires data of even higher quality. Patients undergo treatments (drugs, procedures) at various times during their hospital stays, yet the data being recorded are messy and error-prone for various reasons. Analysts spend significant amount of time to sit together with clinicians to identify and understand abnormal records, and unfortunately this process is challenging to automate.\nThis talk will use an example on antibiotics prescription and use at a Nordic hospital to illustrate how some EHR systems can improve for better clinical decision-making and better data for research. I will also introduce a pilot R package (ggehr) that facilitates visual exploration of EHR data, and how it can help reconstruct patient journeys and enable analysts to perform effective quality control."
  },
  {
    "objectID": "talks/ph_20230330_sp/index.html",
    "href": "talks/ph_20230330_sp/index.html",
    "title": "Public health surveillance and reporting",
    "section": "",
    "text": "Time and place: Mar.¬†30, 2023 12:00 PM‚Äì1:00 PM\nHybrid: Georg Sverdrups hus and Zoom\nEvent page"
  },
  {
    "objectID": "talks/ph_20230330_sp/index.html#about-the-topic",
    "href": "talks/ph_20230330_sp/index.html#about-the-topic",
    "title": "Public health surveillance and reporting",
    "section": "About the topic",
    "text": "About the topic\nSituational awareness is key to fast response during a public health emergency, such as COVID-19 pandemic. However, making disease surveillance reports that cover different geographical units for various metrics and data registries is both resource intensive and time consuming. Open source tools such as R packages, GitHub and Airflow can make this process automatic, reproducible and scalable.\nEvery day during the pandemic, Sykdomspulsen team at the Norwegian Institute of Public Health (FHI/NIPH) fetched data from more than 15 data sources, cleaned, censored datasets and carried out a wide range of statistical analyses. Over 1000 situational reports containing automated graphs and tables were produced before breakfast time.\nGrab you matpakke and join us for a presentation from Chi Zhang about how Sykdomspulsen team used and developed open source software to make public health surveillance and reporting more efficient, followed up by a discussion on the benefits and concerns of making these data public. We will end with an open Q&A session as usual!"
  },
  {
    "objectID": "talks/pes_gm_2025/index.html",
    "href": "talks/pes_gm_2025/index.html",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "",
    "text": "As renewable energy integration accelerates, modern power grids face mounting complexity in maintaining stability and efficiency. Deep Reinforcement Learning (DRL) has emerged as a powerful technique for Volt-Var Control (VVC) ‚Äî regulating voltage levels across the distribution grid ‚Äî but its Achilles‚Äô heel lies in expensive retraining.\nEvery new grid topology or environment demands retraining from scratch, costing time, data, and computational energy.\nIn our latest work, presented at the Workshop on Autonomous Energy Systems (GRID-EDGE 2025), we introduce a Transfer Learning (TL)-based DRL framework that enables policy reuse across different grid configurations ‚Äî cutting training time by 98.14% while improving performance by 69.51%."
  },
  {
    "objectID": "blog/technotes_llm_series_20251121_llm_reasoning/index.html",
    "href": "blog/technotes_llm_series_20251121_llm_reasoning/index.html",
    "title": "LLM Reasoning and Planning",
    "section": "",
    "text": "Unlocking Advanced AI: Prompting for LLM Reasoning and Planning\nAre you ready to unlock the advanced capabilities of Large Language Models (LLMs) and elevate your interaction with artificial intelligence? This learning path is designed to equip you with powerful prompting techniques essential for building sophisticated AI agents. Mastering these skills allows you to guide LLMs through complex, multi-step tasks, improving the accuracy, relevance, and utility of their outputs for real-world applications.\nLarge Language Models have created a new computing paradigm largely based on how we write prompts. This learning journey is focused on how advanced prompting techniques enable AI applications to become AI agents. By the end of the journey, you‚Äôll understand the mechanics and possess the skills to apply prompting techniques to agentic AI systems. The Need for Agentic AI: Debugging Complex Code\nImagine you‚Äôre tasked with building an automated system to help developers debug complex code. Simply feeding the buggy code and the error message into a standard LLM often results in generic suggestions that miss the specific context of the larger project. The LLM might suggest superficial fixes or even introduce new bugs.\nHow can you create an AI assistant that acts more like an experienced senior developer ‚Äì one that can break down the problem, hypothesize potential causes, decide which parts of the code to inspect, integrate information from different files, update tests, and even learn from its failures? This requires moving beyond single-shot prompts to build a system capable of multi-step reasoning, planning, and execution ‚Äì precisely the prompting techniques we‚Äôll master.\nWhy is a single, simple prompt often insufficient for guiding an LLM through a complex or multi-step task? Correct! A single prompt is like giving a single instruction, whereas complex tasks require an ongoing dialogue. To act like an ‚Äúexperienced senior developer,‚Äù the AI needs to be guided through a process of breaking down the problem, investigating, and integrating information‚Äîsteps that require a sequence of prompts to manage the plan and its execution effectively.\nThink about a complex, multi-step project you‚Äôve recently worked on, either personally or professionally. This could be anything from planning a detailed event, to troubleshooting a tricky problem at home or work, or even tackling a challenging creative endeavor.\nFoundational Understanding of LLMs: You should know what a Large Language Model (LLM) is at a conceptual level, including its general capabilities (e.g., text generation, understanding) and the basic idea of using ‚Äúprompts‚Äù to interact with it.\nBriefly describe the project and list 3-4 distinct steps you had to take to move it forward.\nNow, imagine you were trying to get a standard AI assistant (like a basic chatbot) to complete the entire project for you using only a single request or prompt.\nBased on your experience with AI, at which specific step do you predict the AI would most likely fail, misunderstand, or give a generic, unhelpful response? Why do you think that particular step would be the breaking point for a single-prompt approach?\n\nprobabilistic In the context of interacting with a Large Language Model (LLM), what is a ‚Äòprompt‚Äô?\n\nThe input text or instructions probide to guide its response Large Language Model (LLM)? A ML model trained on the vast amounts of text data to understand, sumamrize , generate and predict context\nThroughout this course, you‚Äôll explore:\nThe world of AI Agents, understanding their core components and how they reason, plan, and interact with their digital environments.\n\nThe art and science of advanced prompting techniques, mastering how to instruct LLMs with precision and nuance.\n\nCrafting specialized personas using role-based prompting to make AI outputs more targeted and contextually relevant.\n\nUnlocking problem-solving abilities using Chain-of-Thought (CoT) to guide the LLM's reasoning process and ReAct (Reason + Act) to enable LLMs to use tools and take actions.\n\nThe process of prompt instruction refinement, learning to systematically analyze and adjust your prompts for optimal performance.\n\nBuilding multi-step agentic workflows by chaining prompts together, allowing AI to tackle more complex tasks.\n\nPrompt Chaining & Feedback Loops: Building robust, multi-step workflows that allow an AI to tackle complex tasks and even improve its own work based on feedback.\nEnd of Course Project: Agentsville Trip Planner\nAt the end of the course, you‚Äôll attempt to build the ‚ÄúAgentsville Trip Planner Assistant‚Äù project, a smart agent that can take a complex request and see it through to completion. This is your opportunity to see just how powerful prompting can be in agentic AI. You will apply all of the individual skills you learned to create a truly capable system.\nWe want to wish you the very best of luck! You‚Äôre about to start a journey to harness the incredible power of Large Language Models. Get ready to move beyond basic interactions and learn how to architect and guide AI.\nBy the end of this journey, you will have acquired the skills to:\nExplain AI systems that utilize LLMs for sophisticated reasoning and planning capabilities.\nMaster a range of advanced prompting strategies to elicit precise behavior and information from LLMs.\nSystematically optimize and refine your prompts, transforming general AI responses into highly specific and useful outputs.\nConstruct multi-step AI workflows that can handle complex, real-world challenges.\nImplement mechanisms for validation and iterative improvement, leading to more reliable AI agents.\nUltimately, transform generic Large Language Models into specialized, powerful tools tailored to solve intricate problems across various domains.\nThis course will both challenge you and equip you with the cutting-edge skills needed to innovate in the rapidly evolving field of artificial intelligence. We‚Äôre excited to see what you‚Äôll learn and, eventually, what you‚Äôll build. Good luck!"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blogs",
    "section": "",
    "text": "Research Scientist Interview Guide\n\n\n\nData science\n\nInterview Guide\n\n\n\nResearch Scientist Interview Guide\n\n\n\n\n\nNov 24, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nSelf-Attention Mechanism\n\n\n\nDeep Learning\n\nNLP\n\nTransformers\n\n\n\nMy thoughts on the open source transition in pharma, public (health) sector and academia. A culture change is needed, and it‚Äôs done better at some places than others. As educators and researchers, there are many things that can be done.\n\n\n\n\n\nOct 21, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nHow to handle class-unbalanced data?\n\n\n\nclass imbalance\n\nData science\n\n\n\nThe majority class dominates while the minority class is underrepresented, leading models to bias their predictions toward the majority class.\n\n\n\n\n\nSep 27, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nLLM Reasoning and Planning\n\n\n\nData science\n\nLarge Language Models\n\nPrompting\n\n\n\nPrompting for LLM Reasoning and Planning\n\n\n\n\n\nMay 6, 2025\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#overview",
    "href": "blog/technotes_20251102_research_guide/index.html#overview",
    "title": "Research Scientist Interview Guide",
    "section": "Overview",
    "text": "Overview\nThis guide outlines a comprehensive and practical preparation strategy for Research Scientist interviews across academia, FAANG research labs, applied ML groups, and frontier model companies (OpenAI, DeepMind, Anthropic, NVIDIA, Meta FAIR). It blends real-world expectations from hiring managers with the lived experience of preparing for and interviewing with research teams.\n\n\n\nResource\nLink\n\n\n\n\nResearch Scientist\nPreparation Guide\n\n\nData Science\nData Science Notes\n\n\nStatistical Learning\nStatistics Notes\n\n\nLLM Curriculum\nAI Agents Guide"
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#what-interviewers-evaluate",
    "href": "blog/technotes_20251102_research_guide/index.html#what-interviewers-evaluate",
    "title": "Research Scientist Interview Guide",
    "section": "What interviewers evaluate",
    "text": "What interviewers evaluate\nResearch interviews revolve around a single core question:\nCan you turn an ambiguous problem into a clear idea, an experiment, a result, and an impact?\nTo answer that, teams evaluate:\n\nResearch impact: clarity of motivation, novelty, reproducibility, and measurable progress over baselines.\nTechnical depth: applied math, ML fundamentals, experimental rigor, ablations, and error analysis.\nSystems intuition: how research turns into real systems‚Äîdata, pipelines, infra, metrics, drift, safety.\nExecution: ability to scope, plan, prototype, debug, iterate, and deliver.\nCommunication & collaboration: clarity with engineers, PMs, scientists, and leadership.\nCulture/LP fit: scientific judgment, ownership, collaboration, and cultural alignment.\n\n\n\n\n\n\n\nTip\n\n\n\nAlways highlight your contribution. Summarize each project as:\nproblem ‚Üí gap ‚Üí idea ‚Üí method ‚Üí evidence ‚Üí limitations ‚Üí next steps ‚Üí impact."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#interview-process-at-a-glance",
    "href": "blog/technotes_20251102_research_guide/index.html#interview-process-at-a-glance",
    "title": "Research Scientist Interview Guide",
    "section": "Interview process at a glance",
    "text": "Interview process at a glance\nTypical stages\n1) Recruiter + HM intro ‚Üí 2) Tech/Research screens (coding, ML/math, paper deep dive) ‚Üí\n3) Onsite: research talk, systems/experimentation design, cross-functional, behavioral/bar raiser ‚Üí\n4) Debrief ‚Üí offer.\n(Use the SVG diagram you generated earlier or embed it with ![](research_scientist_interview_process.svg).)"
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#preparation-timeline-68-weeks",
    "href": "blog/technotes_20251102_research_guide/index.html#preparation-timeline-68-weeks",
    "title": "Research Scientist Interview Guide",
    "section": "Preparation timeline (6‚Äì8 weeks)",
    "text": "Preparation timeline (6‚Äì8 weeks)\nWeeks 1‚Äì2: Foundations & portfolio - Curate 2‚Äì3 flagship projects; write 1-page project briefs (problem, novelty, 3 results, open questions). - Refresh ML math: gradients, likelihoods, bias‚Äìvariance, generalization, off-policy vs on-policy RL. - DS&A 20‚Äì30 mins/day (arrays, hash maps, trees, graphs, DP‚Äîmedium level). - Draft talk outline; collect figures; start a reproducible repo.\nWeeks 3‚Äì4: Research talk + deep dives - Build slides (30/45/60 min versions). Timebox: Motivation 10% ‚Üí Method 35% ‚Üí Evidence 40% ‚Üí Limits + Roadmap 15%. - Prepare ablation stories and negative results; design a live error analysis demo if feasible. - Mock talks with labmates; iterate twice.\nWeeks 5‚Äì6: Systems & coding polish - 5 case studies: online inference, data pipelines, eval at scale, safety/guardrails, monitoring. - Practice 6‚Äì8 coding problems in 60-min sessions; review idioms (two-pointers, heap, BFS/DFS, topo sort). - Draft answers for 8‚Äì10 behavioral prompts using STAR(L).\nWeek 7+: Company-specific tuning - Read team papers/repos; align your roadmap slide to their charter. - Prepare 8‚Äì12 questions to ask (below). - Dry run full onsite (talk + 3 interviews + behavioral) in a single sitting."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#research-portfolio-deep-dive",
    "href": "blog/technotes_20251102_research_guide/index.html#research-portfolio-deep-dive",
    "title": "Research Scientist Interview Guide",
    "section": "Research portfolio deep dive",
    "text": "Research portfolio deep dive\nFor each project, be ready to answer: - Gap: What prior SOTA did not address? Why now? - Assumptions: Distributional, structural, or operational assumptions‚Äîhow validated? - Method: Key design choices (loss, architecture, training regime, priors/constraints). - Evidence: Metrics that matter (with CIs); strongest ablation; hardest failure case. - Impact: External adoption, dataset/code release, internal KPI movement, patents. - Next: What would you do with 3 months & a small team?\nArtifacts checklist - 10‚Äì12 figure slide deck (vector PDFs), 1-page PDF overview, GitHub README with quickstart, repro seed + script."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#technical-machine-learning-knowledge-what-to-refresh",
    "href": "blog/technotes_20251102_research_guide/index.html#technical-machine-learning-knowledge-what-to-refresh",
    "title": "Research Scientist Interview Guide",
    "section": "Technical machine learning knowledge (what to refresh)",
    "text": "Technical machine learning knowledge (what to refresh)\n\nRL: policy gradient theorem; advantage estimation; PPO/TRPO constraints; off-policy (DQN/TD3/SAC); safe RL & constraints; exploration vs exploitation; eval instability & seeding.\nDeep learning: optimization (warmup, cosine decay, AdamW), regularization (dropout, mixup, label-smoothing), attention/transformers, LoRA/parameter-efficient finetuning.\nStatistics & probabilistic modeling: MLE/MAP; conjugacy; posterior predictive; calibration (ECE), uncertainty (epistemic vs aleatoric); A/B testing pitfalls.\nGenerative models: diffusion schedule & guidance, VAEs ELBO, GAN stability.\nLLMs: instruction tuning, RAG retrieval quality, eval (exact match, nDCG, win-rates), toxicity & safety filters, hallucination mitigation.\nVision/multimodal: contrastive learning, detection/segmentation metrics (mAP, IoU), data augmentations."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#ml-systems-experimentation-design",
    "href": "blog/technotes_20251102_research_guide/index.html#ml-systems-experimentation-design",
    "title": "Research Scientist Interview Guide",
    "section": "ML systems & experimentation design",
    "text": "ML systems & experimentation design\n5-step template 1. Clarify goal (user KPI ‚ÜîÔ∏é technical metric; online vs offline).\n2. Data (sources, labeling strategy, noise, sampling, privacy).\n3. Model & infra (baseline ‚Üí candidate ‚Üí serving path; latency, cost, reliability).\n4. Evaluation (offline metrics + counterfactual replays + online guardrails; slicing).\n5. Risk & safety (bias, misuse, red-teaming, rollback plan, observability).\nExample prompt (outline answer)\n‚ÄúDesign a near real-time anomaly detector for a power grid substation.‚Äù\n- KPI: reduce outage MTTR by 20%; constraints: &lt;200 ms latency, 99.9% uptime.\n- Data: PMU/SCADA streams; label via weak supervision + operator tags.\n- Baseline: statistical thresholds; Model: streaming autoencoder + EWMA residuals.\n- Eval: ROC-AUC offline, time-to-detect, false alarms/day; shadow deploy ‚Üí phased rollout.\n- Safety: fail-open; human-in-the-loop; drift detector; incident playbook."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#coding-algorithmic-skills",
    "href": "blog/technotes_20251102_research_guide/index.html#coding-algorithmic-skills",
    "title": "Research Scientist Interview Guide",
    "section": "Coding & algorithmic skills",
    "text": "Coding & algorithmic skills\n\nAim for clean, correct, then optimal. Speak invariants, test cases, and complexity out loud.\nPatterns to practice: two-pointers, sliding window, monotonic stack, BFS/DFS, topological sort, binary search on answer, Dijkstra/Union-Find, prefix sums, DP on sequences/trees.\nML-adjacent coding: vectorized NumPy, PyTorch modules/forward pass, dataloaders, batching, mixed precision, sanity checks."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#research-talk-structure-slides",
    "href": "blog/technotes_20251102_research_guide/index.html#research-talk-structure-slides",
    "title": "Research Scientist Interview Guide",
    "section": "Research talk: structure & slides",
    "text": "Research talk: structure & slides\nSlide budget (45 min talk + Q&A) - Title & takeaway (1), Motivation (2), Problem/Gap (2), Method (5), Results (6), Ablations (3), Error analysis (2), Limits (1), Roadmap/fit (2).\nDos - One idea per slide; consistent color for your method; readable axes; include n and CI.\n- Put the thesis of each slide in the title: ‚ÄúPhysics constraints cut violations by 38% at same cost.‚Äù\nDon‚Äôts - Crowded plots, cherry-picked examples, unanchored qualitative claims, tiny captions."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#behavioral-star-research-flavors",
    "href": "blog/technotes_20251102_research_guide/index.html#behavioral-star-research-flavors",
    "title": "Research Scientist Interview Guide",
    "section": "Behavioral: STAR + research flavors",
    "text": "Behavioral: STAR + research flavors\nUse STAR: Situation, Task, Action, Result, Learning.\nPrepare 6 stories: conflict, failure, leadership without authority, speed vs quality, mentoring, cross-team project.\nExample prompt\n‚ÄúTell me about a time your experiment invalidated a roadmap item.‚Äù\n- S/T: critical Q3 milestone hinged on SOTA surpassing baseline.\n- A: pre-registered analysis; ran holdout; flagged negative lift; proposed minimal viable alternative.\n- R: saved ~6 wks eng time; reallocated to data quality; shipped smaller win.\n- L: add ‚Äúearly stop‚Äù gates; improved pre-mortem checklist."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#recommended-resources",
    "href": "blog/technotes_20251102_research_guide/index.html#recommended-resources",
    "title": "Research Scientist Interview Guide",
    "section": "Recommended resources",
    "text": "Recommended resources\n\nPapers: recent NeurIPS/ICLR/ICML tracks relevant to the team; read 2‚Äì3 team papers.\n\nBooks: Designing Machine Learning Systems (Huyen), Deep Learning (Goodfellow), ESL (HTF), Probabilistic ML (Barber/Murphy).\n\nPractice: LeetCode medium sets; pair-program ML design prompts; mock talks."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#example-technical-research-questions",
    "href": "blog/technotes_20251102_research_guide/index.html#example-technical-research-questions",
    "title": "Research Scientist Interview Guide",
    "section": "Example technical & research questions",
    "text": "Example technical & research questions\n\nSummarize the core contribution of your latest paper in two sentences.\n\nWhich ablation most strongly supports your claim? Which one failed and why?\n\nHow would you adapt your method under 10√ó less data? Under severe shift?\n\nWhat is your evaluation blind spot today? How would you close it?\n\nExplain epistemic vs.¬†aleatoric uncertainty with a concrete modeling choice.\n\nFor PPO, where does instability come from and how do you diagnose it?\n\nDesign a reliable RAG system for safety-critical queries‚Äîretrieval, scoring, guardrails, and evaluation."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#ask-the-interviewer",
    "href": "blog/technotes_20251102_research_guide/index.html#ask-the-interviewer",
    "title": "Research Scientist Interview Guide",
    "section": "‚ÄúAsk the interviewer‚Äù",
    "text": "‚ÄúAsk the interviewer‚Äù\n\nUse the set that best fits the team. If time is short, ask the Top 3 in each block.\n\n\nHiring Manager (core, any research team)\n\nTop 3\n\nWhat research bets matter most in the next 6‚Äì12 months, and how will you measure success?\nWhat makes a ‚Äúhell-yes‚Äù hire here after 90 days? What work would signal that?\nHow do ideas transition from a paper/prototype to production or a public result?\n\nHow is impact recognized‚Äîpublications, product metrics, patents, internal adoption?\nWhat are examples of projects that didn‚Äôt land? Why, and what changed afterward?\nWhere are the biggest data/infra bottlenecks that a new scientist can unlock?\n\n\n\n\nResearch Scientists (peer scientists)\n\nTop 3\n\nWhich canonical datasets/eval harnesses are used for your area? How are baselines enforced?\nWhat‚Äôs a recent ablation or negative result that changed your roadmap?\nHow do you share/replicate experiments (internal tooling, seeds, result store)?\n\nHow are collaborations formed across teams? Any ‚Äúplatform‚Äù teams I should align with?\nWhat‚Äôs the cadence for paper reviews, reading groups, and internal talks?\n\n\n\n\nEngineers / MLEs (production & infra)\n\nTop 3\n\nWhat are the serving constraints (latency, throughput, cost) and reliability SLOs?\nWhat‚Äôs the path from notebook ‚Üí feature store ‚Üí online eval ‚Üí rollout/rollback?\nHow do you monitor drift and failures in the wild? What‚Äôs the on-call/ownership model?\n\nWhat‚Äôs the CI/CD story for models (gating tests, shadow, canary, A/B infra)?\nWhat would you change in our current stack if you could?\n\n\n\n\nPM / Cross-functional (applied impact)\n\nTop 3\n\nWhich decision or workflow actually changes if this model improves by X%?\nWhat is the single metric you‚Äôd show leadership to justify continued investment?\nWhat risks (safety, bias, misuse) keep you up at night for this application?\n\nWhere does data come from and how does quality/coverage limit the roadmap?\n\n\n\n\nRecruiter / Compensation\n\nLevel targeting and calibration‚Äîwhat evidence best demonstrates readiness for this level?\nPublication & open-source policy (authors, timing, preprints), conference travel norms.\nVisa/relocation timeline; expected hire start window and interview re-try policy."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#example-domain-specific",
    "href": "blog/technotes_20251102_research_guide/index.html#example-domain-specific",
    "title": "Research Scientist Interview Guide",
    "section": "Example Domain-specific",
    "text": "Example Domain-specific\n\nIf the team is RL / Control (energy, robotics, autonomy)\n\nWhat control horizon & loop latency are assumed (e.g., 200 ms, 1 s)? Any hard real-time constraints?\nHow are safety constraints enforced (e.g., physics-informed losses, shielded RL, reachability)?\nWhat are the reference environments (e.g., CityLearn/PowerGym, IEEE 13/34/123 bus, HIL)?\nHow do sim-to-real gaps show up, and how do you mitigate them (domain randomization, calibration)?\nWhich offline evaluation and counterfactual replay methods are trusted before online trials?\nWhat‚Äôs the bar for replacing a heuristic/OPF with an RL policy (guardrails, rollback, audits)?\n\n\n\nIf the team is LLM / RAG / GenAI\n\nRetrieval stack: index type, chunking, rerankers, eval (nDCG, recall@k, answer faithfulness).\nHallucination budget & safety: filters/guardrails, red-teaming, and incident handling.\nFinetuning strategy: SFT/LoRA vs.¬†prompt-only; distillation plans; model/versioning policy.\nWhat constitutes ‚Äúwin‚Äù in offline eval vs.¬†human eval? How do you resolve conflicts?\nData governance: PII/PHI handling, dedup, license compliance, auto-eval for drift.\n\n\n\nIf the team is Vision / Multimodal\n\nCanonical datasets & metrics (COCO mAP, IoU, retrieval R@k); how are domain shifts handled?\nLabeling strategy & quality control; synthetic data or augmentation policies.\nDeployment constraints: throughput on edge vs.¬†server; quantization/compilation toolchain.\nFailure modes that matter most (false positives/negatives, OOD, adversarial artifacts).\n\n\n\n\nIf you only have time for 3 questions (universal)\n\nStrategy: What is the one result you‚Äôd want me to deliver in 6 months that proves this hire was a ‚Äúyes‚Äù?\n\nExecution: What is the critical bottleneck (data, infra, evaluation) preventing faster progress today?\n\nFit: Which strengths would make me the complement to the current team‚Äôs skills?"
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#checklists",
    "href": "blog/technotes_20251102_research_guide/index.html#checklists",
    "title": "Research Scientist Interview Guide",
    "section": "Checklists",
    "text": "Checklists\nDay-before technical Interview\n\nTalk readiness: 30/45/60-min versions; 1-sentence thesis; clearly mark your contributions.\nAblations & limits: 1 strongest ablation you can defend; 1 negative result and what it taught you.\nPaper deep dives: be ready to derive the key equation/algorithm; compare to 2 baselines with numbers.\nMath/ML refresh: RL (policy gradient, GAE, PPO/TRPO intuition), DL (optimizers, regularization), stats (MLE vs MAP, bias‚Äìvariance, eval metrics).\nCoding drills: 2 timed mediums using core patterns (two-pointers, BFS/DFS, heap, topo sort, DP); practice test-first pseudocode.\nSystems prompts: outline 3 cases (data ‚Üí model ‚Üí eval ‚Üí guardrails ‚Üí rollout) you can walk through crisply.\nQ&A bank: 10 answers you can deliver fast (assumptions, failure modes, robustness, scalability, safety).\n\nDay-of Interview\n\nOpen strong: restate problem + constraints; define the success metric before proposing solutions.\nReasoning first: outline 2‚Äì3 approaches; justify trade-offs; state target time/space complexity.\nCoding round: implement incrementally; speak invariants and edge cases; analyze complexity after passing tests.\nResearch talk: show the central figure; defend an ablation; admit a limitation and the next experiment.\nDesign/experimentation: baseline ‚Üí candidate ‚Üí eval plan; define slices; propose risks & rollback.\nClose each round: 30‚Äì60s recap with decision, trade-offs, and ‚Äúnext step‚Äù you‚Äôd run."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#offer-debrief-negotiation",
    "href": "blog/technotes_20251102_research_guide/index.html#offer-debrief-negotiation",
    "title": "Research Scientist Interview Guide",
    "section": "Offer, Debrief & Negotiation",
    "text": "Offer, Debrief & Negotiation\n1) Right after the loop\n\nKeep a short brag doc: 5‚Äì8 bullets tying your work to measurable impact (citations, benchmarks, improvements).\nSend thank-you notes; ask the recruiter for decision timeline and whether the team needs any follow-ups (extra slides, code pointers).\n\n2) Debrief (if you don‚Äôt get detailed feedback)\n\nAsk for 3 bullets: (i) strengths that stood out, (ii) top concern, (iii) what would change the decision next time.\nIf there‚Äôs a miscalibration (e.g., level/scope), propose a targeted follow-up (short tech screen or focused deep dive).\n\n3) Offer review (when it comes)\n\nBreak it down: base + bonus + equity/RSUs (grant, vesting, refreshers) + sign-on + extras (compute budget, conference travel, publication policy, patent bonus).\nClarify: level, title, team mandate, location policy, start date, performance review cycles, and conference/OSS policies.\n\n4) Negotiation (impact-first)\n\nAnchor with scope & impact (what you can deliver in 6‚Äì12 months), plus comparables (peer offers or market data for the same level/geo).\nPrioritize asks (pick 2‚Äì3): sign-on / equity / level / research budget / conf travel.\n\nSample script:\n‚ÄúGiven the scope (X) and the impact I‚Äôm positioned to deliver (Y), I‚Äôm targeting total comp of Z at level L. If level is fixed, increasing equity by A or adding a B sign-on would bridge the gap. I‚Äôd also value C (e.g., conference travel commitment).‚Äù\n\n5) Timelines\n\nIf you need time: ‚ÄúI‚Äôm very excited. To make a well-considered decision, could we set a reply date of ? I want to complete one pending loop and compare scopes fairly.‚Äù\nIf there‚Äôs an exploding deadline, ask for a short extension in exchange for a firm decision date and clear intent.\n\n6) If rejected\n\nRequest specific growth areas and ask whether a re-interview window (e.g., 6 months) with a targeted bar (e.g., systems/experiments) is possible."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#mentorship",
    "href": "blog/technotes_20251102_research_guide/index.html#mentorship",
    "title": "Research Scientist Interview Guide",
    "section": "Mentorship",
    "text": "Mentorship\nIf you‚Äôd like feedback on your talk, paper deep dive, or a full mock onsite, reach me at cs.kundann@gmail.com."
  },
  {
    "objectID": "rpkg/safe/index.html",
    "href": "rpkg/safe/index.html",
    "title": "Safe DRL",
    "section": "",
    "text": "This oding.\nPlanned content:\n\nE\n2\nEu"
  },
  {
    "objectID": "rpkg/qtwAcademic/index.html",
    "href": "rpkg/qtwAcademic/index.html",
    "title": "qtwAcademic",
    "section": "",
    "text": "qtwAcademic stands for Quarto Websites for Academics, which provides a few Quarto templates for Quarto website that are commonly used by academics.\nThe templates are designed to make it quick and easy for users with little or no Quarto experience to create a website for their personal portfolio or courses. Each template is fully customizable once the user is more familiar with Quarto.\nRead more about the package here.\n\nTemplates\nSo far, 3 templates have been implemented in this package:\n\nPersonal website\nWebsite for courses or workshops\nMinimal website template that can be easily customized\n\nYou can find more details on each option in the vignettes."
  },
  {
    "objectID": "rpkg/drl_vvc/index.html",
    "href": "rpkg/drl_vvc/index.html",
    "title": "DRL for Smart Energy Systems",
    "section": "",
    "text": "Anxperiments\nCode"
  },
  {
    "objectID": "rpkg/uncertainty/index.html",
    "href": "rpkg/uncertainty/index.html",
    "title": "uncertainity",
    "section": "",
    "text": "cstime provides convenient and consistent conversion between\n\nisoyear\nisoweek\ncalyear\nseason week (u)"
  },
  {
    "objectID": "teaching/coms3630/index.html#introduction-to-database-management-systems",
    "href": "teaching/coms3630/index.html#introduction-to-database-management-systems",
    "title": "COMS 3630: Introduction to Database Management Systems",
    "section": "",
    "text": "COMS 3630 offers a comprehensive introduction to database systems, covering both theoretical foundations and practical implementation. Students explore various data models (relational, object-oriented, and semistructured), learn query languages such as SQL and NoSQL, and build full-stack applications that integrate modern database backends with web interfaces.\nThe course emphasizes database design, optimization, and application development, using tools like MySQL, MongoDB, and Neo4J.\n\n\n\nFigure: Conceptual overview of database management systems and their core components."
  },
  {
    "objectID": "teaching/coms3090/index.html",
    "href": "teaching/coms3090/index.html",
    "title": "COMS 3090: Software Development Practices",
    "section": "",
    "text": "COMS 3090 provides a practical introduction to software engineering principles, including process models, requirements engineering, system design, testing, and project management.\nThe course emphasizes collaborative software development through a semester-long group project, focusing on teamwork, accountability, and real-world software delivery.\n\n\n\nFigure: Iterative software development process integrating design, implementation, and testing phases."
  },
  {
    "objectID": "teaching/coms3090/index.html#coms-3090-software-development-practices",
    "href": "teaching/coms3090/index.html#coms-3090-software-development-practices",
    "title": "COMS 3090: Software Development Practices",
    "section": "",
    "text": "COMS 3090 provides a practical introduction to software engineering principles, including process models, requirements engineering, system design, testing, and project management.\nThe course emphasizes collaborative software development through a semester-long group project, focusing on teamwork, accountability, and real-world software delivery.\n\n\n\nFigure: Iterative software development process integrating design, implementation, and testing phases."
  },
  {
    "objectID": "teaching/coms3620/index.html",
    "href": "teaching/coms3620/index.html",
    "title": "COMS 3620: Object-Oriented Analysis and Design",
    "section": "",
    "text": "COMS 3620 is a project-based course focused on object-oriented requirements analysis and system design.\nStudents learn to apply Unified Modeling Language (UML) and design patterns to develop robust, scalable, and maintainable software systems.\nThe course emphasizes teamwork, iterative development, and effective communication of design decisions through documentation and presentations.\n\n\n\nFigure: UML-driven process for analyzing, designing, and implementing object-oriented systems.\n\n\n\n\n\n\nProcedural & Data Abstraction\n\nModularity, Objects, and State\n\nUnified Modeling Language (UML)\n\nObject-Oriented Design Principles & Patterns\n\nMetalinguistic Abstraction\n\nSoftware Architecture & Evaluation\n\nTeam Presentations and Final Project Showcase\n\n\n\n\n\nComputer Science Graduate Teaching Assistant (Fall 2024)\n\nAs a Teaching Assistant for COMS 3620, I provided end-to-end guidance to students through both the design and implementation phases of large-scale object-oriented projects. My contributions included:\n\nUML & Design Mentorship: Assisted students in modeling system requirements using UML (use case diagrams, class diagrams, sequence diagrams).\nProject Guidance: Advised student teams during the full development cycle‚Äîfrom requirement analysis and domain modeling to implementation and testing.\nDesign Critique & Feedback: Evaluated and gave feedback on design homeworks, helping students strengthen their reasoning with design principles and patterns.\nTechnical Assistance: Supported Java implementation of OOPS designs, clarifying concepts like inheritance, polymorphism, abstraction, and class hierarchies.\nPresentation Coaching: Helped teams prepare and deliver clear, well-structured final project presentations and reports.\n\nThis experience strengthened my expertise in software architecture, model-driven design, and pedagogical mentoring for complex system development."
  },
  {
    "objectID": "teaching/coms3620/index.html#coms-3620-object-oriented-analysis-and-design",
    "href": "teaching/coms3620/index.html#coms-3620-object-oriented-analysis-and-design",
    "title": "COMS 3620: Object-Oriented Analysis and Design",
    "section": "",
    "text": "COMS 3620 is a project-based course focused on object-oriented requirements analysis and system design.\nStudents learn to apply Unified Modeling Language (UML) and design patterns to develop robust, scalable, and maintainable software systems.\nThe course emphasizes teamwork, iterative development, and effective communication of design decisions through documentation and presentations.\n\n\n\nFigure: UML-driven process for analyzing, designing, and implementing object-oriented systems.\n\n\n\n\n\n\nComputer Science Graduate Teaching Assistant (Fall 2024)\n\nAs a Teaching Assistant for COMS 3620, I provided end-to-end guidance to students through both the design and implementation phases of large-scale object-oriented projects. My contributions included:\n\nUML & Design Mentorship: Assisted students in modeling system requirements using UML (use case diagrams, class diagrams, sequence diagrams).\nProject Guidance: Advised student teams during the full development cycle‚Äîfrom requirement analysis and domain modeling to implementation and testing.\nDesign Critique & Feedback: Evaluated and gave feedback on design homeworks, helping students strengthen their reasoning with design principles and patterns.\nTechnical Assistance: Supported Java implementation of OOPS designs, clarifying concepts like inheritance, polymorphism, abstraction, and class hierarchies.\nPresentation Coaching: Helped teams prepare and deliver clear, well-structured final project presentations and reports.\n\nThis experience strengthened my expertise in software architecture, model-driven design, and pedagogical mentoring for complex system development."
  },
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "üìÑ Resume"
  },
  {
    "objectID": "cv.html#professional-experience",
    "href": "cv.html#professional-experience",
    "title": "Curriculum Vitae",
    "section": " Professional Experience",
    "text": "Professional Experience\n\n\n\n\n\nNational Renewable Energy Laboratory (NREL)\n\n\n\n\n\nMachine Learning Engineer (Intern)\n\n\n May 2024 ¬†‚Äî¬† Jan 2025 \n\n\n\n\nDeveloped novel machine learning models for automated network topology inference and resilient control policy optimization for complex distributed systems under extreme scenarios\nDesigned and developed semi‚Äësupervised learning approaches to tackle the challenge of limited labeled data in networks, achieving 98% improvement in model accuracy with varying labeled data.\nPaper ‚ÄùAdvanced Semi‚ÄëSupervised Learning with Uncertainty Estimation for Phase Identification in Distribution Systems‚Äù accepted at IEEE Power & Energy Society General Meeting (PES GM) 2025.\n\n\n\n\n\n\n\nComcast\n\n\n\n\n\nSoftware Engineer\n\n\n Jul 2019 ¬†‚Äî¬† Feb 2020 \n\n\n\n\nDesigned and implemented real‚Äëtime data processing pipelines using Amazon Kinesis and RabbitMQ, processing 1TB+ daily data for fraud detection and system monitoring.\nDeveloped machine learning models for anomaly detection and user behavior analysis, reducing fraudulent activities by 70% through predictive analytics.\nCreated interactive dashboards using Presto DB and Python visualization tools, enabling real‚Äëtime monitoring of network performance metrics and fraud patterns.\n\n\n\n\n\n\nIBM\n\n\n\n\n\nSoftware Engineer\n\n\n Jan 2019 ¬†‚Äî¬† Jun 2019 \n\n\n\n\nLed cloud infrastructure optimization using OpenShift, implementing auto‚Äëscaling solutions that reduced operational costs by 30%.\nDeveloped a comprehensive monitoring system using Grafana and Flask, providing real‚Äëtime visibility into 100+ cloud servers.\nImplemented automated performance monitoring and alerting system, reducing incident response time by 60%.\n\n\n\n\n\n\nHewlett Packard Enterprise (HPE)\n\n\n\n\n\nSoftware Engineer\n\n\n Apr 2017 ¬†‚Äî¬† Dec 2018 \n\n\n\n\n\nSpearheaded migration of critical applications from HPI to HPE domain, ensuring zero downtime during transition.\nImplemented OAuth 2.0 authentication system and RESTful services using Spring Boot, securing applications serving 50K+ users.\nDesigned and deployed microservices architecture on Apache/WebLogic servers, improving system response time by 40%.\n\n\n\n\n\n\nTata Consultancy Services (TCS)\n\n\n\n\n\nSystem Engineer\n\n\n Jul 2012 ¬†‚Äî¬† Dec 2015 \n\n\n\n\n\nEngineered high‚Äëperformance ETL pipelines for data warehouse integration, processing 100GB+ daily data volumes.\nOptimized database performance through advanced SQL tuning and indexing strategies, reducing query execution time by 70%.\nReceived excellence award for achieving $100K cost savings through database optimization initiatives."
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "Curriculum Vitae",
    "section": " Education",
    "text": "Education\n\n\n\n\n\nIowa State University\n\n\n\n\n\nPh.D.¬†in Computer Science (Minor: Statistics)\n\n\n 2020 ¬†‚Äî¬† 2025 (Expected) \n\n\n\n\n\nResearch: Deep RL, Physics-Informed AI, Uncertainty Quantification, LLM Agents\nCourses: Deep Learning, NLP, Statistical Theory, Empirical Methods, Algorithm, Databases"
  },
  {
    "objectID": "cv.html#teaching-experience",
    "href": "cv.html#teaching-experience",
    "title": "Curriculum Vitae",
    "section": " Teaching Experience",
    "text": "Teaching Experience\n\n\n\n\n\nIowa State University\n\n\n\n\n\nTeaching Assistant\n\n\n 2020 ¬†‚Äî¬† 2025 \n\n\n\nDepartment of Computer Science\n\nSupported undergraduate/graduate courses including Software Development Practices, Database Systems, and Spreadsheets.\nLed weekly lab sessions, assisted students with debugging and conceptual challenges, and held office hours.\nDesigned assignments and quizzes aligned with real-world workflows and agile development practices.\nMentored students on semester-long capstone projects simulating software engineering team experiences.\n\n\n Teaching Portfolio"
  },
  {
    "objectID": "cv.html#research-experience",
    "href": "cv.html#research-experience",
    "title": "Curriculum Vitae",
    "section": " Research Experience",
    "text": "Research Experience\n\n\n\n\n\nIowa State University\n\n\n\n\n\nResearch Assistant\n\n\n Aug 2022 ¬†‚Äî¬† Jul 2025 \n\n\n\n\nResearch on Physics‚ÄëInformed Deep Reinforcement Learning for Critical Infrastructure Systems, focusing on Intelligent Resource Management and Security in Large‚ÄëScale Distributed Networks.\nApplied computational deep reinforcement learning algorithms in a Smart Energy System to analyze power simulation data, minimizing voltage violations, power loss, and control errors.\nDeveloped physics‚Äëinformed DRL algorithms incorporating domain‚Äëspecific physical constraints, achieving 30% improvement in resource allocation efficiency and reducing system violations in complex distributed networks.\nDesigned and implemented adversarial attack detection and mitigation frameworks for AI models in critical systems, enhancing robustness against security threats through systematic testing and defensive techniques.\nCreated novel transfer learning methodologies enabling DRL models to adapt across varying network sizes and topologies, reducing training time by 40% for new configurations.\nDeveloped Python‚Äëbased simulation and control framework integrating real‚Äëtime hardware (OPAL‚ÄëRT and OpenDSS) with distributed systems.\nLeveraged LLM‚Äëdriven reasoning and contextual understanding within simulation environments to support real‚Äëtime adaptive control, human‚ÄëAI collaboration, and predictive system optimization.\n\n\n\n\nResearch Assistant\n\n\n Aug 2020 ¬†‚Äî¬† Jul 2022 \n\n\n\n\nResearch on Deep Reinforcement Learning (DRL) and Safety‚ÄëCritical Learning for Autonomous Systems, with focus on perception, control, and decision‚Äëmaking in high‚Äëstakes environments.\nUtilized CARLA simulator for vision‚Äëbased autonomous driving tasks, including perception, object detection, trajectory planning, and policy learning in complex traffic scenarios.\nApplied deep computer vision models for object recognition, semantic segmentation, and sensor fusion, enabling robust situational awareness in autonomous driving and robotics.\n\n\n Research Portfolio"
  },
  {
    "objectID": "cv.html#skills",
    "href": "cv.html#skills",
    "title": "Curriculum Vitae",
    "section": " Skills",
    "text": "Skills\n\n\n\nProgramming\n\n\nPython, R, Java, C++, SAS, MATLAB, SQL, HTML/CSS, JavaScript (Node.js, React)\n\n\nMachine/Deep Learning\n\n\nscikit-learn, TensorFlow, PyTorch, pandas, Matplotlib, Seaborn, Gym, RLlib\n\n\nLLMs & NLP\n\n\nOpenAI API, Hugging Face Transformers, LangChain, LlamaIndex, RAG (retrievers, chunking, reranking), vector DBs (FAISS, Chroma, Pinecone), prompt engineering & structured outputs, evaluation (Ragas, Promptfoo)\n\n\nAgentic Systems & Orchestration\n\n\nLangGraph (stateful workflows), LangChain Agents (ReAct/MRKL/tools), function/tool calling, multi-agent design, planning & memory, tool-use (search/code/execution), guards & grounding\n\n\nHPC & Big Data\n\n\nHadoop, Hive, Spark, Kafka, Kinesis, SLURM, MPI, OpenMP\n\n\nSimulation & Modeling\n\n\nOPAL-RT, OpenDSS (Power), CARLA (Autonomous Driving)\n\n\nOptimization\n\n\nGurobi, Pyomo, BoTorch, Optuna, Hyperopt\n\n\nVisualization & GIS\n\n\nTableau, ArcGIS, Leaflet\n\n\nCloud & DevOps\n\n\nAWS (EC2, S3, Lambda), GCP, Docker, Kubernetes, Git, Terraform, Jenkins, CircleCI"
  },
  {
    "objectID": "cv.html#honors-awards",
    "href": "cv.html#honors-awards",
    "title": "Curriculum Vitae",
    "section": " Honors & Awards",
    "text": "Honors & Awards\n\nSelected, Seventh Workshop on Autonomous Energy Systems @ NREL (2024)\nSelected, ByteBoost Workshop on Accelerating HPC Research Skills (2024)\nSelected, Oxford Machine Learning Summer School (OxML) (2022)\nExcellence Award, Database Optimization @ TCS\n2nd Place, BAJA SAE India (Safest Terrain Vehicle Category, National Level)"
  },
  {
    "objectID": "cv.html#service",
    "href": "cv.html#service",
    "title": "Curriculum Vitae",
    "section": " Service",
    "text": "Service\n\nReviewer:\n\nIEEE Transactions on Industrial Informatics (2025)\nConference on Neural Information Processing Systems (Ethics)(2025)\nIEEE Transactions on Neural Networks and Learning Systems (2024)\nIEEE PES GM, Grid Edge & ISGT (2023, 2024)\n\nMock Interviewer: Supporting underrepresented minorities in tech.\nVolunteer, Prayaas India (BIT): NGO providing quality education to underprivileged children in slums and villages."
  },
  {
    "objectID": "cv.html#projects",
    "href": "cv.html#projects",
    "title": "Curriculum Vitae",
    "section": " Projects",
    "text": "Projects\n\n\n   RAG-Enhanced Energy Advisor Retrieval-augmented LLM agent for adaptive control and decision.  \n   LLM-Driven Grid Planner Natural-language-guided reinforcement learning for smart grid management.  \n   LLM‚ÄëPowered Energy Optimizer Multi‚Äëbuilding energy optimization in CityLearn with LLM guidance.  \n\n\n üìÅ Check My Projects"
  },
  {
    "objectID": "llms/llms10.html",
    "href": "llms/llms10.html",
    "title": "Classification of Foods Based on their Quality",
    "section": "",
    "text": "App  Code \nThe Soil Health Roadmap is a science-based guide to maintaining and improving soil health in eight focus areas across Washington state.\nFor each focus area, I created crop and soil maps using the arcpy Python package. I then summarized the crop acreage and soil properties in interactive ArcGIS dashboards to complement the Paper."
  },
  {
    "objectID": "llms/llms5/index.html",
    "href": "llms/llms5/index.html",
    "title": "Noreden",
    "section": "",
    "text": "Noreden"
  },
  {
    "objectID": "llms/llms3/index.html",
    "href": "llms/llms3/index.html",
    "title": "Chatbot Design using Retrieval‚ÄëAugmented Generation (RAG)",
    "section": "",
    "text": "Noreden"
  },
  {
    "objectID": "llms/llms1/index.html",
    "href": "llms/llms1/index.html",
    "title": "AI-Powered Patient Education System",
    "section": "",
    "text": "ggehr (read: gg E-H-R) stands for ggplot2 extension for EHR data, which provides a set of tools to facilitate EHR (Electronic Health Records) visualization.\nggehr package helps you make visualize EHR data, so that you can\n\nhave an overview of the mixed type information related to a patient;\nvisually identify the errors in data recording.\n\nLearn more about ggehr"
  },
  {
    "objectID": "llms/llms8.html",
    "href": "llms/llms8.html",
    "title": "P2P File Sharing Protocol",
    "section": "",
    "text": "App  Code \nThe Washington State Department of Agriculture developed WaCSE for the Washington State Conservation Commission to use in the Sustainable Farms and Fields (SFF) program. Intended users are the Conservation Commission, conservation districts, growers, and anyone interested in reducing agricultural greenhouse gas (GHG) emissions. This interactive tool estimates the reduction of GHG emissions from different conservation practices across Washington‚Äôs diverse counties."
  },
  {
    "objectID": "robo/robo8.html",
    "href": "robo/robo8.html",
    "title": "Classification of Foods Based on their Quality",
    "section": "",
    "text": "App  Code \nThe Soil Health Roadmap is a science-based guide to maintaining and improving soil health in eight focus areas across Washington state.\nFor each focus area, I created crop and soil maps using the arcpy Python package. I then summarized the crop acreage and soil properties in interactive ArcGIS dashboards to complement the Paper."
  },
  {
    "objectID": "robo/robo_6/index.html",
    "href": "robo/robo_6/index.html",
    "title": "Noreden",
    "section": "",
    "text": "Noreden"
  },
  {
    "objectID": "robo/robo_4/index.html",
    "href": "robo/robo_4/index.html",
    "title": "Chatbot Design using Retrieval‚ÄëAugmented Generation (RAG)",
    "section": "",
    "text": "Noreden"
  },
  {
    "objectID": "robo/robo_5/index.html",
    "href": "robo/robo_5/index.html",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "robo/robo_5/index.html#norwegian-surveillance-system-for-excess-mortality",
    "href": "robo/robo_5/index.html#norwegian-surveillance-system-for-excess-mortality",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "",
    "text": "NorMOMO"
  },
  {
    "objectID": "robo/robo_5/index.html#r-packages-for-mortality-surveillance",
    "href": "robo/robo_5/index.html#r-packages-for-mortality-surveillance",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "R packages for mortality surveillance",
    "text": "R packages for mortality surveillance\n(continue‚Ä¶)\n\nnowcast\nsplalert\nmortanor"
  },
  {
    "objectID": "robo/robo_5/index.html#collaboration-with-cause-of-death-registry",
    "href": "robo/robo_5/index.html#collaboration-with-cause-of-death-registry",
    "title": "Congressional Policy Analysis using ML and HPCA",
    "section": "Collaboration with Cause of Death Registry",
    "text": "Collaboration with Cause of Death Registry"
  },
  {
    "objectID": "robo/robo7.html",
    "href": "robo/robo7.html",
    "title": "Prompt Injection Attacks on LLM Medical Diagnosis by Symptom Elaboration",
    "section": "",
    "text": "Code \nThe goal of orcas is to scrape orca sighting data from the web and visualize it in maps and tables.\nI‚Äôve always had an affinity for the Southern Resident Killer Whales in the Salish Sea. The Center for Whale Research does a lot of really fascinating and important work monitoring their population. They post their survey data on their website; each encounter with the orcas is a separate webpage. I was both curious and intimidated by web scraping so I decided this would make a great case study and personal project. I also learned how to use custom icons in leaflet maps! üêã"
  },
  {
    "objectID": "teaching/coms4170/index.html#overview",
    "href": "teaching/coms4170/index.html#overview",
    "title": "COMS 4170: Software Testing",
    "section": "Overview",
    "text": "Overview\nThis course provides a rigorous study of software testing principles, methodologies, management strategies, and tools.\nTopics include coverage criteria, specification- and structure-based test design, integration, system and regression testing, automated test generation, GUI testing, mutation and metamorphic testing, and test management.\n\n\n\nFigure: Iterative flow of software testing key phases from requirements to closure."
  },
  {
    "objectID": "teaching/coms4170/index.html#learning-objectives",
    "href": "teaching/coms4170/index.html#learning-objectives",
    "title": "COMS 4170: Software Testing",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nDesign tests to meet realistic coverage criteria\nApply standard software testing techniques and tools\nGain hands-on experience with automation and at least one advanced testing method\n\n\nMy Role\n\nMy Role (Computer Science Graduate Teaching Assistant, Spring 2025)\n\n\nAssisted in delivering course content and reinforced core topics such as black-box and white-box testing, adequacy and coverage criteria, integration, and regression testing.\nSupported the design, grading, and feedback process for assignments and examinations.\nProvided one-on-one mentoring and technical guidance to help students strengthen their understanding of software reliability, testing tools, and debugging practices."
  },
  {
    "objectID": "teaching/coms4170/index.html#key-topics-covered",
    "href": "teaching/coms4170/index.html#key-topics-covered",
    "title": "COMS 4170: Software Testing",
    "section": "Key Topics Covered:",
    "text": "Key Topics Covered:\n\nPrinciples and methodologies of software testing\nTest design techniques, including black-box and white-box testing\nTest models, adequacy criteria, and coverage metrics\nIntegration, system, and regression testing strategies\nAutomated test generation and tool-based testing frameworks\nTest management, documentation, and process optimization\nAdvanced topics such as mutation testing, metamorphic testing, and AI-based testing approaches\n\n\nTextbook\nIntroduction to Software Testing, 2nd edition by Paul Ammann and Jeff Offutt"
  },
  {
    "objectID": "teaching/coms3630/index.html",
    "href": "teaching/coms3630/index.html",
    "title": "COMS 3630: Introduction to Database Management Systems",
    "section": "",
    "text": "COMS 3630 offers a comprehensive introduction to database systems, covering both theoretical foundations and practical implementation. Students explore various data models (relational, object-oriented, and semistructured), learn query languages such as SQL and NoSQL, and build full-stack applications that integrate modern database backends with web interfaces.\nThe course emphasizes database design, optimization, and application development, using tools like MySQL, MongoDB, and Neo4J.\n\n\n\nFigure: Conceptual overview of database management systems and their core components.\n\n\n\n\n\n\nEntity-Relationship (ER) Modeling\n\nRelational Model & Relational Algebra\n\nSQL Programming and Constraints\n\nNoSQL Systems (MongoDB, Neo4J)\n\nSchema Normalization & Data Dependencies\n\nDatabase Storage & Indexing\n\nCost Estimation & Query Optimization\n\nTransaction Management & Concurrency Control\n\nWeb Application Integration using SQL APIs & ORMs\n\nApplication Development using Host Languages (e.g., Python, Java)\n\n\n\n\n\nComputer Science Graduate Teaching Assistant (Spring 2023)\n\nAs a Teaching Assistant for COMS 3630, I supported over 100 students in understanding key database concepts and building end-to-end data-driven applications. My responsibilities included:\n\nLab Instruction & Demonstrations: Led weekly sessions on topics like SQL programming, ER modeling, and NoSQL databases (MongoDB, Neo4J).\nProject Mentorship: Guided students through semester-long projects, helping them design schemas, write efficient queries, and integrate databases with web applications.\nTechnical Support: Assisted students in implementing transactions, managing storage, and debugging issues related to query execution and performance.\nDesign Review & Grading: Evaluated assignments and database design submissions, providing constructive feedback aligned with best practices.\nOffice Hours: Offered one-on-one and group-based academic support on database internals, relational algebra, and query optimization strategies."
  },
  {
    "objectID": "teaching/coms3630/index.html#my-role",
    "href": "teaching/coms3630/index.html#my-role",
    "title": "COMS 3630: Introduction to Database Management Systems",
    "section": "My Role",
    "text": "My Role\n\nComputer Science Graduate Teaching Assistant (Spring 2023)\n\nAs a Teaching Assistant for COMS 3630, I supported over 100 students in understanding key database concepts and building end-to-end data-driven applications. My responsibilities included:\n\nLab Instruction & Demonstrations: Led weekly sessions on topics like SQL programming, ER modeling, and NoSQL databases (MongoDB, Neo4J).\nProject Mentorship: Guided students through semester-long projects, helping them design schemas, write efficient queries, and integrate databases with web applications.\nTechnical Support: Assisted students in implementing transactions, managing storage, and debugging issues related to query execution and performance.\nDesign Review & Grading: Evaluated assignments and database design submissions, providing constructive feedback aligned with best practices.\nOffice Hours: Offered one-on-one and group-based academic support on database internals, relational algebra, and query optimization strategies."
  },
  {
    "objectID": "teaching/coms3630/index.html#database-management-systems",
    "href": "teaching/coms3630/index.html#database-management-systems",
    "title": "COMS 3630: Introduction to Database Management Systems",
    "section": "",
    "text": "COMS 3630 offers a comprehensive introduction to database systems, covering both theoretical foundations and practical implementation. Students explore various data models (relational, object-oriented, and semistructured), learn query languages such as SQL and NoSQL, and build full-stack applications that integrate modern database backends with web interfaces.\nThe course emphasizes database design, optimization, and application development, using tools like MySQL, MongoDB, and Neo4J.\n\n\n\nFigure: Conceptual overview of database management systems and their core components.\n\n\n\n\n\n\nEntity-Relationship (ER) Modeling\n\nRelational Model & Relational Algebra\n\nSQL Programming and Constraints\n\nNoSQL Systems (MongoDB, Neo4J)\n\nSchema Normalization & Data Dependencies\n\nDatabase Storage & Indexing\n\nCost Estimation & Query Optimization\n\nTransaction Management & Concurrency Control\n\nWeb Application Integration using SQL APIs & ORMs\n\nApplication Development using Host Languages (e.g., Python, Java)\n\n\n\n\n\nComputer Science Graduate Teaching Assistant (Spring 2023)\n\nAs a Teaching Assistant for COMS 3630, I supported over 100 students in understanding key database concepts and building end-to-end data-driven applications. My responsibilities included:\n\nLab Instruction & Demonstrations: Led weekly sessions on topics like SQL programming, ER modeling, and NoSQL databases (MongoDB, Neo4J).\nProject Mentorship: Guided students through semester-long projects, helping them design schemas, write efficient queries, and integrate databases with web applications.\nTechnical Support: Assisted students in implementing transactions, managing storage, and debugging issues related to query execution and performance.\nDesign Review & Grading: Evaluated assignments and database design submissions, providing constructive feedback aligned with best practices.\nOffice Hours: Offered one-on-one and group-based academic support on database internals, relational algebra, and query optimization strategies."
  },
  {
    "objectID": "teaching/coms3630/index.html#course-description",
    "href": "teaching/coms3630/index.html#course-description",
    "title": "COMS 3630: Introduction to Database Management Systems",
    "section": "Course Description",
    "text": "Course Description\nCOMS 3630 offers a comprehensive introduction to database systems, covering both theoretical foundations and practical implementation. Students explore various data models (relational, object-oriented, and semistructured), learn query languages such as SQL and NoSQL, and build full-stack applications that integrate modern database backends with web interfaces.\nThe course emphasizes database design, optimization, and application development, using tools like MySQL, MongoDB, and Neo4J.\n\n\n\nFigure: Conceptual overview of database management systems and their core components."
  },
  {
    "objectID": "teaching/coms3630/index.html#learning-outcomes",
    "href": "teaching/coms3630/index.html#learning-outcomes",
    "title": "COMS 3630: Introduction to Database Management Systems",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of the course, students are expected to:\n\nDesign and implement relational databases using ER modeling and normalization techniques.\n\nDevelop database-driven applications using SQL, APIs, and ORM frameworks.\n\nWork with NoSQL systems including document-based (MongoDB) and graph-based (Neo4J) databases.\n\nUnderstand internal DBMS operations, including query processing, transaction management, and storage optimization."
  },
  {
    "objectID": "teaching/coms3630/index.html#topics-covered",
    "href": "teaching/coms3630/index.html#topics-covered",
    "title": "COMS 3630: Introduction to Database Management Systems",
    "section": "Topics Covered",
    "text": "Topics Covered\n\nEntity-Relationship (ER) Modeling\n\nRelational Model & Relational Algebra\n\nSQL Programming and Constraints\n\nNoSQL Systems (MongoDB, Neo4J)\n\nSchema Normalization & Data Dependencies\n\nDatabase Storage & Indexing\n\nCost Estimation & Query Optimization\n\nTransaction Management & Concurrency Control\n\nWeb Application Integration using SQL APIs & ORMs\n\nApplication Development using Host Languages (e.g., Python, Java)"
  },
  {
    "objectID": "teaching/coms3620/index.html#learning-outcomes",
    "href": "teaching/coms3620/index.html#learning-outcomes",
    "title": "COMS 3620: Object-Oriented Analysis and Design",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nUpon completing the course, students will be able to:\n\nAnalyze software requirements and model problem domains using UML.\n\nDesign robust object-oriented architectures following proven design principles.\n\nApply and justify the use of design patterns in software construction.\n\nProduce UML-based design documentation and diagrams.\n\nImplement OOPS designs in Java using inheritance, abstraction, and polymorphism.\n\nCommunicate and defend design decisions through written and oral presentations.\n\nCollaborate effectively in team-based development environments."
  },
  {
    "objectID": "teaching/coms3620/index.html#topics-covered",
    "href": "teaching/coms3620/index.html#topics-covered",
    "title": "COMS 3620: Object-Oriented Analysis and Design",
    "section": "Topics Covered",
    "text": "Topics Covered\n\nProcedural & Data Abstraction\n\nModularity, Objects, and State\n\nUnified Modeling Language (UML)\n\nObject-Oriented Design Principles & Patterns\n\nMetalinguistic Abstraction\n\nSoftware Architecture & Evaluation\n\nTeam Presentations and Final Project Showcase"
  },
  {
    "objectID": "teaching/coms3620/index.html#object-oriented-analysis-and-design",
    "href": "teaching/coms3620/index.html#object-oriented-analysis-and-design",
    "title": "COMS 3620: Object-Oriented Analysis and Design",
    "section": "",
    "text": "COMS 3620 is a project-based course focused on object-oriented requirements analysis and system design.\nStudents learn to apply Unified Modeling Language (UML) and design patterns to develop robust, scalable, and maintainable software systems.\nThe course emphasizes teamwork, iterative development, and effective communication of design decisions through documentation and presentations.\n\n\n\nFigure: UML-driven process for analyzing, designing, and implementing object-oriented systems.\n\n\n\n\n\n\nProcedural & Data Abstraction\n\nModularity, Objects, and State\n\nUnified Modeling Language (UML)\n\nObject-Oriented Design Principles & Patterns\n\nMetalinguistic Abstraction\n\nSoftware Architecture & Evaluation\n\nTeam Presentations and Final Project Showcase\n\n\n\n\n\nComputer Science Graduate Teaching Assistant (Fall 2024)\n\nAs a Teaching Assistant for COMS 3620, I provided end-to-end guidance to students through both the design and implementation phases of large-scale object-oriented projects. My contributions included:\n\nUML & Design Mentorship: Assisted students in modeling system requirements using UML (use case diagrams, class diagrams, sequence diagrams).\nProject Guidance: Advised student teams during the full development cycle‚Äîfrom requirement analysis and domain modeling to implementation and testing.\nDesign Critique & Feedback: Evaluated and gave feedback on design homeworks, helping students strengthen their reasoning with design principles and patterns.\nTechnical Assistance: Supported Java implementation of OOPS designs, clarifying concepts like inheritance, polymorphism, abstraction, and class hierarchies.\nPresentation Coaching: Helped teams prepare and deliver clear, well-structured final project presentations and reports.\n\nThis experience strengthened my expertise in software architecture, model-driven design, and pedagogical mentoring for complex system development."
  },
  {
    "objectID": "teaching/coms3190/index.html#learning-outcomes",
    "href": "teaching/coms3190/index.html#learning-outcomes",
    "title": "COMS 3190: User Interface Design",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of this course, students will be able to:\n\nDesign and implement interactive, accessible user interfaces.\n\nApply principles of HCI, UI design, UX testing, and event-driven architecture.\n\nDevelop responsive full-stack applications using modern frameworks and tools.\n\nModel system behavior using UML and interaction diagrams.\n\nTest and deploy applications using modern development environments and version control."
  },
  {
    "objectID": "teaching/coms3190/index.html#topics-covered",
    "href": "teaching/coms3190/index.html#topics-covered",
    "title": "COMS 3190: User Interface Design",
    "section": "Topics Covered",
    "text": "Topics Covered\n\nDesign Principles for User Interfaces\n\nHuman-Computer Interaction (HCI) Fundamentals\n\nUX Testing and Evaluation\n\nHTML, CSS, JavaScript\n\nReact, Node.js, Express\n\nMongoDB, MySQL\n\nEvent-Driven Programming\n\nAPI & Framework Integration\n\nUML Diagrams (Structural, Behavioral, Interaction)\n\nUnit & UI Testing in JavaScript\n\nWindows-Based UI Development\n\nClient/Server Architecture"
  },
  {
    "objectID": "teaching/coms3190/index.html#user-interface-design",
    "href": "teaching/coms3190/index.html#user-interface-design",
    "title": "COMS 3190: User Interface Design",
    "section": "",
    "text": "COMS 3190 introduces students to the principles and practices of user interface (UI) and user experience (UX) design through a balance of theory and extensive hands-on development.\nThe course covers human-computer interaction (HCI) concepts, front-end and back-end technologies, and the use of modern frameworks and APIs for developing web and Windows-based user interfaces.\nStudents gain experience with:\n- UI design principles\n- HTML, CSS, and JavaScript\n- React, Node.js, and Express\n- Databases (MongoDB and MySQL)\n- UML modeling and event-driven architecture\n- Web and desktop-based client/server applications\n\n\n\nFigure: Design-to-development process for building interactive and user-centered applications.\n\n\n\n\n\n\nComputer Science Graduate Teaching Assistant (Fall 2024)\n\nAs a Teaching Assistant for COMS 3190, I supported over 100 students in learning full-stack web development principles within the context of UI/UX design. My responsibilities included:\n\nTechnical Instruction: Led lab sessions and live demos on HTML, CSS, JavaScript, React, and Node.js, focusing on responsive, accessible design.\n\nProject Mentorship: Guided teams through semester-long UI/UX projects, helping with front-end development, API design, and database integration.\n\nDesign & Modeling Support: Assisted students in using UML for system modeling and behavioral analysis, including use case and interaction diagrams.\n\nTesting Assistance: Supported unit testing and UI testing in JavaScript and assisted with debugging web applications.\n\nCode Review & Feedback: Evaluated submissions and provided feedback on usability, design consistency, and code efficiency.\n\nOffice Hours: Offered individualized technical support and design mentoring to strengthen students‚Äô understanding of UI/UX best practices."
  },
  {
    "objectID": "teaching/coms3090/index.html#learning-objectives",
    "href": "teaching/coms3090/index.html#learning-objectives",
    "title": "COMS 3090: Software Development Practices",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nStudents completing this course will be able to:\n\nGain hands-on experience across the software development lifecycle, from requirements gathering to testing and deployment.\n\nApply project management techniques, including cost estimation, scheduling, and risk analysis.\n\nCollaborate effectively in teams to design, develop, and deliver functional software products.\n\nUse software engineering artifacts and tools, such as UML diagrams, SQL schemas, versioning systems, and source control.\n\nDemonstrate understanding of software ethics, professional conduct, and legal responsibilities.\n\nImplement client/server programming concepts, including socket communication, APIs, and HTTP protocols."
  },
  {
    "objectID": "teaching/coms3090/index.html#topics-covered",
    "href": "teaching/coms3090/index.html#topics-covered",
    "title": "COMS 3090: Software Development Practices",
    "section": "Topics Covered",
    "text": "Topics Covered\n\nSoftware Process Models and Lifecycle\n\nRequirements Analysis & Specification\n\nArchitecture and System Design\n\nProject Scheduling, Risk Management, and Metrics\n\nTesting, Inspections, and Code Reviews\n\nSoftware Configuration & Source Control (Git)\n\nDatabase Schema Design and SQL\n\nObject-Oriented Concepts and Modeling\n\nNetworking & Client-Server Programming (HTTP, DNS, Sockets)\n\nDNS, IP, URI\n\nClient/Server Model Fundamentals\n\nHTTP and Socket APIs\n\nRESTful API Design\n\n\nProfessional Ethics in Computing\n\n\nMy Role\n\nComputer Science Graduate Teaching Assistant (Fall 2024)\n\nAs a Teaching Assistant for COMS 3090, I supported over 150 students in mastering the principles of modern software engineering through lectures, labs, and team-based projects. My key contributions included:\n\nMentoring Project Teams: Guided multiple student groups throughout the requirements, design, and implementation stages of their semester-long projects.\n\nWeekly Team Meetings: Conducted regular progress check-ins with each team to monitor milestones, resolve blockers, and ensure consistent communication and agile progress tracking.\n\nLab Instruction: Delivered labs on Git, object-oriented modeling, system architecture, and backend programming fundamentals.\n\nTechnical Support: Provided hands-on assistance with debugging, API integration, testing frameworks, and version control workflows.\n\nEvaluation & Feedback: Graded project deliverables, presentations, and code quality, offering structured feedback for improvement.\n\nProcess Coaching: Reinforced Agile and Scrum practices, emphasizing milestone planning, documentation standards, and team collaboration strategies.\n\nThis role strengthened my expertise in software process management, technical mentorship, and team coordination, blending academic support with real-world software development practices."
  },
  {
    "objectID": "teaching/coms3090/index.html#software-development-practices",
    "href": "teaching/coms3090/index.html#software-development-practices",
    "title": "COMS 3090: Software Development Practices",
    "section": "",
    "text": "COMS 3090 provides a practical introduction to software engineering principles, including process models, requirements engineering, system design, testing, and project management.\nThe course emphasizes collaborative software development through a semester-long group project, focusing on teamwork, accountability, and real-world software delivery.\n\n\n\nFigure: Iterative software development process integrating design, implementation, and testing phases."
  },
  {
    "objectID": "teaching/coms1130/index.html#learning-objectives",
    "href": "teaching/coms1130/index.html#learning-objectives",
    "title": "COMS 1130: Introduction to Spreadsheets and Databases",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this course, students will be able to:\n\nApply Microsoft Excel and Access tools to solve real-world analytical problems.\n\nConduct data modeling, statistical analysis, and visualization.\n\nBuild, manage, and query relational databases and structured datasets."
  },
  {
    "objectID": "teaching/coms1130/index.html#topics-covered",
    "href": "teaching/coms1130/index.html#topics-covered",
    "title": "COMS 1130: Introduction to Spreadsheets and Databases",
    "section": "Topics Covered",
    "text": "Topics Covered\n\nMicrosoft Excel (Spreadsheets)\n\nCreate and format spreadsheets\n\nApply mathematical, statistical, logical, and lookup functions\n\nBuild charts and data visualizations\n\nUse PivotTables and subtotals for data summarization\n\nConduct What-If Analysis\n\nImport and export spreadsheet data\n\n\n\n\nFigure 1: Spreadsheet data analysis and visualization in Microsoft Excel.\n\n\n\n\nMicrosoft Access (Databases)\n\nDesign relational tables and define relationships\n\nCreate forms, queries, and reports\n\nSort, filter, and update records\n\nImplement data validation\n\nPerform decision-making tasks based on database queries\n\n\n\n\nFigure 2: Relational database design and querying using Microsoft Access.\n\n\n\n\nMy Role\n\nComputer Science Graduate Teaching Assistant (Fall 2024)\n\nAs a Teaching Assistant for COMS 1130, I supported this large foundational course through lab instruction, mentorship, and assessment. My responsibilities included:\n\nLab Instruction & Demonstrations: Conducted in-person labs on Excel and Access, showcasing real-world applications of data tools.\n\nStudent Mentorship: Provided one-on-one support during labs and office hours, helping students navigate complex formulas, queries, and project workflows.\n\nContent Support: Responded to student queries on Canvas and via email, ensuring timely and clear communication.\n\nAssessment & Feedback: Evaluated assignments, projects, and practical exams, providing actionable feedback.\n\nCourse Coordination: Collaborated with the course instructor to improve teaching materials and lab engagement strategies.\n\nThis role strengthened my expertise in data analysis education, practical software instruction, and student mentoring, helping learners build analytical fluency essential for both academic and professional growth."
  },
  {
    "objectID": "teaching/coms1130/index.html#introduction-to-spreadsheets-and-databases",
    "href": "teaching/coms1130/index.html#introduction-to-spreadsheets-and-databases",
    "title": "COMS 1130: Introduction to Spreadsheets and Databases",
    "section": "",
    "text": "Credits: 3\nInstitution: Iowa State University\nFormat: In-Person Course (Offered Fall & Spring)\nCOMS 1130 is a 3-credit undergraduate course that teaches essential skills in Microsoft Excel and Microsoft Access, emphasizing hands-on, real-world applications of data management and analysis.\n\n\n\nThis course introduces students to data organization, analysis, and decision-making using Microsoft Excel and Access. Through a project-based approach, students learn to create, analyze, and manage data models for business, engineering, and academic applications."
  },
  {
    "objectID": "rpkg/research.html#through-the-tight-coupling-of-domain-knowledge-into-learning-frameworks-i-hope-to-enable-resilient-generalizable-and-safe-ai-for-critical-applications-in-areas-such-as-smart-grids-autonomous-systems-and-intelligent-infrastructure.",
    "href": "rpkg/research.html#through-the-tight-coupling-of-domain-knowledge-into-learning-frameworks-i-hope-to-enable-resilient-generalizable-and-safe-ai-for-critical-applications-in-areas-such-as-smart-grids-autonomous-systems-and-intelligent-infrastructure.",
    "title": "Research",
    "section": "Through the tight coupling of domain knowledge into learning frameworks, I hope to enable resilient, generalizable, and safe AI for critical applications in areas such as smart grids, autonomous systems, and intelligent infrastructure.",
    "text": "Through the tight coupling of domain knowledge into learning frameworks, I hope to enable resilient, generalizable, and safe AI for critical applications in areas such as smart grids, autonomous systems, and intelligent infrastructure."
  },
  {
    "objectID": "talks/pes_gm_2025/index.html#about-the-talk",
    "href": "talks/pes_gm_2025/index.html#about-the-talk",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "About the talk",
    "text": "About the talk\nWe developed a TL-DRL framework, as shown in Fig.~\\(\\ref{fig:A2C}\\), which involves transferring policy knowledge from one distribution grid to another. Additionally, we have created a policy reuse classifier to determine whether to transfer the policy knowledge from the IEEE-123 Bus to the IEEE-13 Bus system and conducted an impact analysis. \\[\\begin{equation}\\label{eq:ppo_objective}\n\\theta_{\\text{source}} = \\arg \\max_{\\theta} \\mathbb{E}_{\\tau \\sim \\pi_{\\theta}} \\left[ \\sum_{t=0}^{T} \\gamma^t r_t - \\beta \\text{CLIP}(\\theta) \\right]\n\\end{equation}\\] The \\(\\theta_{\\text{source}}\\) is trained with the DRL algorithm on the IEEE-123 Bus, which regulates the VVC voltage profiles within permissible limits.\nWhile \\(\\theta_{\\text{target}}\\) is the model which transferred the knowledge \\(\\theta_{\\text{source}}\\) and adapts well in the \\(\\theta_{\\text{target}}\\) domain. \\[\\begin{equation}\\label{eq:target_theta}\n\\theta_{\\text{target}} =\n\\begin{cases}\n\\begin{aligned}\n\\theta_{\\text{source}}\\; & \\text{if } P(\\text{Reuse}|\\text{Observation}) &gt; 0.5\n\\end{aligned} \\\\\n\\arg \\max_{\\theta} \\mathbb{E}_{\\tau \\sim \\pi_{\\theta}} \\left[ \\sum_{t=0}^{T} \\gamma^t r_t \\right] & \\text{otherwise}\n\\end{cases}\n\\end{equation}\\]"
  },
  {
    "objectID": "talks/pes_gm_2025/index.html#introduction",
    "href": "talks/pes_gm_2025/index.html#introduction",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "",
    "text": "As renewable energy integration accelerates, modern power grids face mounting complexity in maintaining stability and efficiency. Deep Reinforcement Learning (DRL) has emerged as a powerful technique for Volt-Var Control (VVC) ‚Äî regulating voltage levels across the distribution grid ‚Äî but its Achilles‚Äô heel lies in expensive retraining.\nEvery new grid topology or environment demands retraining from scratch, costing time, data, and computational energy.\nIn our latest work, presented at the Workshop on Autonomous Energy Systems (GRID-EDGE 2025), we introduce a Transfer Learning (TL)-based DRL framework that enables policy reuse across different grid configurations ‚Äî cutting training time by 98.14% while improving performance by 69.51%."
  },
  {
    "objectID": "talks/pes_gm_2025/index.html#core-idea-transfer-learning-meets-drl",
    "href": "talks/pes_gm_2025/index.html#core-idea-transfer-learning-meets-drl",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "Core Idea: Transfer Learning Meets DRL",
    "text": "Core Idea: Transfer Learning Meets DRL\nTraditional DRL systems learn from scratch. TL-DRL systems, however, transfer policy knowledge from a source grid (e.g., IEEE-123 Bus) to a target grid (e.g., IEEE-13 Bus).\n\nThis approach allows agents to start smarter, building upon previously learned representations rather than reinventing them. The heart of this system is a policy reuse classifier, a small neural network that decides when the previously learned policy should be reused or adapted."
  },
  {
    "objectID": "talks/pes_gm_2025/index.html#how-it-works",
    "href": "talks/pes_gm_2025/index.html#how-it-works",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "How It Works",
    "text": "How It Works\nThe framework operates in three phases:\n\n1. Source Training\nA DRL agent, using the Proximal Policy Optimization (PPO) algorithm, learns to manage the IEEE-123 Bus system. The policy parameters, denoted as Œ∏‚Çõ‚Çí·µ§·µ£c‚Çë, optimize voltage levels and reactive power flow according to ANSI C84.1-2020 voltage standards.\n\n\n2. Policy Reuse Classifier\nWe train a binary classifier that predicts the probability of reusing a learned policy: [ P(|) = (f_()) ] If this probability exceeds 0.5, the source policy is transferred directly; otherwise, the agent retrains in the target environment.\n\n\n3. Target Adaptation\nThe target model (Œ∏‚Çú‚Çê·µ£g‚Çë‚Çú) adapts to the IEEE-13 Bus through fine-tuning and Q-value updates, balancing exploration and exploitation dynamically: [ = P(|) ] This adaptive mechanism allows the agent to decide when to trust previous experience and when to explore new strategies."
  },
  {
    "objectID": "talks/pes_gm_2025/index.html#experimental-setup",
    "href": "talks/pes_gm_2025/index.html#experimental-setup",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "Experimental Setup",
    "text": "Experimental Setup\nWe implemented the system in OpenDSS using the PowerGym RL environment.\nThe source policy (IEEE-123 Bus) was trained for 20,000 iterations, taking 313 seconds.\nThe TL-enhanced target model (IEEE-13 Bus) adapted in just 9.6 seconds ‚Äî compared to 518 seconds when trained from scratch.\n\n\n\nMetric\nTraining with TL\nWithout TL\n\n\n\n\nMean Reward\n-8.310\n-27.256\n\n\nTraining Time\n9.62 s\n518.38 s\n\n\nT-Statistic\n102.93\n‚Äî\n\n\nP-Value\n6.38\n‚Äî\n\n\nTAS (Task Adaptation Score)\n72.78\n‚Äî\n\n\nEmbedding Distance (ED)\n31.11\n‚Äî\n\n\n\nThese results show that TL not only speeds up convergence but also produces a statistically significant performance improvement."
  },
  {
    "objectID": "talks/pes_gm_2025/index.html#key-insights",
    "href": "talks/pes_gm_2025/index.html#key-insights",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "Key Insights",
    "text": "Key Insights\n\nEfficiency Leap ‚Äî TL cut training time by 98%, accelerating grid simulation workflows dramatically.\n\nPolicy Robustness ‚Äî The classifier effectively distinguished when to reuse policies, preserving stability in unseen grid configurations.\n\nScalability ‚Äî The approach generalizes across systems of different complexity, paving the way for large-scale adaptive control."
  },
  {
    "objectID": "talks/pes_gm_2025/index.html#broader-impact",
    "href": "talks/pes_gm_2025/index.html#broader-impact",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "Broader Impact",
    "text": "Broader Impact\nThe proposed TL-DRL framework makes reinforcement learning practical for real-world grid management.\nBy leveraging existing knowledge, utilities can deploy smarter and faster control policies, reducing both operational costs and computational footprints ‚Äî a critical step toward sustainable AI-driven power systems."
  },
  {
    "objectID": "talks/pes_gm_2025/index.html#whats-next",
    "href": "talks/pes_gm_2025/index.html#whats-next",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "What‚Äôs Next",
    "text": "What‚Äôs Next\nOur next goal is to scale TL across multiple grid sizes ‚Äî from micro-grids to regional networks ‚Äî and to integrate physics-informed constraints that further improve generalization.\nWe also aim to extend this framework to federated and collaborative learning paradigms, allowing distributed grids to share intelligence securely."
  },
  {
    "objectID": "talks/pes_gm_2025/index.html#reference",
    "href": "talks/pes_gm_2025/index.html#reference",
    "title": "Scaling Smart Grids with Transfer Learning and DRL",
    "section": "Reference",
    "text": "Reference\nKundan Kumar, Ravikumar Gelli.\n‚ÄúTransfer Learning Enhanced Deep Reinforcement Learning for Volt-Var Control in Smart Grids.‚Äù\nWorkshop on Autonomous Energy Systems, GRID-EDGE 2025.\nWe developed a TL-DRL framework, as shown in Fig.~\\(\\ref{fig:A2C}\\), which involves transferring policy knowledge from one distribution grid to another. Additionally, we have created a policy reuse classifier to determine whether to transfer the policy knowledge from the IEEE-123 Bus to the IEEE-13 Bus system and conducted an impact analysis."
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Collaboration and Competition",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "publications/articles/pesgm2025.html#mathematical-formulation-of-ssl",
    "href": "publications/articles/pesgm2025.html#mathematical-formulation-of-ssl",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "3. Mathematical Formulation of SSL",
    "text": "3. Mathematical Formulation of SSL\nWe define phase identification as a semi-supervised classification problem, where the dataset \\(D = D_L \\cup D_U\\) consists of a small labeled subset \\(D_L\\) and a large unlabeled subset \\(D_U\\).\nThe SSL objective is a regularized minimization:\n\\[\n  \\min_{f \\in \\mathcal{F}} \\left[\n    \\frac{1}{n_L} \\sum_{i=1}^{n_L} \\ell(f(x_i), y_i)\n    + \\lambda R(f, \\mathcal{D}_U)\n  \\right]\n  \\]\nwhere:\n- \\(\\ell\\) is the supervised loss (e.g., cross-entropy)\n- \\(R(f, \\mathcal{D}_U)\\) is the regularization term capturing structure in the unlabeled data, - \\(\\lambda\\) : trade-off parameter controlling the influence of unlabeled data\nThis formulation encourages the model to learn a decision boundary consistent with both labeled examples and the structure of the unlabeled feature space.\n\nWe formulate SSL as a regularized optimization problem:\n\\[\n\\min_{f \\in \\mathcal{F}} \\left[ \\frac{1}{n_L} \\sum_{i=1}^{n_L} \\ell(f(x_i), y_i) + \\lambda R_u(f, \\mathcal{D}_U) \\right]\n\\] Where \\[a^2 + b^2 = d^2\\] is the Unsupervised regularization term\nWhere: \\[\nR_u(f, \\mathcal{D}_U)\n\\] is the - ( (, ) ): Supervised loss (cross-entropy)\n- ( R_u(f, _U) ): Unsupervised regularization term\n- ( ): Trade-off parameter\nThe challenge is designing ( R_u(f, _U) ) to effectively leverage unlabeled data.\n\n\\[\\ell(\\cdot, \\cdot)\\]: Supervised loss (cross-entropy)\n\\[R_u(f, \\mathcal{D}_U)\\]: Unsupervised regularization term\n\\[\\lambda\\]: Trade-off parameter\n( (, ) ): Supervised loss (cross-entropy)\n\n( R_u(f, _U) ): Unsupervised regularization term\n\n( ): Trade-off parameter\n\nWe formulate SSL as a regularized optimization problem: min_{f‚àà‚Ñ±} [ (1/n_L) ‚àë^{n_L}_{i=1} ‚Ñì(f(x_i), y_i) + ŒªR_u(f, ùíü_U) ] Where:\n‚Ñì(¬∑,¬∑): Supervised loss (cross-entropy) R_u(f, ùíü_U): Unsupervised regularization term Œª: Trade-off parameter\nThe challenge: designing R_u(f, ùíü_U) that effectively exploits unlabeled data structure ## Methodology\nWe define the binomial distribution as:(Equation¬†2)\n\\[\nf(k) = \\binom{n}{k} p^k (1-p)^{n-k}\n\\tag{2}\\]\nAs shown in Equation @ref(eq:binom), the binomial function defines the probability‚Ä¶\nBlack-Scholes (Equation¬†3) is a mathematical model that seeks to explain the behavior of financial derivatives, most commonly options:\n\\[\n\\frac{\\partial \\mathrm C}{ \\partial \\mathrm t } + \\frac{1}{2}\\sigma^{2} \\mathrm S^{2}\n\\frac{\\partial^{2} \\mathrm C}{\\partial \\mathrm S^2}\n  + \\mathrm r \\mathrm S \\frac{\\partial \\mathrm C}{\\partial \\mathrm S}\\ =\n  \\mathrm r \\mathrm C\n\\tag{3}\\]"
  },
  {
    "objectID": "publications/articles/pesgm2025.html#methodology-and-core-equations",
    "href": "publications/articles/pesgm2025.html#methodology-and-core-equations",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "4. Methodology and Core Equations",
    "text": "4. Methodology and Core Equations\n\n4.1 Self-Training with MLP Ensembles\nThe MLP classifier f(x; \\(\\theta\\)) is trained on \\(D_L\\) to minimize cross-entropy loss:\n\\[\n\\theta = \\arg\\min_\\theta \\sum_{(x_i, y_i) \\in D_L} \\mathcal{L}(f(x_i; \\theta), y_i)\n\\]\nUnlabeled samples with high prediction confidence \\(p_j\\) &gt; \\(\\tau\\) receive pseudo-labels:\n\\[\nD^{\\text{new}}_L = \\{(x_j, \\hat{y}_j) \\mid p_j &gt; \\tau\\}\n\\]\nThe process repeats iteratively, enriching the labeled dataset.\n\n\n\n4.2 Label Spreading (Graph-Based SSL)\nWe construct a similarity matrix \\(W\\) where edge weights encode feature similarity:\n\\[\nW_{ij} =\n\\begin{cases}\n\\exp\\!\\left(-\\frac{\\|x_i - x_j\\|^2}{\\sigma^2}\\right), & i \\neq j \\\\\n0, & i = j\n\\end{cases}\n\\]\nLabel distributions are updated iteratively as:\n\\[\nY^{(t+1)} = (1 - \\alpha)Y^{(t)} + \\alpha D^{-1}WY^{(t)}\n\\]\nThis propagates known labels through the data manifold, smoothing class boundaries.\n\n\n4.3 Bayesian Neural Networks (BNNs)\nBNNs treat weights as random variables, assigning a Gaussian prior:\n\\[\np(W) = \\mathcal{N}(W | \\mu_{W}, \\sigma_W^2)\n\\]\nGiven training data \\(D_L\\), the posterior distribution is:\n\\[\np(W | D_L) \\propto p(D_L | W) \\, p(W)\n\\]\nThe predictive distribution integrates over all possible weight configurations:\n\\[\np(y^* | x^*, D_L) = \\int p(y^* | x^*, W) \\, p(W | D_L) \\, dW\n\\]\nWe approximate this via Monte Carlo dropout by averaging multiple stochastic forward passes:\n\\[\n\\hat{y}^* = \\frac{1}{N} \\sum_{n=1}^N f(x^*; W_n)\n\\] ### 4.4 Uncertainty Quantification\nTwo forms of uncertainty are estimated:\n\nEpistemic (Model Uncertainty): \\[\nU_{\\text{epistemic}} = \\mathrm{Var}(\\hat{y}^*)\n\\]\nAleatoric (Data Uncertainty): \\[\nU_{\\text{aleatoric}} = \\mathbb{E}\\!\\left[(\\hat{y}^* - \\mathbb{E}[\\hat{y}^*])^2\\right]\n\\]\n\nTogether, they help distinguish between what the model doesn‚Äôt know and what cannot be known due to noise."
  },
  {
    "objectID": "publications/articles/pesgm2025.html#experimental-framework",
    "href": "publications/articles/pesgm2025.html#experimental-framework",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "5. Experimental Framework",
    "text": "5. Experimental Framework\n\n\n\nFig. 2: Proposed SSL Framework Applied to AMI Data\n\n\n\nData Flow and Setup\n\nDataset Source: Real AMI data from a U.S. utility (Duquesne Light Company).\n\nFeature Set:\n( F = {R_0, X_0, R_1, X_1, P, V_{}, V_{}, V_{}} )\n\nData Split: 70% development, 30% test; within development, labeled fractions vary from 5‚Äì80%.\n\nModels:\n\nMLP (64‚Äì32 layers, ReLU activation)\n\nLabel Spreading with kNN kernel\n\n3-layer BNN using Gaussian priors, dropout rate 0.7, Adam optimizer\n\n\n\n\n\nFig. 3: Distribution Feeder Topology\n\n\n\n\n\nFig. 4: Training and Testing Data Partitions"
  },
  {
    "objectID": "publications/articles/pesgm2025.html#results-and-discussion",
    "href": "publications/articles/pesgm2025.html#results-and-discussion",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "6. Results and Discussion",
    "text": "6. Results and Discussion\nBNNs outperformed both self-training and label spreading across all labeled data ratios.\nWhen only 5% of the dataset was labeled, BNNs already achieved 64.15% ¬± 0.14, compared to 34.9% for self-training and 44.3% for label spreading.\nAt 70% labeled data, the BNN reached 99.06% ¬± 0.06 accuracy.\n\n\n\nFig. 5: Comparison of SSL Algorithms with Uncertainty Estimation\n\n\nInterpretation:\nBNNs‚Äô probabilistic nature allows them to express how sure they are about each decision. This prevents overfitting and enables informed decision-making when data are uncertain‚Äîcrucial for utility operations."
  },
  {
    "objectID": "publications/articles/pesgm2025.html#conclusion",
    "href": "publications/articles/pesgm2025.html#conclusion",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "7. Conclusion",
    "text": "7. Conclusion\nThis research presents a semi-supervised learning framework enhanced with Bayesian uncertainty estimation for phase identification in power distribution systems.\nBy integrating pseudo-labeling, graph-based label propagation, and Bayesian inference, our framework achieves robust performance with minimal labeled data‚Äî98% ¬± 0.08 accuracy‚Äîand provides confidence metrics for each prediction.\nThis uncertainty-aware paradigm is a step toward trustworthy, data-efficient, and intelligent smart grids, where models not only predict but also know when they might be wrong.\n\nProposed SSL Framework Applied to AMI Data\n\n\n\nDistribution Feeder Topology\n\n\n\nTraining and Testing Data Partitions\n\n\n\nAccuracy Comparison of SSL Methods"
  },
  {
    "objectID": "publications/articles/pesgm2025.html#problem-formulation-of-framework-for-ami",
    "href": "publications/articles/pesgm2025.html#problem-formulation-of-framework-for-ami",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "3. Problem Formulation of Framework for AMI",
    "text": "3. Problem Formulation of Framework for AMI\nWe define phase identification as a semi-supervised classification problem,\\@ref(eq:black-scholes2) where the dataset \\(D = D_L \\cup D_U\\) consists of a small labeled subset \\(D_L\\) and a large unlabeled subset \\(D_U\\).\nThe SSL objective is a regularized minimization:\n\\[\n  \\min_{f \\in \\mathcal{F}} \\left[\n    \\frac{1}{n_L} \\sum_{i=1}^{n_L} \\ell(f(x_i), y_i)\n    + \\lambda R(f, \\mathcal{D}_U)\n  \\right]\n\\]{#eq:black-scholes2}\nwhere:\n- \\(\\ell\\) is the supervised loss (e.g., cross-entropy)\n- \\(R(f, \\mathcal{D}_U)\\) is the regularization term capturing structure in the unlabeled data, - \\(\\lambda\\) : trade-off parameter controlling the influence of unlabeled data\nThis formulation encourages the model to learn a decision boundary consistent with both labeled examples and the structure of the unlabeled feature space. c‚Äô"
  },
  {
    "objectID": "publications/articles/pesgm2025.html#methodology",
    "href": "publications/articles/pesgm2025.html#methodology",
    "title": "Advanced Semi-Supervised Learning With Uncertainty Estimation for Phase Identification in Distribution Systems",
    "section": "Methodology",
    "text": "Methodology\n\n\n4.1 Self-Training with MLP Ensembles\nThe MLP classifier f(x; \\(\\theta\\)) is trained on \\(D_L\\) to minimize cross-entropy loss (Equation¬†1):\n\\[\n\\theta = \\arg\\min_\\theta \\sum_{(x_i, y_i) \\in D_L} \\mathcal{L}(f(x_i; \\theta), y_i)\n\\tag{1}\\]\nUnlabeled samples with high prediction confidence \\(p_j\\) &gt; \\(\\tau\\) receive pseudo-labels:\n\\[\nD^{\\text{new}}_L = \\{(x_j, \\hat{y}_j) \\mid p_j &gt; \\tau\\}\n\\]\nThe process repeats iteratively, enriching the labeled dataset.\n\n\n\n4.2 Label Spreading (Graph-Based SSL)\nWe construct a similarity matrix \\(W\\) where edge weights encode feature similarity:\n\\[\nW_{ij} =\n\\begin{cases}\n\\exp\\!\\left(-\\frac{\\|x_i - x_j\\|^2}{\\sigma^2}\\right), & i \\neq j \\\\\n0, & i = j\n\\end{cases}\n\\]\nLabel distributions are updated iteratively as:\n\\[\nY^{(t+1)} = (1 - \\alpha)Y^{(t)} + \\alpha D^{-1}WY^{(t)}\n\\]\nThis propagates known labels through the data manifold, smoothing class boundaries.\n\n\n4.3 Bayesian Neural Networks (BNNs)\nBNNs treat weights as random variables, assigning a Gaussian prior:\n\\[\np(W) = \\mathcal{N}(W | \\mu_{W}, \\sigma_W^2)\n\\]\nGiven training data \\(D_L\\), the posterior distribution is:\n\\[\np(W | D_L) \\propto p(D_L | W) \\, p(W)\n\\]\nThe predictive distribution integrates over all possible weight configurations:\n\\[\np(y^* | x^*, D_L) = \\int p(y^* | x^*, W) \\, p(W | D_L) \\, dW\n\\]\nWe approximate this via Monte Carlo dropout by averaging multiple stochastic forward passes:\n\\[\n\\hat{y}^* = \\frac{1}{N} \\sum_{n=1}^N f(x^*; W_n)\n\\] ### 4.4 Uncertainty Quantification\nTwo forms of uncertainty are estimated:\n\nEpistemic (Model Uncertainty): \\[\nU_{\\text{epistemic}} = \\mathrm{Var}(\\hat{y}^*)\n\\]\nAleatoric (Data Uncertainty): \\[\nU_{\\text{aleatoric}} = \\mathbb{E}\\!\\left[(\\hat{y}^* - \\mathbb{E}[\\hat{y}^*])^2\\right]\n\\]\n\nTogether, they help distinguish between what the model doesn‚Äôt know and what cannot be known due to noise."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#overview-1",
    "href": "blog/technotes_20251102_research_guide/index.html#overview-1",
    "title": "Research Scientist Interview Guide",
    "section": "Overview",
    "text": "Overview\nThis guide provides a practical framework to prepare for Research Scientist roles in academia, industry research labs (FAANG, OpenAI, DeepMind, Anthropic, NVIDIA), and national labs. It blends personal experience with hiring-manager expectations and common evaluation rubrics.\n\n\n\nResource\nLink\n\n\n\n\nGitHub Repository\nResearch Scientist Preparation Guide\n\n\nData Science Notes\nData Science Intro\n\n\nStatistical Learning Notes\nStatistical Analysis\n\n\nLLM Curriculum\nZero2LLM Crafter\n\n\n\n\nGitHub repository: Research Scientist Preparation Guide\nData Science Notes: Data Science Intro\nStatistical Learning Notes: Statistical Analysis LLM : Statistical Analysis ‚Äî"
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#why-ai-research-interviews-are-different",
    "href": "blog/technotes_20251102_research_guide/index.html#why-ai-research-interviews-are-different",
    "title": "Research Scientist Interview Guide",
    "section": "1. Why AI Research Interviews Are Different",
    "text": "1. Why AI Research Interviews Are Different\nResearch hiring revolves around one core question:\n\nCan you take an ambiguous problem and turn it into a clear idea, an experiment, a result, and an impact?\n\nTo answer this, interviewers probe six major capabilities:\n\nResearch depth\nCan you clearly explain the gap, the idea, the method, the evidence, and the limitations of your work?\nTechnical foundations\nMath, ML, optimization, probability, RL, uncertainty modeling, transformers, and systems fundamentals.\nExperimentation mindset\nHow you design baselines, run ablations, debug failures, reason about data, and measure uncertainty.\nSystems thinking\nHow your ideas turn into deployed systems‚Äîlatency, reliability, guardrails, monitoring, drift, and safety.\nExecution\nCan you scope, prototype, iterate, debug, and deliver‚Äîpapers, code, and production impact?\nCommunication\nCan you explain complex ideas clearly to engineers, PMs, research peers, and leadership?\n\n\n\n\n\n\n\nTip\n\n\n\nFor each project, try this lens:\nproblem ‚Üí gap ‚Üí idea ‚Üí method ‚Üí evidence ‚Üí limitations ‚Üí next steps ‚Üí impact"
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#what-the-interview-process-looks-like",
    "href": "blog/technotes_20251102_research_guide/index.html#what-the-interview-process-looks-like",
    "title": "Research Scientist Interview Guide",
    "section": "2. What the Interview Process Looks Like",
    "text": "2. What the Interview Process Looks Like\nMost AI research interview loops have a similar skeleton:\n\nRecruiter / Hiring Manager Screen\nScope, research fit, background, interests, and communication.\nTechnical Screen\nML fundamentals, math, and a coding round (usually Python).\nResearch Deep Dive\nA long-form discussion of your best project: motivation, choices, experiments, failures.\nResearch Talk / Seminar (45‚Äì60 minutes)\nA slide-based talk to a mixed audience (researchers, engineers, PMs).\nSystems / Experimentation Round\nDesign and evaluation: metrics, baselines, guardrails, safety, reliability.\nBehavioral / Team Fit\nOwnership, collaboration, scientific judgment, decision-making under uncertainty.\nDebrief & Calibration\nCross-interviewer discussion ‚Üí final decision ‚Üí offer or no offer."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#phase-1-100-day-preparation-roadmap",
    "href": "blog/technotes_20251102_research_guide/index.html#phase-1-100-day-preparation-roadmap",
    "title": "Research Scientist Interview Guide",
    "section": "3. Phase 1: 100-Day Preparation Roadmap",
    "text": "3. Phase 1: 100-Day Preparation Roadmap\nPreparing for a research scientist role isn‚Äôt a weekend sprint. The plan below assumes ~100 days (around 14‚Äì15 weeks) of disciplined, focused preparation. Think of it as 10 phases (‚âà10 days each), grouped into larger thematic blocks.\n#100DaysofPreparation\n\n3.1 (Weeks 1‚Äì2) Build Your Research Portfolio Foundation\nWeeks 1‚Äì2: Foundations & portfolio - Curate 2‚Äì3 flagship projects; write 1-page project briefs (problem, novelty, 3 results, open questions). - Refresh ML math: gradients, likelihoods, bias‚Äìvariance, generalization, off-policy vs on-policy RL. - DS&A 20‚Äì30 mins/day (arrays, hash maps, trees, graphs, DP‚Äîmedium level). - Draft talk outline; collect figures; start a reproducible repo.\nWeeks 3‚Äì4: Research talk + deep dives - Build slides (30/45/60 min versions). Timebox: Motivation 10% ‚Üí Method 35% ‚Üí Evidence 40% ‚Üí Limits + Roadmap 15%. - Prepare ablation stories and negative results; design a live error analysis demo if feasible. - Mock talks with labmates; iterate twice.\nWeeks 5‚Äì6: Systems & coding polish - 5 case studies: online inference, data pipelines, eval at scale, safety/guardrails, monitoring. - Practice 6‚Äì8 coding problems in 60-min sessions; review idioms (two-pointers, heap, BFS/DFS, topo sort). - Draft answers for 8‚Äì10 behavioral prompts using STAR(L).\nWeek 7+: Company-specific tuning - Read team papers/repos; align your roadmap slide to their charter. - Prepare 8‚Äì12 questions to ask (below). - Dry run full onsite (talk + 3 interviews + behavioral) in a single sitting."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#interview-preparation-roadmap",
    "href": "blog/technotes_20251102_research_guide/index.html#interview-preparation-roadmap",
    "title": "Research Scientist Interview Guide",
    "section": "3. Interview Preparation Roadmap",
    "text": "3. Interview Preparation Roadmap\nPreparing for a research scientist role isn‚Äôt a weekend sprint. The plan below assumes ~100 days (around 14‚Äì15 weeks) of disciplined, focused preparation. Think of it as 10 phases (‚âà10 days each), grouped into larger thematic blocks.\n#100DaysofPreparation\n\n3.1 (Weeks 1‚Äì2) Build Your Research Portfolio Foundation\nGoal: Establish your scientific identity and core artifacts.\nWhat to accomplish:\n\nSelect 2‚Äì3 flagship projects ‚Äî the ones you want to be hired for.\nWrite one-page summaries for each:\n\nproblem ‚Üí gap ‚Üí idea ‚Üí method ‚Üí evidence ‚Üí limits.\n\nOrganize code, plots, logs, notebooks, and experiment sheets into a clean structure.\nRefresh foundational ML math:\n\nGradients, softmax, cross-entropy\nBias‚Äìvariance tradeoff, generalization\nRegularization basics (weight decay, dropout)\n\nReview optimization basics:\n\nSGD, AdamW\nLearning rate warmup, cosine decay\nMLE vs.¬†MAP\n\nDo light DS&A:\n\n20‚Äì30 minutes/day on arrays/strings, hash maps, basic trees.\n\n\nOutcome: A clear, coherent scientific story and crisp articulation of your contributions.\nFollow-along tasks:\n\nCreate a Portfolio/ folder and write 3 one-page project summaries.\nList your 5 strongest experimental results (with metrics and context).\nSummarize 3 papers from your target teams (FAANG, DeepMind, OpenAI, Anthropic, etc.).\n\n\n\n3.2 (Weeks 3‚Äì4) Deep Learning & Modern Architectures Refresh\nGoal: Regain fluency in the architectures that power modern AI systems.\nTopics to review:\n\nCNNs, RNNs, LSTMs, GRUs\nTransformers: attention, QKV projections, multi-head attention\nResidual connections, LayerNorm, normalization strategies\nKL divergence, entropy, cross-entropy\nPositional encodings, rotary embeddings (RoPE)\nRegularization techniques: dropout, mixup, cutmix, label smoothing\nTraining dynamics:\n\nGradient flow\nVanishing/exploding gradients\nLoss landscapes, sharpness, generalization behavior\n\n\nFollow-along tasks: - Re-derive softmax + cross-entropy and their gradients. - Solve 10 small gradient/optimization exercises. - Summarize 3 internals of transformers (e.g., QKV, attention, layer norm) in your own words.\nHands-on:\n\nRebuild a transformer encoder from scratch in PyTorch (minimal but clean).\nImplement vision augmentations (random crop, flip, color jitter).\nReproduce a small-scale paper result (e.g., CIFAR-10 or MNIST baseline).\n\nOutcome: You should be comfortable answering: ‚ÄúHow does this model actually work?‚Äù instead of just ‚ÄúIt‚Äôs a transformer.‚Äù\n\n\n3.3 (Weeks 5‚Äì6) Deep Reinforcement Learning Refresher\nGoal: Achieve deep, working-level confidence with modern DRL.\nCore topics:\n\nDerive the policy gradient theorem from first principles.\nUnderstand Generalized Advantage Estimation (GAE) and why it stabilizes training.\nBuild intuition for PPO and TRPO:\n\nClipped objective\nTrust regions\nKL constraints\n\nMaster key off-policy algorithms:\n\nDQN, TD3, SAC\nWhen to use which (discrete/continuous, exploration needs).\n\nReplay buffers, target networks, delayed policy updates.\nExploration vs exploitation in discrete and continuous settings.\nDiagnosing RL instability:\n\nValue drift\nEntropy collapse\nMis-scaled advantages\nReward hacking\n\nSafety-aware RL:\n\nConstraint handling, shields, penalties\nReachability logic basics\n\nOffline RL fundamentals:\n\nDataset coverage\nBehavior policies\nDistributional shift\n\nCounterfactual evaluation and why it matters in safety-critical systems.\n\nFollow-along tasks:\n\nWrite out the PPO objective and update rule by hand, including clipping, advantage, and entropy terms.\nImplement PPO or DQN from scratch in PyTorch (keep it minimal but readable).\nRe-derive the REINFORCE update starting from log-likelihood gradients.\nWrite a one-paragraph explanation of what causes PPO instability and how you‚Äôd detect it.\nRead two recent RL papers from your target teams.\nTrain a simple RL agent:\n\nCartPole, or\nA domain-specific environment like OpenDSS/CityLearn.\n\nStudy 2‚Äì3 DRL papers closely related to your dream role.\n\nOutcome: Confidently explain, derive, implement, and debug modern RL algorithms and discuss where they fail.\n\n\n3.4 (Weeks 7‚Äì8) LLMs, RAG, Multimodal Systems, Prompting & Finetuning\nGoal: Build a strong working mastery of LLMs and the surrounding ecosystem.\nTopics:\n\nPretraining vs finetuning vs RLHF vs instruction tuning.\nParameter-efficient finetuning:\n\nLoRA, QLoRA, PEFT.\n\nTokenization:\n\nBPE, SentencePiece basics.\n\nDiffusion models:\n\nKey intuition (noise schedule, denoising).\n\nRAG systems:\n\nChunking strategies\nVector search and indexing\nReranking\n\nLLM evaluation:\n\nExact match, BLEU, nDCG\nWin-rate and human eval\n\nSafety:\n\nHallucination mitigation\nSafety filters, prompt defenses\n\nKnowledge distillation for LLMs.\nMultimodal encoders (CLIP-style), contrastive learning.\nVision metrics:\n\nmAP, IoU, retrieval (k?).\n\n\nHands-on tasks:\n\nPlay with prompt engineering and basic tool calling.\nBuild a minimal RAG pipeline using a public dataset.\nFinetune a small model (e.g., Mistral-7B, Qwen-2B or similar).\nEvaluate retriever quality using recall@k or nDCG.\nSummarize one frontier LLM paper (OpenAI, Anthropic, DeepMind, etc.).\nCreate 5 ‚Äúhallucination test‚Äù prompts and inspect failure cases.\n\nOutcome: Can talk about LLMs as both a research topic and a system you can build and debug.\n\n\n3.5 (Weeks 9‚Äì10) AI Safety, Alignment & Responsible AI\nGoal: Develop a rigorous understanding of safety and alignment principles used in modern labs.\nTopics:\n\nAlignment foundations:\n\nOuter vs inner alignment\nGoal misgeneralization.\n\nDeception risks and model monitoring.\nRed teaming and adversarial prompting.\nGuardrails & safety filters (moderation models, policy layers).\nInterpretability:\n\nSaliency\nProbing\nCausal scrubbing (intuitively)\n\nRobustness & adversarial attacks.\nReward hacking & specification gaming.\nResponsible deployment and incident response.\n\nHands-on tasks:\n\nEvaluate an LLM for hallucination and unsafe completions.\nBuild a small safety classifier (e.g., toxicity or PII detection).\nImplement simple adversarial prompts to test robustness.\nSummarize 2‚Äì3 alignment papers from DeepMind / OpenAI / Anthropic.\n\nOutcome: Can speak maturely and concretely about safety, alignment risks, and mitigation strategies.\n\n\n3.6 (Weeks 11‚Äì12) ML Systems, Experimentation Design & Infrastructure\nGoal: Understand how research artifacts turn into production-grade systems.\nTopics:\n\nData-centric AI:\n\nData pipelines, labeling strategies, noise.\n\nFeature engineering vs representation learning.\nConstraints:\n\nLatency, throughput, cost.\n\nMonitoring:\n\nDrift, anomalies, reliability SLOs.\n\nGuardrails:\n\nFail-open vs fail-safe\nCircuit breakers\nFallback heuristics.\n\nShadow vs online experimentation.\nKey metrics:\n\nProduct KPIs ‚ÜîÔ∏é technical metrics\nOOD splits, fairness audits.\n\nReliability:\n\nRollback plans, incident runbooks.\n\n\nHands-on tasks:\n\nDesign a deployment plan for a real ML model (e.g., anomaly detection, RAG, recommender).\nBuild a small drift-detection pipeline.\nWrite a full ML system design doc (data ‚Üí model ‚Üí eval ‚Üí rollout).\nEvaluate at least 3 slices of a dataset: OOD, rare cases, edge cases.\n\nOutcome: Can walk through a complete ‚Äúresearch to production‚Äù story with credible detail."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#weeks-56-deep-reinforcement-learning-refresher",
    "href": "blog/technotes_20251102_research_guide/index.html#weeks-56-deep-reinforcement-learning-refresher",
    "title": "Research Scientist Interview Guide",
    "section": "3.3 (Weeks 5‚Äì6) Deep Reinforcement Learning Refresher",
    "text": "3.3 (Weeks 5‚Äì6) Deep Reinforcement Learning Refresher\nGoal: Achieve deep, working-level confidence with modern DRL.\nCore topics:\n\nDerive the policy gradient theorem from first principles.\nUnderstand Generalized Advantage Estimation (GAE) and why it stabilizes training.\nBuild intuition for PPO and TRPO:\n\nClipped objective\nTrust regions\nKL constraints\n\nMaster key off-policy algorithms:\n\nDQN, TD3, SAC\nWhen to use which (discrete/continuous, exploration needs).\n\nReplay buffers, target networks, delayed policy updates.\nExploration vs exploitation in discrete and continuous settings.\nDiagnosing RL instability:\n\nValue drift\nEntropy collapse\nMis-scaled advantages\nReward hacking\n\nSafety-aware RL:\n\nConstraint handling, shields, penalties\nReachability logic basics\n\nOffline RL fundamentals:\n\nDataset coverage\nBehavior policies\nDistributional shift\n\nCounterfactual evaluation and why it matters in safety-critical systems.\n\nFollow-along tasks:\n\nWrite out the PPO objective and update rule by hand, including clipping, advantage, and entropy terms.\nImplement PPO or DQN from scratch in PyTorch (keep it minimal but readable).\nRe-derive the REINFORCE update starting from log-likelihood gradients.\nWrite a one-paragraph explanation of what causes PPO instability and how you‚Äôd detect it.\nRead two recent RL papers from your target teams.\nTrain a simple RL agent:\n\nCartPole, or\nA domain-specific environment like OpenDSS/CityLearn.\n\nStudy 2‚Äì3 DRL papers closely related to your dream role.\n\nOutcome: Confidently explain, derive, implement, and debug modern RL algorithms and discuss where they fail."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#weeks-78-llms-rag-multimodal-systems-prompting-finetuning",
    "href": "blog/technotes_20251102_research_guide/index.html#weeks-78-llms-rag-multimodal-systems-prompting-finetuning",
    "title": "Research Scientist Interview Guide",
    "section": "3.4 (Weeks 7‚Äì8) LLMs, RAG, Multimodal Systems, Prompting & Finetuning",
    "text": "3.4 (Weeks 7‚Äì8) LLMs, RAG, Multimodal Systems, Prompting & Finetuning\nGoal: Build a strong working mastery of LLMs and the surrounding ecosystem.\nTopics:\n\nPretraining vs finetuning vs RLHF vs instruction tuning.\nParameter-efficient finetuning:\n\nLoRA, QLoRA, PEFT.\n\nTokenization:\n\nBPE, SentencePiece basics.\n\nDiffusion models:\n\nKey intuition (noise schedule, denoising).\n\nRAG systems:\n\nChunking strategies\nVector search and indexing\nReranking\n\nLLM evaluation:\n\nExact match, BLEU, nDCG\nWin-rate and human eval\n\nSafety:\n\nHallucination mitigation\nSafety filters, prompt defenses\n\nKnowledge distillation for LLMs.\nMultimodal encoders (CLIP-style), contrastive learning.\nVision metrics:\n\nmAP, IoU, retrieval (k?).\n\n\nHands-on tasks:\n\nPlay with prompt engineering and basic tool calling.\nBuild a minimal RAG pipeline using a public dataset.\nFinetune a small model (e.g., Mistral-7B, Qwen-2B or similar).\nEvaluate retriever quality using recall@k or nDCG.\nSummarize one frontier LLM paper (OpenAI, Anthropic, DeepMind, etc.).\nCreate 5 ‚Äúhallucination test‚Äù prompts and inspect failure cases.\n\nOutcome: Can talk about LLMs as both a research topic and a system you can build and debug."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#weeks-910-ai-safety-alignment-responsible-ai",
    "href": "blog/technotes_20251102_research_guide/index.html#weeks-910-ai-safety-alignment-responsible-ai",
    "title": "Research Scientist Interview Guide",
    "section": "3.5 (Weeks 9‚Äì10) AI Safety, Alignment & Responsible AI",
    "text": "3.5 (Weeks 9‚Äì10) AI Safety, Alignment & Responsible AI\nGoal: Develop a rigorous understanding of safety and alignment principles used in modern labs.\nTopics:\n\nAlignment foundations:\n\nOuter vs inner alignment\nGoal misgeneralization.\n\nDeception risks and model monitoring.\nRed teaming and adversarial prompting.\nGuardrails & safety filters (moderation models, policy layers).\nInterpretability:\n\nSaliency\nProbing\nCausal scrubbing (intuitively)\n\nRobustness & adversarial attacks.\nReward hacking & specification gaming.\nResponsible deployment and incident response.\n\nHands-on tasks:\n\nEvaluate an LLM for hallucination and unsafe completions.\nBuild a small safety classifier (e.g., toxicity or PII detection).\nImplement simple adversarial prompts to test robustness.\nSummarize 2‚Äì3 alignment papers from DeepMind / OpenAI / Anthropic.\n\nOutcome: Can speak maturely and concretely about safety, alignment risks, and mitigation strategies."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#m3.6-weeks-1112-ml-systems-experimentation-design-infrastructure",
    "href": "blog/technotes_20251102_research_guide/index.html#m3.6-weeks-1112-ml-systems-experimentation-design-infrastructure",
    "title": "Research Scientist Interview Guide",
    "section": "M3.6 (Weeks 11‚Äì12) ML Systems, Experimentation Design & Infrastructure",
    "text": "M3.6 (Weeks 11‚Äì12) ML Systems, Experimentation Design & Infrastructure\nGoal: Understand how research artifacts turn into production-grade systems.\nTopics:\n\nData-centric AI:\n\nData pipelines, labeling strategies, noise.\n\nFeature engineering vs representation learning.\nConstraints:\n\nLatency, throughput, cost.\n\nMonitoring:\n\nDrift, anomalies, reliability SLOs.\n\nGuardrails:\n\nFail-open vs fail-safe\nCircuit breakers\nFallback heuristics.\n\nShadow vs online experimentation.\nKey metrics:\n\nProduct KPIs ‚ÜîÔ∏é technical metrics\nOOD splits, fairness audits.\n\nReliability:\n\nRollback plans, incident runbooks.\n\n\nHands-on tasks:\n\nDesign a deployment plan for a real ML model (e.g., anomaly detection, RAG, recommender).\nBuild a small drift-detection pipeline.\nWrite a full ML system design doc (data ‚Üí model ‚Üí eval ‚Üí rollout).\nEvaluate at least 3 slices of a dataset: OOD, rare cases, edge cases.\n\nOutcome: Can walk through a complete ‚Äúresearch to production‚Äù story with credible detail."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#phase-2-weeks-1314-research-talk-deep-dives-scientific-communication",
    "href": "blog/technotes_20251102_research_guide/index.html#phase-2-weeks-1314-research-talk-deep-dives-scientific-communication",
    "title": "Research Scientist Interview Guide",
    "section": "4. Phase 2 (Weeks 13‚Äì14): Research Talk, Deep Dives & Scientific Communication",
    "text": "4. Phase 2 (Weeks 13‚Äì14): Research Talk, Deep Dives & Scientific Communication\nGoal: Prepare the single most important artifact in the interview loop‚Äîyour research story.\nActivities:\n\nBuild 30, 45, and 60-minute versions of your talk.\nUse a clear slide ratio:\n\nMotivation (10%)\nProblem + Gap (10‚Äì15%)\nMethod (35%)\nResults (40%)\nLimitations (10%)\n\nCreate:\n\n3 strong ablation stories\n1 negative result you can explain with maturity.\nA ‚Äúfailure case‚Äù slide.\n\nWrite a single-sentence thesis for your talk.\nDo at least one dry run alone (no audience).\nPrepare 25‚Äì30 deep-dive technical questions you might be asked.\nDerive your core equation/algorithm on paper (e.g., loss function, policy update).\n\nMock sessions: - Give your talk to peers/mentors. - Ask for aggressive Q&A (poke at assumptions, data choices, evaluation). - Do a full ‚Äúpaper walkthrough‚Äù session, slide by slide or section by section.\nOutcome: Can defend your work with clarity, honesty, and scientific maturity, including what didn‚Äôt work."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#phase-3-week-15-behavioral-mastery-star-l",
    "href": "blog/technotes_20251102_research_guide/index.html#phase-3-week-15-behavioral-mastery-star-l",
    "title": "Research Scientist Interview Guide",
    "section": "5. Phase 3 (Week 15): Behavioral Mastery (STAR-L)",
    "text": "5. Phase 3 (Week 15): Behavioral Mastery (STAR-L)\nGoal: Show leadership, ownership, and judgment‚Äînot just equations.\nUse STAR-L: &gt; Situation ‚Üí Task ‚Üí Action ‚Üí Result ‚Üí Learning\nPrepare stories for: - A failure you owned and learned from. - A conflict you resolved or navigated. - Working under ambiguity. - Mentoring or unblocking someone. - Leading without formal authority. - A data-quality disaster. - A roadmap change after a major negative result.\nFollow-along tasks:\n\nWrite 10 STAR-L stories.\nPractice two-minute delivery for each.\nRecord a mock behavioral round (audio or video).\nIdentify your ‚Äúsuperpower‚Äù and your ‚Äúgrowth edges‚Äù as a researcher.\n\n\n5.1 Final Polish & Company-Specific Tuning\nGoal: Finish the cycle aligned, sharp, and confident.\nWhat to finalize:\n\n30/45/60-minute talk versions.\nDeep dive answers for your top 2‚Äì3 projects.\nOne-page project summaries.\nA set of 10 questions for each interviewer type (researcher, MLE, PM, HM).\nA 60-second elevator pitch about who you are as a researcher.\nA mock onsite simulation: &gt;Talk ‚Üí technical ‚Üí systems ‚Üí behavioral.\n\nFollow-along tasks: - Study 3‚Äì5 papers from the target team. - Align one slide in your talk to their mission/charter. - Prepare a ‚ÄúWhat I can deliver in 6 months‚Äù slide or talking point. - Design your Interview Day game plan: - Sleep, food, breaks, notes, mindset."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#closing-note",
    "href": "blog/technotes_20251102_research_guide/index.html#closing-note",
    "title": "Research Scientist Interview Guide",
    "section": "Closing Note",
    "text": "Closing Note\nThis 15-week, ~100-day preparation cycle is not just about surviving interviews. It is about becoming a clearer thinker, stronger experimenter, better systems designer, and more confident communicator‚Äîthe kind of researcher who can walk into any environment and add value quickly."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#subscribe-neuraagentix-ai-to-get-new-posts-on-ai-research-rl-llms-and-the-science-of-building-intelligent-systems.",
    "href": "blog/technotes_20251102_research_guide/index.html#subscribe-neuraagentix-ai-to-get-new-posts-on-ai-research-rl-llms-and-the-science-of-building-intelligent-systems.",
    "title": "Research Scientist Interview Guide",
    "section": "> Subscribe NeuraAgentix AI to get new posts on AI research, RL, LLMs, and the science of building intelligent systems.",
    "text": "&gt; Subscribe NeuraAgentix AI to get new posts on AI research, RL, LLMs, and the science of building intelligent systems."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#potential-questions-to-practice-post-guide-add-on",
    "href": "blog/technotes_20251102_research_guide/index.html#potential-questions-to-practice-post-guide-add-on",
    "title": "Research Scientist Interview Guide",
    "section": "Potential Questions to Practice (Post-Guide Add-On)",
    "text": "Potential Questions to Practice (Post-Guide Add-On)\nEven after a full preparation cycle, the most critical skill is being able to reason aloud under pressure. These are high-signal prompts‚Äîexactly the kind you‚Äôll face in research loops at FAANG labs, DeepMind, OpenAI, Anthropic, NVIDIA, and applied ML teams. Use them for mock interviews, daily drills, or deep-dive rehearsals.\n\n1. Research Narrative Questions\nThese assess your clarity, causality, and scientific maturity.\n\nWhat was the original problem motivation, and what gap in prior work did you identify?\nIf someone tries to reproduce your paper, what is the first place they might get stuck‚Äîand why?\nWhat is the core equation behind your method? Derive it.\nHow did you choose hyperparameters and baselines? What alternatives did you reject, and why?\nWhat was your strongest ablation and the most surprising negative result?\nWhat are the three biggest assumptions in your work? How do they impact generalization?\nExplain one design decision that turned out to be wrong. What did you learn?\nIf you had 3 more months, what experiment would you run first?\n\n\n\n2. Machine Learning Fundamentals\n\nThese evaluate foundations beyond ‚Äútool usage.‚Äù\nExplain bias‚Äìvariance tradeoff using a real ML experiment you ran.\nWhy is cross-entropy the default classification loss? What are its weaknesses?\nExplain the difference between calibration and accuracy.\nWhen does AdamW outperform Adam? When does SGD outperform both?\nWhy does label smoothing help? When can it hurt?\nWalk me through how LayerNorm works and what problem it solves.\nDerive the gradient of softmax + cross-entropy.\nWhat makes a metric robust? Give an example from your work.\n\n\n\n3. Deep Learning & Transformers\n\nYou should be able to explain these without jargon.\nHow does self-attention scale? What is the bottleneck?\nWhy does RoPE (rotary embeddings) help at long sequence lengths?\nCompare MLP layers in transformers with convolutional layers.\nHow do you detect and fix attention drift or instability?\nWhat are the differences between pretraining, SFT, RLHF, and DPO?\nWhen would you prefer LoRA to full fine-tuning? When not?\n\n\n\n4. Reinforcement Learning / Control\nVery common for robotics, energy, and autonomy research teams.\n\nDerive the policy gradient theorem.\nExplain GAE and how it stabilizes PPO.\nWhat causes PPO instability? Diagnose this using logs.\nCompare TD3 vs.¬†SAC‚Äîwhere does each shine?\nWhat‚Äôs your exploration story? What happens if it collapses too early?\nHow do you enforce safety constraints in RL?\nDesign an experiment to detect reward hacking.\nWhy is offline RL difficult? What are the common failure modes?\n\n\n\n5. LLMs, RAG, and Multimodal Systems\nThese appear in GenAI-focused interviews.\n\nHow do you design chunk sizes for RAG?\nEvaluate retriever quality using recall@k and nDCG‚Äîwhat‚Äôs the difference?\nWhat are the typical root causes of hallucination?\nExplain instruction tuning vs.¬†alignment.\nWhen would you use a reranker?\nHow do you design a guardrail for a safety-critical RAG pipeline?\nWhat does it mean for an embedding model to be anisotropic?\n\n\n\n6. Experimentation, Evaluation & Systems Thinking\nThese questions separate strong researchers from average candidates.\n\nWhat is the minimum viable baseline for your task?\nHow do you know if your improvement is statistically meaningful?\nHow do you test for OOD generalization?\nPropose a slicing strategy for your dataset.\nDesign a drift detection pipeline for a production model.\nExplain guardrails in the context of ML systems.\nHow would you deploy a model that is correct but unstable?\n\n\n\n7. Behavioral / Scientific Judgment\nThese should follow STAR-L.\n\nTell me about a time your experiment invalidated your entire roadmap.\nDescribe a major failure‚Äîwhat did you learn?\nDescribe a conflict in a research collaboration and how you resolved it.\nTell me about a time you mentored someone technically.\nWhen did you choose scientific rigor over speed? When did you choose speed?\nDescribe a risky research bet you made. How did it turn out?\n\n\n\n8. Extremely High-Signal ‚ÄúBar Raiser‚Äù Questions\nThese often decide the offer.\n\nWhat is your strongest research intuition?\nWhat‚Äôs a problem you won‚Äôt solve with deep learning?\nWhat is one idea you believe is true but is not proven yet?\nTeach me the main idea of your method in 20 seconds.\nIf I remove 80% of your training compute, what breaks first?\nIf you were in charge of this team, what would you prioritize for the next 6 months?\n\n\n\n9. Practical Coding / ML Engineering Prompts\nNot LeetCode‚Äîreal ML-adjacent coding.\n\nImplement a basic dataloader with batching and shuffling.\nWrite a PyTorch forward pass for an MLP with dropout.\nImplement multi-head attention step-by-step.\nWrite vectorized NumPy code to compute cosine similarity.\nImplement prioritized replay sampling.\nBuild a simple streaming anomaly detector.\nGiven a log file with rewards and losses, produce summary diagnostics.\n\n\n\n10. Lightning-Round ‚ÄúExplain in Plain English‚Äù Prompts\nA favorite of FAANG research interviews.\n\nWhat is KL divergence?\nWhat does entropy measure?\nWhat is overfitting, really?\nWhy does normalization matter?\nWhat is a confidence interval?\nWhy is drift dangerous?\nWhat is a reward function in one sentence?\nWhy do we need baselines?\n\n\n\nSubscribe to NeuraAgentix AI ¬†¬∑"
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#weeks-1112-ml-systems-experimentation-design-infrastructure",
    "href": "blog/technotes_20251102_research_guide/index.html#weeks-1112-ml-systems-experimentation-design-infrastructure",
    "title": "Research Scientist Interview Guide",
    "section": "3.6 (Weeks 11‚Äì12) ML Systems, Experimentation Design & Infrastructure",
    "text": "3.6 (Weeks 11‚Äì12) ML Systems, Experimentation Design & Infrastructure\nGoal: Understand how research artifacts turn into production-grade systems.\nTopics:\n\nData-centric AI:\n\nData pipelines, labeling strategies, noise.\n\nFeature engineering vs representation learning.\nConstraints:\n\nLatency, throughput, cost.\n\nMonitoring:\n\nDrift, anomalies, reliability SLOs.\n\nGuardrails:\n\nFail-open vs fail-safe\nCircuit breakers\nFallback heuristics.\n\nShadow vs online experimentation.\nKey metrics:\n\nProduct KPIs ‚ÜîÔ∏é technical metrics\nOOD splits, fairness audits.\n\nReliability:\n\nRollback plans, incident runbooks.\n\n\nHands-on tasks:\n\nDesign a deployment plan for a real ML model (e.g., anomaly detection, RAG, recommender).\nBuild a small drift-detection pipeline.\nWrite a full ML system design doc (data ‚Üí model ‚Üí eval ‚Üí rollout).\nEvaluate at least 3 slices of a dataset: OOD, rare cases, edge cases.\n\nOutcome: Can walk through a complete ‚Äúresearch to production‚Äù story with credible detail."
  },
  {
    "objectID": "blog/technotes_20251102_research_guide/index.html#phase-1-interview-preparation-roadmap",
    "href": "blog/technotes_20251102_research_guide/index.html#phase-1-interview-preparation-roadmap",
    "title": "Research Scientist Interview Guide",
    "section": "3. Phase 1 Interview Preparation Roadmap",
    "text": "3. Phase 1 Interview Preparation Roadmap\nPreparing for a research scientist role isn‚Äôt a weekend sprint. The plan below assumes ~100 days (around 14‚Äì15 weeks) of disciplined, focused preparation. Think of it as 10 phases (‚âà10 days each), grouped into larger thematic blocks.\n#100DaysofPreparation\n\n3.1 (Weeks 1‚Äì2) Build Your Research Portfolio Foundation\nGoal: Establish your scientific identity and core artifacts.\nWhat to accomplish:\n\nSelect 2‚Äì3 flagship projects ‚Äî the ones you want to be hired for.\nWrite one-page summaries for each:\n\nproblem ‚Üí gap ‚Üí idea ‚Üí method ‚Üí evidence ‚Üí limits.\n\nOrganize code, plots, logs, notebooks, and experiment sheets into a clean structure.\nRefresh foundational ML math:\n\nGradients, softmax, cross-entropy\nBias‚Äìvariance tradeoff, generalization\nRegularization basics (weight decay, dropout)\n\nReview optimization basics:\n\nSGD, AdamW\nLearning rate warmup, cosine decay\nMLE vs.¬†MAP\n\nDo light DS&A:\n\n20‚Äì30 minutes/day on arrays/strings, hash maps, basic trees.\n\n\nOutcome: A clear, coherent scientific story and crisp articulation of your contributions.\nFollow-along tasks:\n\nCreate a Portfolio/ folder and write 3 one-page project summaries.\nList your 5 strongest experimental results (with metrics and context).\nSummarize 3 papers from your target teams (FAANG, DeepMind, OpenAI, Anthropic, etc.).\n\n\n\n3.2 (Weeks 3‚Äì4) Deep Learning & Modern Architectures Refresh\nGoal: Regain fluency in the architectures that power modern AI systems.\nTopics to review:\n\nCNNs, RNNs, LSTMs, GRUs\nTransformers: attention, QKV projections, multi-head attention\nResidual connections, LayerNorm, normalization strategies\nKL divergence, entropy, cross-entropy\nPositional encodings, rotary embeddings (RoPE)\nRegularization techniques: dropout, mixup, cutmix, label smoothing\nTraining dynamics:\n\nGradient flow\nVanishing/exploding gradients\nLoss landscapes, sharpness, generalization behavior\n\n\nFollow-along tasks: - Re-derive softmax + cross-entropy and their gradients. - Solve 10 small gradient/optimization exercises. - Summarize 3 internals of transformers (e.g., QKV, attention, layer norm) in your own words.\nHands-on:\n\nRebuild a transformer encoder from scratch in PyTorch (minimal but clean).\nImplement vision augmentations (random crop, flip, color jitter).\nReproduce a small-scale paper result (e.g., CIFAR-10 or MNIST baseline).\n\nOutcome: You should be comfortable answering: ‚ÄúHow does this model actually work?‚Äù instead of just ‚ÄúIt‚Äôs a transformer.‚Äù\n\n\n3.3 (Weeks 5‚Äì6) Deep Reinforcement Learning Refresher\nGoal: Achieve deep, working-level confidence with modern DRL.\nCore topics:\n\nDerive the policy gradient theorem from first principles.\nUnderstand Generalized Advantage Estimation (GAE) and why it stabilizes training.\nBuild intuition for PPO and TRPO:\n\nClipped objective\nTrust regions\nKL constraints\n\nMaster key off-policy algorithms:\n\nDQN, TD3, SAC\nWhen to use which (discrete/continuous, exploration needs).\n\nReplay buffers, target networks, delayed policy updates.\nExploration vs exploitation in discrete and continuous settings.\nDiagnosing RL instability:\n\nValue drift\nEntropy collapse\nMis-scaled advantages\nReward hacking\n\nSafety-aware RL:\n\nConstraint handling, shields, penalties\nReachability logic basics\n\nOffline RL fundamentals:\n\nDataset coverage\nBehavior policies\nDistributional shift\n\nCounterfactual evaluation and why it matters in safety-critical systems.\n\nFollow-along tasks:\n\nWrite out the PPO objective and update rule by hand, including clipping, advantage, and entropy terms.\nImplement PPO or DQN from scratch in PyTorch (keep it minimal but readable).\nRe-derive the REINFORCE update starting from log-likelihood gradients.\nWrite a one-paragraph explanation of what causes PPO instability and how you‚Äôd detect it.\nRead two recent RL papers from your target teams.\nTrain a simple RL agent:\n\nCartPole, or\nA domain-specific environment like OpenDSS/CityLearn.\n\nStudy 2‚Äì3 DRL papers closely related to your dream role.\n\nOutcome: Confidently explain, derive, implement, and debug modern RL algorithms and discuss where they fail.\n\n\n3.4 (Weeks 7‚Äì8) LLMs, RAG, Multimodal Systems, Prompting & Finetuning\nGoal: Build a strong working mastery of LLMs and the surrounding ecosystem.\nTopics:\n\nPretraining vs finetuning vs RLHF vs instruction tuning.\nParameter-efficient finetuning:\n\nLoRA, QLoRA, PEFT.\n\nTokenization:\n\nBPE, SentencePiece basics.\n\nDiffusion models:\n\nKey intuition (noise schedule, denoising).\n\nRAG systems:\n\nChunking strategies\nVector search and indexing\nReranking\n\nLLM evaluation:\n\nExact match, BLEU, nDCG\nWin-rate and human eval\n\nSafety:\n\nHallucination mitigation\nSafety filters, prompt defenses\n\nKnowledge distillation for LLMs.\nMultimodal encoders (CLIP-style), contrastive learning.\nVision metrics:\n\nmAP, IoU, retrieval (k?).\n\n\nHands-on tasks:\n\nPlay with prompt engineering and basic tool calling.\nBuild a minimal RAG pipeline using a public dataset.\nFinetune a small model (e.g., Mistral-7B, Qwen-2B or similar).\nEvaluate retriever quality using recall@k or nDCG.\nSummarize one frontier LLM paper (OpenAI, Anthropic, DeepMind, etc.).\nCreate 5 ‚Äúhallucination test‚Äù prompts and inspect failure cases.\n\nOutcome: Can talk about LLMs as both a research topic and a system you can build and debug.\n\n\n3.5 (Weeks 9‚Äì10) AI Safety, Alignment & Responsible AI\nGoal: Develop a rigorous understanding of safety and alignment principles used in modern labs.\nTopics:\n\nAlignment foundations:\n\nOuter vs inner alignment\nGoal misgeneralization.\n\nDeception risks and model monitoring.\nRed teaming and adversarial prompting.\nGuardrails & safety filters (moderation models, policy layers).\nInterpretability:\n\nSaliency\nProbing\nCausal scrubbing (intuitively)\n\nRobustness & adversarial attacks.\nReward hacking & specification gaming.\nResponsible deployment and incident response.\n\nHands-on tasks:\n\nEvaluate an LLM for hallucination and unsafe completions.\nBuild a small safety classifier (e.g., toxicity or PII detection).\nImplement simple adversarial prompts to test robustness.\nSummarize 2‚Äì3 alignment papers from DeepMind / OpenAI / Anthropic.\n\nOutcome: Can speak maturely and concretely about safety, alignment risks, and mitigation strategies.\n\n\n3.6 (Weeks 11‚Äì12) ML Systems, Experimentation Design & Infrastructure\nGoal: Understand how research artifacts turn into production-grade systems.\nTopics:\n\nData-centric AI:\n\nData pipelines, labeling strategies, noise.\n\nFeature engineering vs representation learning.\nConstraints:\n\nLatency, throughput, cost.\n\nMonitoring:\n\nDrift, anomalies, reliability SLOs.\n\nGuardrails:\n\nFail-open vs fail-safe\nCircuit breakers\nFallback heuristics.\n\nShadow vs online experimentation.\nKey metrics:\n\nProduct KPIs ‚ÜîÔ∏é technical metrics\nOOD splits, fairness audits.\n\nReliability:\n\nRollback plans, incident runbooks.\n\n\nHands-on tasks:\n\nDesign a deployment plan for a real ML model (e.g., anomaly detection, RAG, recommender).\nBuild a small drift-detection pipeline.\nWrite a full ML system design doc (data ‚Üí model ‚Üí eval ‚Üí rollout).\nEvaluate at least 3 slices of a dataset: OOD, rare cases, edge cases.\n\nOutcome: Can walk through a complete ‚Äúresearch to production‚Äù story with credible detail."
  }
]